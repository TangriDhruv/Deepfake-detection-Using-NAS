{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.052618Z",
     "iopub.status.busy": "2025-04-19T00:04:12.052384Z",
     "iopub.status.idle": "2025-04-19T00:04:12.071227Z",
     "shell.execute_reply": "2025-04-19T00:04:12.070475Z",
     "shell.execute_reply.started": "2025-04-19T00:04:12.052603Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_curve\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import random\n",
    "from torch.distributions import Categorical\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Feature extraction functions\n",
    "def extract_mfcc(audio, sr=16000, n_mfcc=20):\n",
    "    \"\"\"Extract MFCC features from audio\"\"\"\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    features = np.concatenate([mfcc, delta, delta2], axis=0)\n",
    "    return features\n",
    "\n",
    "def extract_spec(audio, sr=16000, n_fft=512, hop_length=256):\n",
    "    \"\"\"Extract log mel-spectrogram features from audio\"\"\"\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=80)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec)\n",
    "    return log_mel_spec\n",
    "\n",
    "def extract_cqt(audio, sr=16000, hop_length=256):\n",
    "    \"\"\"Extract Constant-Q Transform features from audio\"\"\"\n",
    "    cqt = librosa.cqt(y=audio, sr=sr, hop_length=hop_length)\n",
    "    return np.abs(cqt)\n",
    "\n",
    "# ASVSpoof Dataset Class\n",
    "class ASVSpoofDataset(Dataset):\n",
    "    def __init__(self, root_dir, protocol_file, feature_type='mfcc', max_len=None, is_train=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the audio files.\n",
    "            protocol_file (string): Path to the protocol file.\n",
    "            feature_type (string): Type of features to extract ('mfcc', 'spec', 'cqt').\n",
    "            max_len (int): Maximum length of features sequence.\n",
    "            is_train (bool): Whether this is for training or testing.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.feature_type = feature_type\n",
    "        self.max_len = max_len\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Read protocol file\n",
    "        self.data = []\n",
    "        \n",
    "        print(f\"Reading protocol file: {protocol_file}\")\n",
    "        try:\n",
    "            with open(protocol_file, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "                # Use tqdm for loading progress\n",
    "                for line in tqdm(lines, desc=f\"Loading {'training' if is_train else 'evaluation'} protocol\"):\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:\n",
    "                        speaker_id = parts[0]\n",
    "                        file_id = parts[1]\n",
    "                        label_text = parts[4]\n",
    "                        label = 0 if label_text == 'bonafide' else 1  # 0 for bonafide, 1 for spoof\n",
    "                        self.data.append((file_id, label))\n",
    "            \n",
    "            # Count number of bonafide and spoof samples\n",
    "            bonafide_count = sum(1 for _, label in self.data if label == 0)\n",
    "            spoof_count = sum(1 for _, label in self.data if label == 1)\n",
    "            \n",
    "            print(f\"Dataset loaded: {len(self.data)} samples ({bonafide_count} bonafide, {spoof_count} spoof)\")\n",
    "            \n",
    "            if is_train:\n",
    "                # Subsample for faster NAS\n",
    "                if len(self.data) > 5000:\n",
    "                    print(f\"Subsampling training data for faster NAS...\")\n",
    "                    np.random.shuffle(self.data)\n",
    "                    # Keep balanced class distribution\n",
    "                    bonafide_samples = [item for item in self.data if item[1] == 0][:2500]\n",
    "                    spoof_samples = [item for item in self.data if item[1] == 1][:2500]\n",
    "                    self.data = bonafide_samples + spoof_samples\n",
    "                    np.random.shuffle(self.data)\n",
    "                    print(f\"Subsampled to {len(self.data)} samples\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading protocol file: {e}\")\n",
    "            self.data = []\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_id, label = self.data[idx]\n",
    "        audio_path = os.path.join(self.root_dir, f\"{file_id}.flac\")\n",
    "        \n",
    "        try:\n",
    "            audio, sr = sf.read(audio_path)\n",
    "            \n",
    "            # Feature extraction\n",
    "            if self.feature_type == 'mfcc':\n",
    "                features = extract_mfcc(audio, sr)\n",
    "            elif self.feature_type == 'spec':\n",
    "                features = extract_spec(audio, sr)\n",
    "            elif self.feature_type == 'cqt':\n",
    "                features = extract_cqt(audio, sr)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown feature type: {self.feature_type}\")\n",
    "            \n",
    "            # Normalize features\n",
    "            features = (features - np.mean(features)) / (np.std(features) + 1e-8)\n",
    "            \n",
    "            # Handle sequence length\n",
    "            seq_len = features.shape[1]\n",
    "            if self.max_len is not None:\n",
    "                if seq_len > self.max_len:\n",
    "                    start = np.random.randint(0, seq_len - self.max_len) if self.is_train else 0\n",
    "                    features = features[:, start:start+self.max_len]\n",
    "                elif seq_len < self.max_len:\n",
    "                    # Pad with zeros\n",
    "                    pad_width = ((0, 0), (0, self.max_len - seq_len))\n",
    "                    features = np.pad(features, pad_width, mode='constant')\n",
    "            \n",
    "            return torch.FloatTensor(features), torch.LongTensor([label])[0]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {audio_path}: {e}\")\n",
    "            # Return a dummy sample in case of error\n",
    "            dummy_features = np.zeros((60, 100 if self.max_len is None else self.max_len))\n",
    "            return torch.FloatTensor(dummy_features), torch.LongTensor([label])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.076602Z",
     "iopub.status.busy": "2025-04-19T00:04:12.076063Z",
     "iopub.status.idle": "2025-04-19T00:04:12.102218Z",
     "shell.execute_reply": "2025-04-19T00:04:12.101335Z",
     "shell.execute_reply.started": "2025-04-19T00:04:12.076569Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Neural Architecture Search operations\n",
    "\n",
    "# Base operation class\n",
    "class Operation(nn.Module):\n",
    "    \"\"\"Base class for all operations in the search space\"\"\"\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(Operation, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "# Convolutional Block\n",
    "class ConvBlock(Operation):\n",
    "    def __init__(self, channels, kernel_size, stride=1):\n",
    "        super(ConvBlock, self).__init__(channels, stride)\n",
    "        self.conv = nn.Conv1d(channels, channels, kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.bn = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "# LSTM Block\n",
    "class LSTM(Operation):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(LSTM, self).__init__(channels, stride)\n",
    "        self.lstm = nn.LSTM(channels, channels, batch_first=True)\n",
    "        self.input_proj = nn.Conv1d(in_channels=channels, out_channels=channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [B, C, T]\n",
    "        batch_size, channels, seq_len = x.size()\n",
    "        x = x.permute(0, 2, 1)  # [B, C, T] -> [B, T, C]\n",
    "        \n",
    "        # LSTM with batch_first=True\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # Return to original dimension ordering\n",
    "        x = x.permute(0, 2, 1)  # [B, T, C] -> [B, C, T]\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Dilated Convolution\n",
    "class Dilated(Operation):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(Dilated, self).__init__(channels, stride)\n",
    "        self.conv = nn.Conv1d(channels, channels, 3, stride=stride, padding=2, dilation=2)\n",
    "        self.bn = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))\n",
    "\n",
    "# Skip Connection\n",
    "class SkipConnect(Operation):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(SkipConnect, self).__init__(channels, stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# Self-Attention Block\n",
    "class Attention(Operation):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(Attention, self).__init__(channels, stride)\n",
    "        self.query = nn.Conv1d(channels, channels, 1)\n",
    "        self.key = nn.Conv1d(channels, channels, 1)\n",
    "        self.value = nn.Conv1d(channels, channels, 1)\n",
    "        self.scale = torch.sqrt(torch.FloatTensor([channels])).to(device)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [B, C, T]\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        \n",
    "        # Reshape for attention\n",
    "        batch_size, C, T = q.size()\n",
    "        q = q.permute(0, 2, 1)  # [B, T, C]\n",
    "        k = k.permute(0, 2, 1)  # [B, T, C]\n",
    "        v = v.permute(0, 2, 1)  # [B, T, C]\n",
    "        \n",
    "        # Self-attention\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attention, v)\n",
    "        \n",
    "        # Reshape back\n",
    "        return context.permute(0, 2, 1)  # [B, C, T]\n",
    "\n",
    "# Separable Convolution\n",
    "class SeparableConv(Operation):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(SeparableConv, self).__init__(channels, stride)\n",
    "        self.depthwise = nn.Conv1d(channels, channels, 3, stride=stride, padding=1, groups=channels)\n",
    "        self.pointwise = nn.Conv1d(channels, channels, 1)\n",
    "        self.bn = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.pointwise(self.depthwise(x))))\n",
    "\n",
    "# Squeeze-and-Excitation Block\n",
    "class SqueezeExcitation(Operation):\n",
    "    def __init__(self, channels, stride=1, reduction=16):\n",
    "        super(SqueezeExcitation, self).__init__(channels, stride)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc1 = nn.Conv1d(channels, max(channels // reduction, 1), kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Conv1d(max(channels // reduction, 1), channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [B, C, T]\n",
    "        scale = self.avg_pool(x)\n",
    "        scale = self.fc1(scale)\n",
    "        scale = self.relu(scale)\n",
    "        scale = self.fc2(scale)\n",
    "        scale = self.sigmoid(scale)\n",
    "        return x * scale\n",
    "\n",
    "# Frequency-Aware Convolution (Audio-specific)\n",
    "class FrequencyAwareConv(Operation):\n",
    "    def __init__(self, channels, stride=1, bands=4):\n",
    "        super(FrequencyAwareConv, self).__init__(channels, stride)\n",
    "        # Ensure band_size is at least 1\n",
    "        self.band_size = max(channels // bands, 1)\n",
    "        self.bands = min(bands, channels)\n",
    "        \n",
    "        # Create different kernel sizes for frequency bands\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(self.band_size, self.band_size, 3 + i*2, padding=(3+i*2)//2, stride=stride)\n",
    "            for i in range(self.bands)\n",
    "        ])\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(channels)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Split along channel dimension into bands\n",
    "        split_sizes = [self.band_size] * self.bands\n",
    "        remaining = self.channels - (self.band_size * self.bands)\n",
    "        if remaining > 0:\n",
    "            split_sizes[-1] += remaining\n",
    "            \n",
    "        x_bands = torch.split(x, split_sizes, dim=1)\n",
    "        \n",
    "        # Process each band separately\n",
    "        out_bands = []\n",
    "        for i, band in enumerate(x_bands):\n",
    "            if i < self.bands:\n",
    "                out_bands.append(self.convs[i](band))\n",
    "        \n",
    "        # Concatenate results\n",
    "        out = torch.cat(out_bands, dim=1)\n",
    "        \n",
    "        return self.relu(self.bn(out))\n",
    "\n",
    "# Gated Convolution\n",
    "class GatedConv(Operation):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(GatedConv, self).__init__(channels, stride)\n",
    "        self.conv_features = nn.Conv1d(channels, channels, 3, stride=stride, padding=1)\n",
    "        self.conv_gate = nn.Conv1d(channels, channels, 3, stride=stride, padding=1)\n",
    "        self.bn = nn.BatchNorm1d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.conv_features(x)\n",
    "        gate = torch.sigmoid(self.conv_gate(x))\n",
    "        return self.bn(features * gate)\n",
    "\n",
    "# Mixed Operation (Weighted sum of operations)\n",
    "class MixedOp(nn.Module):\n",
    "    def __init__(self, channels, stride=1):\n",
    "        super(MixedOp, self).__init__()\n",
    "        self.ops = nn.ModuleList([\n",
    "            # Original operations\n",
    "            ConvBlock(channels, 3, stride),\n",
    "            ConvBlock(channels, 5, stride),\n",
    "            LSTM(channels, stride),\n",
    "            Dilated(channels, stride),\n",
    "            SkipConnect(channels, stride),\n",
    "            Attention(channels, stride),\n",
    "            # New operations\n",
    "            SeparableConv(channels, stride),\n",
    "            SqueezeExcitation(channels, stride),\n",
    "            FrequencyAwareConv(channels, stride),\n",
    "            GatedConv(channels, stride)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x, weights):\n",
    "        \"\"\"Forward pass with operation weights\"\"\"\n",
    "        return sum(w * op(x) for w, op in zip(weights, self.ops))\n",
    "\n",
    "# Cell structure\n",
    "class Cell(nn.Module):\n",
    "    def __init__(self, channels, num_nodes=4):\n",
    "        super(Cell, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.num_nodes = num_nodes\n",
    "        \n",
    "        # For each node, create edges from all previous nodes\n",
    "        self.edges = nn.ModuleList()\n",
    "        for i in range(num_nodes):\n",
    "            for j in range(i+1):  # connections from input and previous nodes\n",
    "                self.edges.append(MixedOp(channels))\n",
    "        \n",
    "        # Output projection\n",
    "        self.project = nn.Conv1d(channels * num_nodes, channels, 1)\n",
    "    \n",
    "    def forward(self, x, weights):\n",
    "        \"\"\"\n",
    "        Forward pass through the cell\n",
    "        Args:\n",
    "            x: Input tensor [B, C, T]\n",
    "            weights: List of weight tensors for each edge\n",
    "        \"\"\"\n",
    "        states = [x]\n",
    "        offset = 0\n",
    "        \n",
    "        # Process each node\n",
    "        for i in range(self.num_nodes):\n",
    "            # Gather inputs from previous nodes\n",
    "            node_inputs = []\n",
    "            for j in range(i+1):\n",
    "                edge_output = self.edges[offset + j](states[j], weights[offset + j])\n",
    "                node_inputs.append(edge_output)\n",
    "            \n",
    "            node_input = sum(node_inputs)\n",
    "            offset += i+1\n",
    "            states.append(node_input)\n",
    "        \n",
    "        # Concatenate all intermediate nodes\n",
    "        cat_states = torch.cat(states[1:], dim=1)\n",
    "        \n",
    "        return self.project(cat_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.103641Z",
     "iopub.status.busy": "2025-04-19T00:04:12.103362Z",
     "iopub.status.idle": "2025-04-19T00:04:12.122454Z",
     "shell.execute_reply": "2025-04-19T00:04:12.121937Z",
     "shell.execute_reply.started": "2025-04-19T00:04:12.103626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Complete model with hybrid PPO-DARTS support\n",
    "class DeepfakeDetectionModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_cells=3, num_nodes=4, num_ops=10):\n",
    "        super(DeepfakeDetectionModel, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.num_cells = num_cells\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_ops = num_ops\n",
    "        \n",
    "        # Initial projection\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv1d(input_channels, 64, 3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Cells\n",
    "        self.cells = nn.ModuleList()\n",
    "        for i in range(num_cells):\n",
    "            self.cells.append(Cell(64, num_nodes))\n",
    "        \n",
    "        # Classification head\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(64, 2)  # Binary classification\n",
    "        \n",
    "        # Initialize architectural parameters (alphas) for DARTS\n",
    "        self._initialize_alphas()\n",
    "        \n",
    "        # Calculate total number of weights needed for PPO\n",
    "        edges_per_cell = sum(range(1, num_nodes+1))\n",
    "        self.total_weights = num_cells * edges_per_cell * num_ops\n",
    "    \n",
    "    def _initialize_alphas(self):\n",
    "        \"\"\"Initialize architectural parameters for DARTS\"\"\"\n",
    "        edges_per_cell = sum(range(1, self.num_nodes+1))\n",
    "        total_edges = self.num_cells * edges_per_cell\n",
    "        # Create parameter tensor for alphas\n",
    "        self._alphas = nn.Parameter(torch.zeros(total_edges, self.num_ops))\n",
    "        # Initialize with small random values\n",
    "        nn.init.normal_(self._alphas, mean=0, std=0.001)\n",
    "    \n",
    "    def alphas(self):\n",
    "        \"\"\"Return architectural parameters for optimizer\"\"\"\n",
    "        return [self._alphas]  # Wrapped in list for optimizer compatibility\n",
    "    \n",
    "    def weights(self):\n",
    "        \"\"\"Return model weights excluding alphas\"\"\"\n",
    "        return [p for n, p in self.named_parameters() if '_alphas' not in n]\n",
    "    \n",
    "    def forward(self, x, architecture_weights=None, discrete=False):\n",
    "        \"\"\"\n",
    "        Forward pass with multiple modes:\n",
    "        - PPO mode: Using external architecture_weights\n",
    "        - DARTS mode: Using internal alphas with continuous relaxation\n",
    "        - Evaluation mode: Using internal alphas with discrete operations\n",
    "        \"\"\"\n",
    "        # Input shape handling\n",
    "        if x.shape[1] == self.input_channels:\n",
    "            # Input is already [B, C, T]\n",
    "            pass\n",
    "        else:\n",
    "            # Input is [B, T, C], convert to [B, C, T]\n",
    "            x = x.permute(0, 2, 1)\n",
    "        \n",
    "        # Process input\n",
    "        x = self.stem(x)\n",
    "        \n",
    "        # Determine which weights to use\n",
    "        edges_per_cell = sum(range(1, self.num_nodes+1))\n",
    "        \n",
    "        if architecture_weights is not None:\n",
    "            # PPO mode: use external weights\n",
    "            edge_weights = []\n",
    "            for i in range(len(architecture_weights) // self.num_ops):\n",
    "                start_idx = i * self.num_ops\n",
    "                end_idx = start_idx + self.num_ops\n",
    "                # Apply softmax to get probability distribution\n",
    "                edge_weights.append(F.softmax(architecture_weights[start_idx:end_idx], dim=0))\n",
    "        else:\n",
    "            # DARTS mode: use internal alphas\n",
    "            if discrete:\n",
    "                # Convert to discrete (one-hot) for evaluation\n",
    "                max_indices = torch.argmax(self._alphas, dim=1)\n",
    "                edge_weights = []\n",
    "                for j, idx in enumerate(max_indices):\n",
    "                    weights = torch.zeros_like(self._alphas[j])\n",
    "                    weights[idx] = 1.0\n",
    "                    edge_weights.append(weights)\n",
    "            else:\n",
    "                # Use softmax for continuous relaxation\n",
    "                edge_weights = [F.softmax(self._alphas[i], dim=0) for i in range(self._alphas.size(0))]\n",
    "        \n",
    "        # Process cells\n",
    "        offset = 0\n",
    "        for i, cell in enumerate(self.cells):\n",
    "            cell_weights = edge_weights[offset:offset + edges_per_cell]\n",
    "            offset += edges_per_cell\n",
    "            x = cell(x, cell_weights)\n",
    "        \n",
    "        # Classification\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import networkx as nx\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "def visualize_architecture(architecture, num_cells=3, num_nodes=4, num_ops=10, save_path='architecture_visualization.png', \n",
    "                           save_to_wandb=False, title=\"Hybrid PPO-DARTS Architecture\"):\n",
    "    \"\"\"\n",
    "    Visualize the architecture discovered by the hybrid PPO-DARTS approach.\n",
    "    \n",
    "    Args:\n",
    "        architecture: Tensor containing the selected operations (for PPO) or operation weights (for DARTS)\n",
    "        num_cells: Number of cells in the architecture\n",
    "        num_nodes: Number of intermediate nodes in each cell\n",
    "        num_ops: Number of possible operations for each edge\n",
    "        save_path: Path to save the visualization\n",
    "        save_to_wandb: Whether to save the visualization to wandb\n",
    "        title: Title of the visualization\n",
    "    \n",
    "    Returns:\n",
    "        Path to the saved visualization\n",
    "    \"\"\"\n",
    "    # Define operation names for visualization\n",
    "    operation_names = [\n",
    "        'Conv 3x3', 'Conv 5x5', 'LSTM', 'Dilated Conv', 'Skip Connect',\n",
    "        'Self Attention', 'Separable Conv', 'Squeeze-Excitation', 'Frequency-Aware', 'Gated Conv'\n",
    "    ]\n",
    "    \n",
    "    # Define colors for different operations\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\n",
    "    \n",
    "    # Calculate edges per cell\n",
    "    edges_per_cell = sum(range(1, num_nodes+1))\n",
    "    total_edges = num_cells * edges_per_cell\n",
    "    \n",
    "    # Check if architecture is from PPO (1D tensor of indices) or DARTS (2D tensor of weights)\n",
    "    is_ppo = architecture.dim() == 1\n",
    "    \n",
    "    # Create a figure with multiple subplots (one per cell)\n",
    "    fig, axes = plt.subplots(1, num_cells, figsize=(6*num_cells, 6), constrained_layout=True)\n",
    "    if num_cells == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    plt.suptitle(title, fontsize=20, y=1.05)\n",
    "    \n",
    "    # For each cell\n",
    "    for cell_idx in range(num_cells):\n",
    "        ax = axes[cell_idx]\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # Label for cell type\n",
    "        cell_type = \"Normal Cell\" if cell_idx % 2 == 0 else \"Expand Cell\"\n",
    "        ax.set_title(f\"Cell {cell_idx+1}: {cell_type}\", fontsize=16)\n",
    "        \n",
    "        # Add nodes to the graph\n",
    "        for i in range(num_nodes + 2):  # +2 for input and output nodes\n",
    "            if i == 0 or i == 1:\n",
    "                G.add_node(i, label=f\"Input {i+1}\")\n",
    "            elif i == num_nodes + 1:\n",
    "                G.add_node(i, label=\"Output\")\n",
    "            else:\n",
    "                G.add_node(i, label=f\"Node {i}\")\n",
    "        \n",
    "        # Add edges to the graph based on the architecture\n",
    "        edge_offset = cell_idx * edges_per_cell\n",
    "        edge_count = 0\n",
    "        \n",
    "        for i in range(2, num_nodes + 2):  # For each intermediate node\n",
    "            for j in range(i):  # For all previous nodes\n",
    "                edge_idx = edge_offset + edge_count\n",
    "                \n",
    "                if is_ppo:\n",
    "                    # For PPO, the architecture contains operation indices\n",
    "                    if edge_idx < len(architecture):\n",
    "                        op_idx = int(architecture[edge_idx].item())\n",
    "                        op_name = operation_names[op_idx]\n",
    "                        G.add_edge(j, i, label=op_name, color=colors[op_idx])\n",
    "                else:\n",
    "                    # For DARTS, the architecture contains operation weights\n",
    "                    if edge_idx < architecture.size(0):\n",
    "                        op_idx = torch.argmax(architecture[edge_idx]).item()\n",
    "                        op_name = operation_names[op_idx]\n",
    "                        G.add_edge(j, i, label=op_name, color=colors[op_idx])\n",
    "                \n",
    "                edge_count += 1\n",
    "        \n",
    "        # Position nodes in a hierarchical layout\n",
    "        pos = {}\n",
    "        pos[0] = np.array([-1, 0.5])\n",
    "        pos[1] = np.array([-1, -0.5])\n",
    "        \n",
    "        # Position intermediate nodes in a line\n",
    "        for i in range(2, num_nodes + 2):\n",
    "            level = (i - 1) / (num_nodes + 1)\n",
    "            pos[i] = np.array([level*2 - 1, 0])\n",
    "        \n",
    "        # Adjust output node position\n",
    "        pos[num_nodes + 1] = np.array([1, 0])\n",
    "        \n",
    "        # Draw nodes\n",
    "        for n in G.nodes:\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=[n], node_size=1200, \n",
    "                                  node_color='lightblue', alpha=0.8, ax=ax)\n",
    "        \n",
    "        # Draw node labels\n",
    "        nx.draw_networkx_labels(G, pos, labels=nx.get_node_attributes(G, 'label'), \n",
    "                               font_size=10, font_family='sans-serif', ax=ax)\n",
    "        \n",
    "        # Draw edges with custom arrows\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            color = data.get('color', 'gray')\n",
    "            label = data.get('label', '')\n",
    "            \n",
    "            # Create a curved arrow\n",
    "            arrow = FancyArrowPatch(pos[u], pos[v], connectionstyle=\"arc3,rad=0.2\",\n",
    "                                   arrowstyle=\"-|>\", color=color, lw=1.5, alpha=0.8)\n",
    "            ax.add_patch(arrow)\n",
    "            \n",
    "            # Add edge label (operation name)\n",
    "            # Calculate label position (midpoint of the curved edge with slight offset)\n",
    "            x = (pos[u][0] + pos[v][0]) / 2\n",
    "            y = (pos[u][1] + pos[v][1]) / 2\n",
    "            offset = 0.1 if pos[u][1] < pos[v][1] else -0.1\n",
    "            ax.text(x, y + offset, label, fontsize=8, ha='center', va='center', \n",
    "                   bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=1))\n",
    "        \n",
    "        # Remove axis ticks and frame\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Log to wandb if requested\n",
    "    if save_to_wandb:\n",
    "        try:\n",
    "            import wandb\n",
    "            if wandb.run is not None:\n",
    "                wandb.log({\"architecture_visualization\": wandb.Image(save_path)})\n",
    "        except ImportError:\n",
    "            print(\"Warning: wandb not installed, skipping wandb logging\")\n",
    "    \n",
    "    plt.close()\n",
    "    return save_path\n",
    "\n",
    "\n",
    "def visualize_darts_architecture(architecture_weights, num_cells=3, num_nodes=4, num_ops=10, \n",
    "                                save_path='darts_architecture.png', save_to_wandb=False):\n",
    "    \"\"\"\n",
    "    Visualize the DARTS architecture represented by architecture weights.\n",
    "    \n",
    "    Args:\n",
    "        architecture_weights: Tensor of shape [num_edges, num_ops] containing operation weights\n",
    "        num_cells: Number of cells in the architecture\n",
    "        num_nodes: Number of nodes in each cell\n",
    "        num_ops: Number of operations\n",
    "    \"\"\"\n",
    "    return visualize_architecture(\n",
    "        architecture_weights, \n",
    "        num_cells, \n",
    "        num_nodes, \n",
    "        num_ops, \n",
    "        save_path, \n",
    "        save_to_wandb,\n",
    "        title=\"DARTS Architecture (Discrete)\"\n",
    "    )\n",
    "\n",
    "\n",
    "def visualize_ppo_architecture(architecture_indices, num_cells=3, num_nodes=4, num_ops=10, \n",
    "                              save_path='ppo_architecture.png', save_to_wandb=False):\n",
    "    \"\"\"\n",
    "    Visualize the PPO architecture represented by operation indices.\n",
    "    \n",
    "    Args:\n",
    "        architecture_indices: Tensor containing operation indices for each edge\n",
    "        num_cells: Number of cells in the architecture\n",
    "        num_nodes: Number of nodes in each cell\n",
    "        num_ops: Number of operations\n",
    "    \"\"\"\n",
    "    return visualize_architecture(\n",
    "        architecture_indices, \n",
    "        num_cells, \n",
    "        num_nodes, \n",
    "        num_ops, \n",
    "        save_path, \n",
    "        save_to_wandb,\n",
    "        title=\"PPO-Generated Architecture\"\n",
    "    )\n",
    "\n",
    "\n",
    "def compare_architectures(ppo_architecture, darts_architecture, num_cells=3, num_nodes=4, num_ops=10,\n",
    "                         save_path='architecture_comparison.png', save_to_wandb=False):\n",
    "    \"\"\"\n",
    "    Create a visualization comparing PPO and DARTS architectures side by side.\n",
    "    \n",
    "    Args:\n",
    "        ppo_architecture: Architecture tensor from PPO\n",
    "        darts_architecture: Architecture tensor from DARTS\n",
    "        num_cells: Number of cells\n",
    "        num_nodes: Number of nodes per cell\n",
    "        num_ops: Number of operations\n",
    "    \"\"\"\n",
    "    # Define operation names\n",
    "    operation_names = [\n",
    "        'Conv 3x3', 'Conv 5x5', 'LSTM', 'Dilated Conv', 'Skip Connect',\n",
    "        'Self Attention', 'Separable Conv', 'Squeeze-Excitation', 'Frequency-Aware', 'Gated Conv'\n",
    "    ]\n",
    "    \n",
    "    # Create a figure with a grid of subplots\n",
    "    fig, axes = plt.subplots(2, num_cells, figsize=(6*num_cells, 12), constrained_layout=True)\n",
    "    plt.suptitle(\"PPO vs DARTS Architecture Comparison\", fontsize=24, y=1.05)\n",
    "    \n",
    "    # Top row for PPO\n",
    "    for cell_idx in range(num_cells):\n",
    "        axes[0, cell_idx].set_title(f\"PPO Cell {cell_idx+1}\", fontsize=16)\n",
    "    \n",
    "    # Bottom row for DARTS\n",
    "    for cell_idx in range(num_cells):\n",
    "        axes[1, cell_idx].set_title(f\"DARTS Cell {cell_idx+1}\", fontsize=16)\n",
    "    \n",
    "    # Save paths for individual visualizations\n",
    "    ppo_save_path = 'ppo_temp.png'\n",
    "    darts_save_path = 'darts_temp.png'\n",
    "    \n",
    "    # Generate the individual visualizations\n",
    "    visualize_ppo_architecture(ppo_architecture, num_cells, num_nodes, num_ops, ppo_save_path)\n",
    "    visualize_darts_architecture(darts_architecture, num_cells, num_nodes, num_ops, darts_save_path)\n",
    "    \n",
    "    # Create a combined visualization\n",
    "    from PIL import Image\n",
    "    ppo_img = Image.open(ppo_save_path)\n",
    "    darts_img = Image.open(darts_save_path)\n",
    "    \n",
    "    # Create a new combined image\n",
    "    combined_width = max(ppo_img.width, darts_img.width)\n",
    "    combined_height = ppo_img.height + darts_img.height + 50  # Extra space for title\n",
    "    combined_img = Image.new('RGB', (combined_width, combined_height), color='white')\n",
    "    \n",
    "    # Add title\n",
    "    from PIL import ImageDraw, ImageFont\n",
    "    draw = ImageDraw.Draw(combined_img)\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 36)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    draw.text((combined_width//2 - 200, 10), \"Architecture Comparison\", fill=\"black\", font=font)\n",
    "    \n",
    "    # Paste the individual images\n",
    "    combined_img.paste(ppo_img, (0, 50))\n",
    "    combined_img.paste(darts_img, (0, 50 + ppo_img.height))\n",
    "    \n",
    "    # Save the combined image\n",
    "    combined_img.save(save_path)\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    os.remove(ppo_save_path)\n",
    "    os.remove(darts_save_path)\n",
    "    \n",
    "    # Log to wandb if requested\n",
    "    if save_to_wandb:\n",
    "        try:\n",
    "            import wandb\n",
    "            if wandb.run is not None:\n",
    "                wandb.log({\"architecture_comparison\": wandb.Image(save_path)})\n",
    "        except ImportError:\n",
    "            print(\"Warning: wandb not installed, skipping wandb logging\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "\n",
    "def analyze_architecture_statistics(best_architecture, is_ppo=True, num_cells=3, num_nodes=4, num_ops=10):\n",
    "    \"\"\"\n",
    "    Analyze the statistics of the discovered architecture.\n",
    "    \n",
    "    Args:\n",
    "        best_architecture: The architecture tensor (PPO indices or DARTS weights)\n",
    "        is_ppo: Whether the architecture is from PPO (True) or DARTS (False)\n",
    "        num_cells: Number of cells\n",
    "        num_nodes: Number of nodes per cell\n",
    "        num_ops: Number of operations\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary of statistics about the architecture\n",
    "    \"\"\"\n",
    "    operation_names = [\n",
    "        'Conv 3x3', 'Conv 5x5', 'LSTM', 'Dilated Conv', 'Skip Connect',\n",
    "        'Self Attention', 'Separable Conv', 'Squeeze-Excitation', 'Frequency-Aware', 'Gated Conv'\n",
    "    ]\n",
    "    \n",
    "    # Calculate edges per cell\n",
    "    edges_per_cell = sum(range(1, num_nodes+1))\n",
    "    total_edges = num_cells * edges_per_cell\n",
    "    \n",
    "    # Initialize operation counts\n",
    "    op_counts = {op: 0 for op in operation_names}\n",
    "    \n",
    "    # Count operations by cell\n",
    "    op_counts_by_cell = []\n",
    "    for cell_idx in range(num_cells):\n",
    "        cell_op_counts = {op: 0 for op in operation_names}\n",
    "        edge_offset = cell_idx * edges_per_cell\n",
    "        \n",
    "        for edge_idx in range(edges_per_cell):\n",
    "            global_edge_idx = edge_offset + edge_idx\n",
    "            \n",
    "            if is_ppo:\n",
    "                # For PPO architecture (indices)\n",
    "                if global_edge_idx < len(best_architecture):\n",
    "                    op_idx = int(best_architecture[global_edge_idx].item())\n",
    "                    op_name = operation_names[op_idx]\n",
    "                    op_counts[op_name] += 1\n",
    "                    cell_op_counts[op_name] += 1\n",
    "            else:\n",
    "                # For DARTS architecture (weights)\n",
    "                if global_edge_idx < best_architecture.size(0):\n",
    "                    op_idx = torch.argmax(best_architecture[global_edge_idx]).item()\n",
    "                    op_name = operation_names[op_idx]\n",
    "                    op_counts[op_name] += 1\n",
    "                    cell_op_counts[op_name] += 1\n",
    "        \n",
    "        op_counts_by_cell.append(cell_op_counts)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total_ops = sum(op_counts.values())\n",
    "    op_percentages = {op: count/total_ops*100 for op, count in op_counts.items()}\n",
    "    \n",
    "    # Find most and least common operations\n",
    "    most_common_op = max(op_counts.items(), key=lambda x: x[1])[0]\n",
    "    least_common_op = min(op_counts.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Analyze patterns\n",
    "    patterns = {}\n",
    "    patterns[\"most_common_op\"] = most_common_op\n",
    "    patterns[\"most_common_percentage\"] = op_percentages[most_common_op]\n",
    "    patterns[\"least_common_op\"] = least_common_op\n",
    "    patterns[\"least_common_percentage\"] = op_percentages[least_common_op]\n",
    "    \n",
    "    # Check for cell-specific patterns\n",
    "    patterns[\"cell_specific_patterns\"] = []\n",
    "    for i, cell_counts in enumerate(op_counts_by_cell):\n",
    "        cell_total = sum(cell_counts.values())\n",
    "        if cell_total > 0:\n",
    "            cell_most_common = max(cell_counts.items(), key=lambda x: x[1])[0]\n",
    "            cell_percent = cell_counts[cell_most_common] / cell_total * 100\n",
    "            if cell_percent > 40:  # If an operation dominates a cell\n",
    "                patterns[\"cell_specific_patterns\"].append(\n",
    "                    f\"Cell {i+1} ({['Normal', 'Expand'][i%2]}) uses {cell_most_common} for {cell_percent:.1f}% of connections\"\n",
    "                )\n",
    "    \n",
    "    # Return combined statistics\n",
    "    statistics = {\n",
    "        \"operation_counts\": op_counts,\n",
    "        \"operation_percentages\": op_percentages,\n",
    "        \"patterns\": patterns,\n",
    "        \"by_cell\": op_counts_by_cell\n",
    "    }\n",
    "    \n",
    "    return statistics\n",
    "\n",
    "\n",
    "def plot_architecture_statistics(statistics, save_path='architecture_stats.png', save_to_wandb=False):\n",
    "    \"\"\"\n",
    "    Create visualizations of architecture statistics.\n",
    "    \n",
    "    Args:\n",
    "        statistics: Output from analyze_architecture_statistics\n",
    "        save_path: Path to save the visualization\n",
    "        save_to_wandb: Whether to log to wandb\n",
    "    \"\"\"\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot operation counts\n",
    "    op_counts = statistics[\"operation_counts\"]\n",
    "    sorted_ops = sorted(op_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    ops, counts = zip(*sorted_ops)\n",
    "    \n",
    "    axes[0].bar(ops, counts, color='skyblue')\n",
    "    axes[0].set_title('Operation Counts', fontsize=16)\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Annotate bars with counts\n",
    "    for i, v in enumerate(counts):\n",
    "        axes[0].text(i, v + 0.1, str(v), ha='center')\n",
    "    \n",
    "    # Plot operation percentages by cell\n",
    "    cell_data = statistics[\"by_cell\"]\n",
    "    cell_names = [f\"Cell {i+1}\\n({'Normal' if i%2==0 else 'Expand'})\" for i in range(len(cell_data))]\n",
    "    \n",
    "    # Get all operations used\n",
    "    all_ops = set()\n",
    "    for cell in cell_data:\n",
    "        for op, count in cell.items():\n",
    "            if count > 0:\n",
    "                all_ops.add(op)\n",
    "    \n",
    "    # Create a grouped bar chart\n",
    "    x = np.arange(len(cell_names))\n",
    "    width = 0.8 / len(all_ops)\n",
    "    \n",
    "    # Sort operations by overall frequency\n",
    "    sorted_all_ops = sorted(all_ops, key=lambda op: -statistics[\"operation_counts\"].get(op, 0))\n",
    "    \n",
    "    for i, op in enumerate(sorted_all_ops):\n",
    "        values = [cell.get(op, 0) for cell in cell_data]\n",
    "        offset = i * width - (len(all_ops) - 1) * width / 2\n",
    "        axes[1].bar(x + offset, values, width, label=op)\n",
    "    \n",
    "    axes[1].set_title('Operations by Cell Type', fontsize=16)\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(cell_names)\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].legend(loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Log to wandb if requested\n",
    "    if save_to_wandb:\n",
    "        try:\n",
    "            import wandb\n",
    "            if wandb.run is not None:\n",
    "                wandb.log({\"architecture_statistics\": wandb.Image(save_path)})\n",
    "        except ImportError:\n",
    "            print(\"Warning: wandb not installed, skipping wandb logging\")\n",
    "    \n",
    "    plt.close()\n",
    "    return save_path\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Example of using these functions with your model:\n",
    "    \n",
    "#     # 1. Load your best architecture from checkpoint\n",
    "#     checkpoint_path = 'best_hybrid_model.pth'\n",
    "    \n",
    "#     if os.path.exists(checkpoint_path):\n",
    "#         checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "#         # Check if it's a PPO or DARTS architecture\n",
    "#         if 'ppo_architecture' in checkpoint:\n",
    "#             # PPO architecture\n",
    "#             architecture = checkpoint['ppo_architecture']\n",
    "#             is_ppo = True\n",
    "#             best_mode = 'PPO'\n",
    "#         elif 'darts_alphas' in checkpoint:\n",
    "#             # DARTS architecture\n",
    "#             architecture = checkpoint['darts_alphas']\n",
    "#             is_ppo = False\n",
    "#             best_mode = 'DARTS'\n",
    "#         else:\n",
    "#             # Example random architecture for demonstration\n",
    "#             print(\"No architecture found in checkpoint, generating random example\")\n",
    "#             architecture = torch.randint(0, 10, (30,))\n",
    "#             is_ppo = True\n",
    "#             best_mode = 'Random'\n",
    "            \n",
    "#         # Visualize the architecture\n",
    "#         if is_ppo:\n",
    "#             save_path = visualize_ppo_architecture(architecture, save_to_wandb=True)\n",
    "#         else:\n",
    "#             save_path = visualize_darts_architecture(architecture, save_to_wandb=True)\n",
    "            \n",
    "#         print(f\"Architecture visualization saved to {save_path}\")\n",
    "        \n",
    "#         # Analyze architecture statistics\n",
    "#         stats = analyze_architecture_statistics(architecture, is_ppo=is_ppo)\n",
    "#         stats_path = plot_architecture_statistics(stats, save_to_wandb=True)\n",
    "        \n",
    "#         print(f\"Architecture statistics saved to {stats_path}\")\n",
    "        \n",
    "#         # Print key findings\n",
    "#         patterns = stats[\"patterns\"]\n",
    "#         print(f\"\\nArchitecture Analysis ({best_mode} architecture):\")\n",
    "#         print(f\"Most common operation: {patterns['most_common_op']} ({patterns['most_common_percentage']:.1f}%)\")\n",
    "#         print(f\"Least common operation: {patterns['least_common_op']} ({patterns['least_common_percentage']:.1f}%)\")\n",
    "        \n",
    "#         if patterns[\"cell_specific_patterns\"]:\n",
    "#             print(\"\\nCell-specific patterns:\")\n",
    "#             for pattern in patterns[\"cell_specific_patterns\"]:\n",
    "#                 print(f\"- {pattern}\")\n",
    "#     else:\n",
    "#         print(f\"Checkpoint file {checkpoint_path} not found.\")\n",
    "#         print(\"To visualize your architecture, run this script after training or modify the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.123259Z",
     "iopub.status.busy": "2025-04-19T00:04:12.123079Z",
     "iopub.status.idle": "2025-04-19T00:04:12.142166Z",
     "shell.execute_reply": "2025-04-19T00:04:12.141476Z",
     "shell.execute_reply.started": "2025-04-19T00:04:12.123246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PPO Controller for architecture search\n",
    "class PPOController(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64):\n",
    "        super(PPOController, self).__init__()\n",
    "        \n",
    "        # Print dimensions for debugging\n",
    "        print(f\"Initializing PPO controller with state_dim={state_dim}, action_dim={action_dim}\")\n",
    "        \n",
    "        # Actor network (policy)\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, action_dim)\n",
    "        )\n",
    "        \n",
    "        # Critic network (value function)\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, state):\n",
    "        # Returns action probabilities and estimated value\n",
    "        action_probs = F.softmax(self.actor(state), dim=-1)\n",
    "        value = self.critic(state)\n",
    "        return action_probs, value\n",
    "    \n",
    "    def act(self, state):\n",
    "        action_probs, _ = self.forward(state)\n",
    "        dist = Categorical(action_probs)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        return action.detach(), log_prob.detach()\n",
    "\n",
    "# PPO Training function\n",
    "def train_ppo(controller, optimizer, memories, clip_ratio=0.2, epochs=10, entropy_coef=0.01):\n",
    "    \"\"\"Train the PPO controller on collected experiences\"\"\"\n",
    "    # Unpack memories\n",
    "    states = torch.cat([m['state'] for m in memories])\n",
    "    actions = torch.cat([m['action'] for m in memories])\n",
    "    old_log_probs = torch.cat([m['log_prob'] for m in memories])\n",
    "    rewards = torch.cat([m['reward'] for m in memories])\n",
    "    \n",
    "    # Normalize rewards for stable training\n",
    "    if rewards.std() > 0:\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n",
    "    \n",
    "    # Store metrics for logging\n",
    "    metrics = {\n",
    "        'actor_loss': 0,\n",
    "        'critic_loss': 0,\n",
    "        'entropy_loss': 0\n",
    "    }\n",
    "    \n",
    "    # Train for multiple epochs\n",
    "    for _ in range(epochs):\n",
    "        # Evaluate current policy\n",
    "        log_probs = []\n",
    "        values = []\n",
    "        entropy = []\n",
    "        \n",
    "        for i in range(len(states)):\n",
    "            state_i = states[i:i+1]\n",
    "            action_i = actions[i]\n",
    "            \n",
    "            # Get action probabilities and value\n",
    "            action_probs, value = controller(state_i)\n",
    "            \n",
    "            # Create categorical distribution\n",
    "            dist = Categorical(action_probs)\n",
    "            \n",
    "            # Get log probability and entropy\n",
    "            log_prob = dist.log_prob(action_i)\n",
    "            entropy_i = dist.entropy()\n",
    "            \n",
    "            log_probs.append(log_prob)\n",
    "            values.append(value.squeeze())\n",
    "            entropy.append(entropy_i)\n",
    "        \n",
    "        # Stack results\n",
    "        log_probs = torch.stack(log_probs)\n",
    "        values = torch.stack(values)\n",
    "        entropy = torch.stack(entropy)\n",
    "        \n",
    "        # Compute ratio and surrogate loss\n",
    "        ratio = torch.exp(log_probs - old_log_probs)\n",
    "        surr1 = ratio * rewards\n",
    "        surr2 = torch.clamp(ratio, 1 - clip_ratio, 1 + clip_ratio) * rewards\n",
    "        \n",
    "        # PPO losses\n",
    "        actor_loss = -torch.min(surr1, surr2).mean()\n",
    "        critic_loss = F.mse_loss(values, rewards)\n",
    "        entropy_loss = -entropy.mean()\n",
    "        \n",
    "        # Total loss\n",
    "        loss = actor_loss + 0.5 * critic_loss - entropy_coef * entropy_loss\n",
    "        \n",
    "        # Update controller\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        metrics['actor_loss'] += actor_loss.item() / epochs\n",
    "        metrics['critic_loss'] += critic_loss.item() / epochs\n",
    "        metrics['entropy_loss'] += entropy_loss.item() / epochs\n",
    "    \n",
    "    return metrics['actor_loss'], metrics['critic_loss'], metrics['entropy_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.143066Z",
     "iopub.status.busy": "2025-04-19T00:04:12.142834Z",
     "iopub.status.idle": "2025-04-19T00:04:12.315200Z",
     "shell.execute_reply": "2025-04-19T00:04:12.314467Z",
     "shell.execute_reply.started": "2025-04-19T00:04:12.143052Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation helper function\n",
    "def evaluate_architecture(model, val_loader, device, architecture_weights=None, discrete=False):\n",
    "    \"\"\"Evaluate the performance of an architecture\"\"\"\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            try:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                if torch.isnan(inputs).any():\n",
    "                    inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "                \n",
    "                # Use the appropriate mode\n",
    "                if architecture_weights is not None:\n",
    "                    # PPO mode with external weights\n",
    "                    outputs = model(inputs, architecture_weights)\n",
    "                else:\n",
    "                    # DARTS mode with internal alphas\n",
    "                    outputs = model(inputs, discrete=discrete)\n",
    "                \n",
    "                scores = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_scores.extend(scores)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in evaluation: {e}\")\n",
    "                continue\n",
    "    \n",
    "    # Calculate EER with robust error handling\n",
    "    try:\n",
    "        if len(all_targets) > 0 and len(all_scores) > 0:\n",
    "            unique_targets = np.unique(all_targets)\n",
    "            if len(unique_targets) >= 2:\n",
    "                fpr, tpr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n",
    "                fnr = 1 - tpr\n",
    "                idx = np.nanargmin(np.absolute(fnr - fpr))\n",
    "                eer = (fpr[idx] + fnr[idx]) / 2\n",
    "            else:\n",
    "                eer = 0.5\n",
    "        else:\n",
    "            eer = 0.5\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating EER: {e}\")\n",
    "        eer = 0.5\n",
    "    \n",
    "    return eer\n",
    "\n",
    "# Hybrid PPO-DARTS search function\n",
    "def search_architecture_hybrid(train_loader, val_loader, device, input_channels=60, num_cells=3, \n",
    "                              num_nodes=4, num_ops=10, epochs=30, ppo_updates=5, \n",
    "                              project_name=\"deepfake-nas-hybrid\"):\n",
    "    \"\"\"Hybrid approach combining PPO for exploration with DARTS for optimization\"\"\"\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=project_name, name=f\"Hybrid_PPO_DARTS_cells{num_cells}_nodes{num_nodes}\")\n",
    "    \n",
    "    # Log hyperparameters\n",
    "    config = {\n",
    "        \"input_channels\": input_channels,\n",
    "        \"num_cells\": num_cells,\n",
    "        \"num_nodes\": num_nodes,\n",
    "        \"num_ops\": num_ops,\n",
    "        \"epochs\": epochs,\n",
    "        \"w_lr\": 0.001,        # Weight learning rate\n",
    "        \"alpha_lr\": 0.0003,   # Architecture parameter learning rate\n",
    "        \"ppo_lr\": 0.0005,     # PPO controller learning rate\n",
    "        \"ppo_updates\": ppo_updates,\n",
    "        \"exploration_ratio\": 0.3,  # Ratio of epochs to use PPO exploration\n",
    "        \"visualization_enabled\": True  # Enable visualization\n",
    "    }\n",
    "    wandb.config.update(config)\n",
    "    \n",
    "    # Initialize model with expanded operation set\n",
    "    model = DeepfakeDetectionModel(input_channels, num_cells, num_nodes, num_ops).to(device)\n",
    "    \n",
    "    # Calculate edges for PPO controller\n",
    "    edges_per_cell = sum(range(1, num_nodes+1))\n",
    "    total_edges = num_cells * edges_per_cell\n",
    "    \n",
    "    # Initialize PPO controller for exploration\n",
    "    state_dim = 1  # Single value for validation performance\n",
    "    action_dim = num_ops  # Number of operations per edge\n",
    "    controller = PPOController(state_dim, action_dim).to(device)\n",
    "    controller_optimizer = optim.Adam(controller.parameters(), lr=config[\"ppo_lr\"])\n",
    "    \n",
    "    # Setup optimizers for DARTS\n",
    "    w_optimizer = optim.Adam(model.weights(), lr=config[\"w_lr\"], weight_decay=3e-4)\n",
    "    w_scheduler = optim.lr_scheduler.CosineAnnealingLR(w_optimizer, epochs)\n",
    "    alpha_optimizer = optim.Adam(model.alphas(), lr=config[\"alpha_lr\"], betas=(0.5, 0.999), weight_decay=1e-3)\n",
    "    \n",
    "    # Metrics tracking\n",
    "    best_val_eer = 1.0\n",
    "    best_architecture = None\n",
    "    best_mode = None\n",
    "    \n",
    "    with tqdm(total=epochs, desc=\"Hybrid Search Progress\", position=0, leave=True) as epoch_pbar:\n",
    "        for epoch in range(epochs):\n",
    "            # Determine exploration mode for this epoch\n",
    "            # More exploration in early stages, more exploitation later\n",
    "            use_ppo = (random.random() < config[\"exploration_ratio\"] * (1 - epoch/epochs))\n",
    "            \n",
    "            # PPO exploration phase\n",
    "            if use_ppo:\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                # For PPO\n",
    "                memories = []\n",
    "                current_architecture = []\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                # Sample architecture using PPO\n",
    "                for i in range(total_edges):\n",
    "                    # Use current validation EER as state\n",
    "                    state = torch.FloatTensor([min(best_val_eer, 0.5) * 2]).to(device)\n",
    "                    \n",
    "                    # Sample architecture weights for this edge\n",
    "                    for j in range(num_ops):\n",
    "                        action, log_prob = controller.act(state)\n",
    "                        current_architecture.append(action.item())\n",
    "                        \n",
    "                        # Store experience for PPO\n",
    "                        memories.append({\n",
    "                            'state': state.clone(),\n",
    "                            'action': action.unsqueeze(0),\n",
    "                            'log_prob': log_prob.unsqueeze(0),\n",
    "                            'reward': torch.zeros(1).to(device)  # Updated later\n",
    "                        })\n",
    "                \n",
    "                # Convert architecture to tensor for PPO mode\n",
    "                architecture_weights = torch.FloatTensor(current_architecture).to(device)\n",
    "                \n",
    "                # Train model with PPO-generated architecture\n",
    "                for inputs, targets in train_loader:\n",
    "                    batch_count += 1\n",
    "                    if batch_count % 10 == 0:\n",
    "                        print(f\"\\rPPO Training batch {batch_count}/{len(train_loader)}\", end=\"\")\n",
    "                    \n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    if torch.isnan(inputs).any():\n",
    "                        inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "                    \n",
    "                    # Update weights\n",
    "                    w_optimizer.zero_grad()\n",
    "                    outputs = model(inputs, architecture_weights)  # Use PPO architecture\n",
    "                    loss = F.cross_entropy(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.weights(), max_norm=1.0)\n",
    "                    w_optimizer.step()\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                \n",
    "                print()  # Line break after training\n",
    "                \n",
    "                # Evaluate architecture from PPO\n",
    "                val_eer = evaluate_architecture(model, val_loader, device, architecture_weights)\n",
    "                \n",
    "                # Update PPO controller based on performance\n",
    "                reward = best_val_eer - val_eer if val_eer < best_val_eer else 0\n",
    "                for memory in memories:\n",
    "                    memory['reward'] = torch.FloatTensor([reward]).to(device)\n",
    "                \n",
    "                # Update best architecture if improved\n",
    "                if val_eer < best_val_eer:\n",
    "                    best_val_eer = val_eer\n",
    "                    best_architecture = architecture_weights.clone()\n",
    "                    best_mode = 'ppo'\n",
    "                    print(f\"\\nNew best architecture found via PPO! EER: {best_val_eer:.4f}\")\n",
    "                \n",
    "                # Update PPO controller\n",
    "                if epoch % config[\"ppo_updates\"] == 0 and memories:\n",
    "                    actor_loss, critic_loss, entropy_loss = train_ppo(\n",
    "                        controller, controller_optimizer, memories)\n",
    "                    \n",
    "                    # Log PPO metrics\n",
    "                    wandb.log({\n",
    "                        \"actor_loss\": actor_loss,\n",
    "                        \"critic_loss\": critic_loss,\n",
    "                        \"entropy_loss\": entropy_loss\n",
    "                    })\n",
    "            \n",
    "            # DARTS optimization phase\n",
    "            else:\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "                batch_count = 0\n",
    "                \n",
    "                # Phase 1: Train model weights using DARTS approach\n",
    "                for inputs, targets in train_loader:\n",
    "                    batch_count += 1\n",
    "                    if batch_count % 10 == 0:\n",
    "                        print(f\"\\rDARTS Weight Training batch {batch_count}/{len(train_loader)}\", end=\"\")\n",
    "                    \n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    if torch.isnan(inputs).any():\n",
    "                        inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "                    \n",
    "                    # Update weights with internal alphas\n",
    "                    w_optimizer.zero_grad()\n",
    "                    outputs = model(inputs)  # Use alphas without external weights\n",
    "                    loss = F.cross_entropy(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.weights(), max_norm=1.0)\n",
    "                    w_optimizer.step()\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                \n",
    "                print()  # Line break after training\n",
    "                \n",
    "                # Phase 2: Update architecture parameters on validation set\n",
    "                model.train()  # Keep in train mode for alpha updates\n",
    "                val_batch_count = 0\n",
    "                \n",
    "                for inputs, targets in val_loader:\n",
    "                    # Use a subset of validation data\n",
    "                    if random.random() > 0.2:  # Sample ~20% for alpha updates\n",
    "                        continue\n",
    "                        \n",
    "                    val_batch_count += 1\n",
    "                    if val_batch_count > 50:  # Limit validation batches for speed\n",
    "                        break\n",
    "                    \n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    if torch.isnan(inputs).any():\n",
    "                        inputs = torch.nan_to_num(inputs, nan=0.0)\n",
    "                    \n",
    "                    # Update alphas\n",
    "                    alpha_optimizer.zero_grad()\n",
    "                    outputs = model(inputs)  # Use internal alphas\n",
    "                    loss = F.cross_entropy(outputs, targets)\n",
    "                    loss.backward()\n",
    "                    alpha_optimizer.step()\n",
    "                \n",
    "                # Evaluate DARTS architecture\n",
    "                val_eer = evaluate_architecture(model, val_loader, device, discrete=True)\n",
    "                \n",
    "                # Update best architecture if improved\n",
    "                if val_eer < best_val_eer:\n",
    "                    best_val_eer = val_eer\n",
    "                    # Save alphas as best architecture\n",
    "                    best_architecture = model._alphas.detach().clone()\n",
    "                    best_mode = 'darts'\n",
    "                    print(f\"\\nNew best architecture found via DARTS! EER: {best_val_eer:.4f}\")\n",
    "            \n",
    "            # Update learning rate for weights\n",
    "            w_scheduler.step()\n",
    "            \n",
    "            # Update epoch progress bar\n",
    "            epoch_pbar.update(1)\n",
    "            epoch_pbar.set_postfix({\n",
    "                \"Mode\": \"PPO\" if use_ppo else \"DARTS\",\n",
    "                \"Val EER\": f\"{val_eer:.4f}\",\n",
    "                \"Best EER\": f\"{best_val_eer:.4f}\"\n",
    "            })\n",
    "            \n",
    "            # Log metrics to wandb\n",
    "            avg_train_loss = train_loss / max(batch_count, 1)\n",
    "            wandb.log({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": avg_train_loss,\n",
    "                \"val_eer\": val_eer,\n",
    "                \"best_val_eer\": best_val_eer,\n",
    "                \"mode\": \"PPO\" if use_ppo else \"DARTS\",\n",
    "                \"learning_rate\": w_optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "            \n",
    "            # Save checkpoint for the best model\n",
    "            if val_eer <= best_val_eer:\n",
    "                checkpoint_path = 'best_hybrid_model.pth'\n",
    "                if use_ppo:\n",
    "                    # Save PPO-generated architecture\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'ppo_architecture': best_architecture,\n",
    "                        'eer': best_val_eer,\n",
    "                        'epoch': epoch + 1,\n",
    "                        'mode': 'PPO'\n",
    "                    }, checkpoint_path)\n",
    "                    # Add visualization during training\n",
    "                    if epoch % 5 == 0:  # Only create visualizations periodically to save time\n",
    "                        vis_path = visualize_ppo_architecture(\n",
    "                        best_architecture, \n",
    "                        num_cells=num_cells,\n",
    "                        num_nodes=num_nodes,\n",
    "                        num_ops=num_ops,\n",
    "                        save_path=f\"ppo_arch_epoch_{epoch}.png\",\n",
    "                        save_to_wandb=True\n",
    "                        )\n",
    "                else:\n",
    "                    # Save DARTS-generated architecture\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'darts_alphas': model._alphas,\n",
    "                        'eer': best_val_eer,\n",
    "                        'epoch': epoch + 1,\n",
    "                        'mode': 'DARTS'\n",
    "                    }, checkpoint_path)\n",
    "                    # Add visualization during training\n",
    "                    if epoch % 5 == 0:  # Only create visualizations periodically\n",
    "                        vis_path = visualize_darts_architecture(\n",
    "                        model._alphas,\n",
    "                        num_cells=num_cells,\n",
    "                        num_nodes=num_nodes, \n",
    "                        num_ops=num_ops,\n",
    "                        save_path=f\"darts_arch_epoch_{epoch}.png\",\n",
    "                        save_to_wandb=True\n",
    "                        )\n",
    "                \n",
    "                # Log best model to wandb\n",
    "                wandb.save(checkpoint_path)\n",
    "    \n",
    "    # Finish wandb run\n",
    "    wandb.finish()\n",
    "    \n",
    "    # Return the best architecture (either from PPO or DARTS)\n",
    "    final_model = model\n",
    "    final_architecture = best_architecture\n",
    "    \n",
    "    return final_model, final_architecture, best_val_eer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.317260Z",
     "iopub.status.busy": "2025-04-19T00:04:12.316941Z",
     "iopub.status.idle": "2025-04-19T00:04:12.336294Z",
     "shell.execute_reply": "2025-04-19T00:04:12.335720Z",
     "shell.execute_reply.started": "2025-04-19T00:04:12.317235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, architecture, test_loader, device, log_to_wandb=True):\n",
    "    \"\"\"Evaluate the model with the best architecture\"\"\"\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_scores = []\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Determine if architecture is from PPO or DARTS\n",
    "    is_ppo_arch = architecture.dim() == 1\n",
    "    \n",
    "    # Create a progress bar for evaluation\n",
    "    eval_pbar = tqdm(test_loader, desc=\"Evaluating\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in eval_pbar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Choose correct evaluation mode\n",
    "            if is_ppo_arch:\n",
    "                # PPO architecture\n",
    "                outputs = model(inputs, architecture)\n",
    "            else:\n",
    "                # DARTS architecture - set model's alphas and use discrete mode\n",
    "                model._alphas.data = architecture.data\n",
    "                outputs = model(inputs, discrete=True)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = F.cross_entropy(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Compute accuracy\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            \n",
    "            # Get scores for EER calculation\n",
    "            scores = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_scores.extend(scores)\n",
    "            \n",
    "            # Update progress bar\n",
    "            eval_pbar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.4f}\",\n",
    "                \"accuracy\": f\"{100.0 * correct / total:.2f}%\"\n",
    "            })\n",
    "    \n",
    "    # Calculate test accuracy\n",
    "    test_accuracy = 100.0 * correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    \n",
    "    # Calculate EER\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n",
    "        fnr = 1 - tpr\n",
    "        idx = np.nanargmin(np.absolute(fnr - fpr))\n",
    "        eer = (fpr[idx] + fnr[idx]) / 2\n",
    "        eer_threshold = thresholds[idx]\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating EER: {e}\")\n",
    "        eer = 0.5\n",
    "        eer_threshold = 0.5\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(fpr, tpr, label=f'ROC Curve (EER = {eer:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Deepfake Detection')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Save ROC curve\n",
    "    roc_curve_path = 'roc_curve.png'\n",
    "    plt.savefig(roc_curve_path)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nTest Results - Loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, EER: {eer:.4f}\")\n",
    "    \n",
    "    # Log to wandb if requested\n",
    "    if log_to_wandb and wandb.run is not None:\n",
    "        wandb.log({\n",
    "            \"test_loss\": avg_test_loss,\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"test_eer\": eer,\n",
    "            \"eer_threshold\": eer_threshold,\n",
    "            \"roc_curve\": wandb.Image(roc_curve_path)\n",
    "        })\n",
    "        \n",
    "        # Log confusion matrix\n",
    "        cm = np.zeros((2, 2))\n",
    "        for i in range(len(all_targets)):\n",
    "            pred_class = 1 if all_scores[i] > eer_threshold else 0\n",
    "            cm[all_targets[i]][pred_class] += 1\n",
    "        \n",
    "        # Normalize confusion matrix\n",
    "        cm_norm = cm / np.maximum(cm.sum(axis=1, keepdims=True), 1e-8)\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm_norm, cmap='Blues')\n",
    "        plt.colorbar()\n",
    "        plt.title('Normalized Confusion Matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.xticks([0, 1], ['Bonafide', 'Spoof'])\n",
    "        plt.yticks([0, 1], ['Bonafide', 'Spoof'])\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                plt.text(j, i, f'{cm[i, j]:.0f}\\n({cm_norm[i, j]:.2f})', \n",
    "                         ha='center', va='center', \n",
    "                         color='white' if cm_norm[i, j] > 0.5 else 'black')\n",
    "        \n",
    "        cm_path = 'confusion_matrix.png'\n",
    "        plt.savefig(cm_path)\n",
    "        wandb.log({\"confusion_matrix\": wandb.Image(cm_path)})\n",
    "    \n",
    "    return eer, eer_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# Architecture Visualization\n",
    "# ===========================\n",
    "print(\"Visualizing discovered architectures...\")\n",
    "\n",
    "# Add the visualization code here\n",
    "# [Insert the entire visualization code I provided]\n",
    "\n",
    "# Then add the usage code:\n",
    "if wandb.run is not None:\n",
    "    print(\"Generating visualizations for best architecture...\")\n",
    "    \n",
    "    # Load best architecture from checkpoint\n",
    "    checkpoint_path = 'best_hybrid_model.pth'\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        \n",
    "        # Determine architecture type\n",
    "        if 'ppo_architecture' in checkpoint:\n",
    "            architecture = checkpoint['ppo_architecture']\n",
    "            is_ppo = True\n",
    "            best_mode = 'PPO'\n",
    "        elif 'darts_alphas' in checkpoint:\n",
    "            architecture = checkpoint['darts_alphas']\n",
    "            is_ppo = False\n",
    "            best_mode = 'DARTS'\n",
    "        \n",
    "        # Create visualizations\n",
    "        if is_ppo:\n",
    "            save_path = visualize_ppo_architecture(architecture, save_to_wandb=True)\n",
    "        else:\n",
    "            save_path = visualize_darts_architecture(architecture, save_to_wandb=True)\n",
    "            \n",
    "        # Analyze architecture statistics\n",
    "        stats = analyze_architecture_statistics(architecture, is_ppo=is_ppo)\n",
    "        plot_architecture_statistics(stats, save_to_wandb=True)\n",
    "        \n",
    "        # Print key findings\n",
    "        patterns = stats[\"patterns\"]\n",
    "        print(f\"Architecture Analysis ({best_mode}):\")\n",
    "        print(f\"Most common operation: {patterns['most_common_op']} ({patterns['most_common_percentage']:.1f}%)\")\n",
    "        \n",
    "        if patterns[\"cell_specific_patterns\"]:\n",
    "            print(\"Cell-specific patterns detected!\")\n",
    "    else:\n",
    "        print(f\"Checkpoint file {checkpoint_path} not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-19T00:04:12.337204Z",
     "iopub.status.busy": "2025-04-19T00:04:12.337020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrnparikh\u001b[0m (\u001b[33mrnparikh-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource monitoring started...\n",
      "Starting Deepfake Audio Detection with NAS\n",
      "================================================================================\n",
      "Train data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_train/flac\n",
      "Train protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\n",
      "Dev data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_dev/flac\n",
      "Dev protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\n",
      "Eval data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_eval/flac\n",
      "Eval protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:02:37] CPU: 1.0% | RAM: 638.5 MB | GPU: 0.0 MBB"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250419_000412-j1tgeeeb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rnparikh-carnegie-mellon-university/ASVspoof2019-NAS/runs/j1tgeeeb' target=\"_blank\">ASVspoof2019_NAS_1745021052_hybrid</a></strong> to <a href='https://wandb.ai/rnparikh-carnegie-mellon-university/ASVspoof2019-NAS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rnparikh-carnegie-mellon-university/ASVspoof2019-NAS' target=\"_blank\">https://wandb.ai/rnparikh-carnegie-mellon-university/ASVspoof2019-NAS</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rnparikh-carnegie-mellon-university/ASVspoof2019-NAS/runs/j1tgeeeb' target=\"_blank\">https://wandb.ai/rnparikh-carnegie-mellon-university/ASVspoof2019-NAS/runs/j1tgeeeb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:07] CPU: 42.0% | RAM: 639.7 MB | GPU: 0.0 MBCreating datasets...\n",
      "Loading training dataset...\n",
      "Reading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training protocol: 100%|| 25380/25380 [00:00<00:00, 1475357.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 25380 samples (2580 bonafide, 22800 spoof)\n",
      "Subsampling training data for faster NAS...\n",
      "Subsampled to 5000 samples\n",
      "Loading validation dataset...\n",
      "Reading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading evaluation protocol: 100%|| 24844/24844 [00:00<00:00, 1630494.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 24844 samples (2548 bonafide, 22296 spoof)\n",
      "Loading evaluation dataset...\n",
      "Reading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading evaluation protocol: 100%|| 71237/71237 [00:00<00:00, 1495518.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 71237 samples (7355 bonafide, 63882 spoof)\n",
      "Training dataset size: 5000 samples\n",
      "Validation dataset size: 24844 samples\n",
      "Evaluation dataset size: 71237 samples\n",
      "\n",
      "Neural Architecture Search Configuration:\n",
      "  input_channels: 60\n",
      "  num_cells: 3\n",
      "  num_nodes: 4\n",
      "  num_ops: 10\n",
      "  epochs: 30\n",
      "  ppo_updates: 5\n",
      "  project_name: ASVspoof2019-NAS\n",
      "\n",
      "Results will be saved to /kaggle/working/results_ASVspoof2019_NAS_1745021052_hybrid\n",
      "\n",
      "Starting Neural Architecture Search using HYBRID method...\n",
      "Initializing PPO controller with state_dim=1, action_dim=10\n",
      "[00:03:13] CPU: 83.7% | RAM: 881.6 MB | GPU: 15.9 MB"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hybrid Search Progress:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:13] CPU: 101.0% | RAM: 1431.5 MB | GPU: 1156.5 MB"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_curve\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import random\n",
    "from torch.distributions import Categorical\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def setup_progress_monitoring():\n",
    "    \"\"\"Setup enhanced progress monitoring\"\"\"\n",
    "    import threading\n",
    "    import time\n",
    "    import psutil\n",
    "    import os\n",
    "    \n",
    "    def monitor_resources():\n",
    "        process = psutil.Process(os.getpid())\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                # CPU usage\n",
    "                cpu_percent = process.cpu_percent(interval=1)\n",
    "                # Memory usage\n",
    "                memory_info = process.memory_info()\n",
    "                memory_mb = memory_info.rss / (1024 * 1024)\n",
    "                # GPU memory if available\n",
    "                gpu_memory_mb = 0\n",
    "                try:\n",
    "                    if torch.cuda.is_available():\n",
    "                        gpu_memory_mb = torch.cuda.memory_allocated() / (1024 * 1024)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                hours, remainder = divmod(elapsed, 3600)\n",
    "                minutes, seconds = divmod(remainder, 60)\n",
    "                \n",
    "                print(f\"\\r[{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}] \"\n",
    "                      f\"CPU: {cpu_percent:.1f}% | RAM: {memory_mb:.1f} MB | \"\n",
    "                      f\"GPU: {gpu_memory_mb:.1f} MB\", end=\"\", flush=True)\n",
    "                \n",
    "                time.sleep(5)  # Update every 5 seconds\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "    # Start monitoring in a background thread\n",
    "    monitor_thread = threading.Thread(target=monitor_resources, daemon=True)\n",
    "    monitor_thread.start()\n",
    "    print(\"Resource monitoring started...\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Main function follows\n",
    "def main():\n",
    "    # Start the resource monitoring first\n",
    "    setup_progress_monitoring()\n",
    "    \n",
    "    # Then set the random seed\n",
    "    set_seed()\n",
    "    \n",
    "    # Import time for experiment naming\n",
    "    import time\n",
    "    import os\n",
    "    \n",
    "    # Initialize wandb for the entire experiment\n",
    "    experiment_name = f\"ASVspoof2019_NAS_{int(time.time())}\"\n",
    "    \n",
    "    print(\"Starting Deepfake Audio Detection with NAS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Paths and parameters (based on the provided dataset structure)\n",
    "    base_dir = \"/kaggle/input/asvspoof-dataset-2019\"\n",
    "    data_dir_train = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_train\", \"flac\")\n",
    "    data_dir_dev = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_dev\", \"flac\")\n",
    "    data_dir_eval = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_eval\", \"flac\")\n",
    "    \n",
    "    train_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.train.trn.txt\")\n",
    "    dev_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.dev.trl.txt\")\n",
    "    eval_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.eval.trl.txt\")\n",
    "    \n",
    "    # Log dataset information\n",
    "    print(f\"Train data directory: {data_dir_train}\")\n",
    "    print(f\"Train protocol file: {train_protocol}\")\n",
    "    print(f\"Dev data directory: {data_dir_dev}\")\n",
    "    print(f\"Dev protocol file: {dev_protocol}\")\n",
    "    print(f\"Eval data directory: {data_dir_eval}\")\n",
    "    print(f\"Eval protocol file: {eval_protocol}\")\n",
    "    \n",
    "    # Experiment configuration\n",
    "    feature_type = 'mfcc'  # Options: 'mfcc', 'spec', 'cqt'\n",
    "    max_seq_len = 400\n",
    "    batch_size_train = 32\n",
    "    batch_size_eval = 64\n",
    "    num_workers = 4\n",
    "    \n",
    "    # Select search method: 'hybrid' for PPO+DARTS\n",
    "    search_method = 'hybrid'\n",
    "\n",
    "    # Initialize wandb with your API key (replace with your actual key)\n",
    "    wandb.login(key=\"\")\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"ASVspoof2019-NAS\",\n",
    "        name=f\"{experiment_name}_{search_method}\",\n",
    "        config={\n",
    "            \"feature_type\": feature_type,\n",
    "            \"max_sequence_length\": max_seq_len,\n",
    "            \"batch_size_train\": batch_size_train,\n",
    "            \"batch_size_eval\": batch_size_eval,\n",
    "            \"num_workers\": num_workers,\n",
    "            \"dataset\": \"ASVspoof2019 LA\",\n",
    "            \"search_method\": search_method\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Creating datasets...\")\n",
    "    \n",
    "    print(\"Loading training dataset...\")\n",
    "    train_dataset = ASVSpoofDataset(\n",
    "        root_dir=data_dir_train,\n",
    "        protocol_file=train_protocol,\n",
    "        feature_type=feature_type,\n",
    "        max_len=max_seq_len,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    print(\"Loading validation dataset...\")\n",
    "    dev_dataset = ASVSpoofDataset(\n",
    "        root_dir=data_dir_dev,\n",
    "        protocol_file=dev_protocol,\n",
    "        feature_type=feature_type,\n",
    "        max_len=max_seq_len,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    print(\"Loading evaluation dataset...\")\n",
    "    eval_dataset = ASVSpoofDataset(\n",
    "        root_dir=data_dir_eval,\n",
    "        protocol_file=eval_protocol,\n",
    "        feature_type=feature_type,\n",
    "        max_len=max_seq_len,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # Log dataset sizes\n",
    "    print(f\"Training dataset size: {len(train_dataset)} samples\")\n",
    "    print(f\"Validation dataset size: {len(dev_dataset)} samples\")\n",
    "    print(f\"Evaluation dataset size: {len(eval_dataset)} samples\")\n",
    "    wandb.log({\n",
    "        \"train_dataset_size\": len(train_dataset),\n",
    "        \"val_dataset_size\": len(dev_dataset),\n",
    "        \"eval_dataset_size\": len(eval_dataset)\n",
    "    })\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size_train, \n",
    "        shuffle=True, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    dev_loader = DataLoader(\n",
    "        dev_dataset, \n",
    "        batch_size=batch_size_eval, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    eval_loader = DataLoader(\n",
    "        eval_dataset, \n",
    "        batch_size=batch_size_eval, \n",
    "        shuffle=False, \n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Architecture search parameters\n",
    "    nas_config = {\n",
    "        \"input_channels\": 60,  # 20 MFCCs x 3 (static, delta, delta-delta)\n",
    "        \"num_cells\": 3,\n",
    "        \"num_nodes\": 4,\n",
    "        \"num_ops\": 10,  # Expanded to 10 operations\n",
    "        \"epochs\": 30,\n",
    "        \"ppo_updates\": 5,\n",
    "        \"project_name\": \"ASVspoof2019-NAS\"\n",
    "    }\n",
    "    \n",
    "    # Log NAS configuration\n",
    "    print(\"\\nNeural Architecture Search Configuration:\")\n",
    "    for key, value in nas_config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Create output directory for results\n",
    "    output_dir = f\"/kaggle/working/results_{experiment_name}_{search_method}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\nResults will be saved to {output_dir}\")\n",
    "    \n",
    "    # Perform architecture search using hybrid PPO-DARTS approach\n",
    "    print(f\"\\nStarting Neural Architecture Search using {search_method.upper()} method...\")\n",
    "    \n",
    "    model, best_architecture, best_val_eer = search_architecture_hybrid(\n",
    "        train_loader=train_loader,\n",
    "        val_loader=dev_loader,\n",
    "        device=device,\n",
    "        input_channels=nas_config[\"input_channels\"],\n",
    "        num_cells=nas_config[\"num_cells\"],\n",
    "        num_nodes=nas_config[\"num_nodes\"],\n",
    "        num_ops=nas_config[\"num_ops\"],\n",
    "        epochs=nas_config[\"epochs\"],\n",
    "        ppo_updates=nas_config[\"ppo_updates\"],\n",
    "        project_name=nas_config[\"project_name\"] + \"-hybrid\"\n",
    "    )\n",
    "    \n",
    "    # Save best architecture\n",
    "    torch.save(best_architecture, os.path.join(output_dir, \"best_architecture.pt\"))\n",
    "    \n",
    "    # Initialize a new wandb run for final evaluation\n",
    "    wandb.finish()  # Finish the NAS run\n",
    "    wandb.init(\n",
    "        project=\"ASVspoof2019-NAS\",\n",
    "        name=f\"{experiment_name}_{search_method}_final_evaluation\",\n",
    "        config={\n",
    "            \"feature_type\": feature_type,\n",
    "            \"best_val_eer\": best_val_eer,\n",
    "            \"search_method\": search_method\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Evaluate on the evaluation set\n",
    "    print(\"\\nPerforming final evaluation on test set...\")\n",
    "    test_eer, eer_threshold = evaluate_model(model, best_architecture, eval_loader, device)\n",
    "    \n",
    "    # Log final metrics\n",
    "    wandb.log({\n",
    "        \"final_test_eer\": test_eer,\n",
    "        \"eer_threshold\": eer_threshold\n",
    "    })\n",
    "    \n",
    "    # Visualize the architecture with annotations\n",
    "    print(\"\\nVisualizing the best architecture...\")\n",
    "    # Check if it's a PPO or DARTS architecture\n",
    "    is_ppo_arch = best_architecture.dim() == 1\n",
    "    \n",
    "    if is_ppo_arch:\n",
    "        fig_path = visualize_architecture(best_architecture, \n",
    "                                     num_cells=nas_config[\"num_cells\"], \n",
    "                                     num_nodes=nas_config[\"num_nodes\"], \n",
    "                                     num_ops=nas_config[\"num_ops\"],\n",
    "                                     save_to_wandb=True)\n",
    "    else:\n",
    "        fig_path = visualize_darts_architecture(best_architecture, \n",
    "                                          num_cells=nas_config[\"num_cells\"], \n",
    "                                          num_nodes=nas_config[\"num_nodes\"], \n",
    "                                          num_ops=nas_config[\"num_ops\"],\n",
    "                                          save_to_wandb=True)\n",
    "    \n",
    "    # Save architecture visualization\n",
    "    import shutil\n",
    "    shutil.copy(fig_path, os.path.join(output_dir, \"architecture_visualization.png\"))\n",
    "    \n",
    "    # Create a summary report\n",
    "    summary = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"search_method\": search_method,\n",
    "        \"feature_type\": feature_type,\n",
    "        \"best_validation_eer\": best_val_eer,\n",
    "        \"test_eer\": test_eer,\n",
    "        \"eer_threshold\": eer_threshold,\n",
    "        \"model_architecture\": {\n",
    "            \"num_cells\": nas_config[\"num_cells\"],\n",
    "            \"num_nodes\": nas_config[\"num_nodes\"],\n",
    "            \"num_operations\": nas_config[\"num_ops\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save summary as JSON\n",
    "    import json\n",
    "    with open(os.path.join(output_dir, \"summary.json\"), \"w\") as f:\n",
    "        json.dump(summary, f, indent=4)\n",
    "    \n",
    "    # Also save as text for easy reading\n",
    "    with open(os.path.join(output_dir, \"summary.txt\"), \"w\") as f:\n",
    "        f.write(\"ASVspoof 2019 Deepfake Detection Summary\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(f\"Experiment name: {experiment_name}\\n\")\n",
    "        f.write(f\"Search method: {search_method.upper()}\\n\")\n",
    "        f.write(f\"Feature type: {feature_type}\\n\\n\")\n",
    "        f.write(\"Performance metrics:\\n\")\n",
    "        f.write(f\"  Best validation EER: {best_val_eer:.4f}\\n\")\n",
    "        f.write(f\"  Test EER: {test_eer:.4f}\\n\")\n",
    "        f.write(f\"  EER threshold: {eer_threshold:.4f}\\n\\n\")\n",
    "        f.write(\"Model architecture:\\n\")\n",
    "        f.write(f\"  Number of cells: {nas_config['num_cells']}\\n\")\n",
    "        f.write(f\"  Number of nodes per cell: {nas_config['num_nodes']}\\n\")\n",
    "        f.write(f\"  Number of operations: {nas_config['num_ops']}\\n\")\n",
    "    \n",
    "    # Log summary to wandb\n",
    "    wandb.save(os.path.join(output_dir, \"summary.txt\"))\n",
    "    wandb.save(os.path.join(output_dir, \"summary.json\"))\n",
    "    \n",
    "    print(\"\\nExperiment completed!\")\n",
    "    print(f\"Final Test EER: {test_eer:.4f}, EER Threshold: {eer_threshold:.4f}\")\n",
    "    print(f\"All results saved to {output_dir}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Finish wandb\n",
    "    wandb.finish()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6891325,
     "sourceId": 11060404,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
