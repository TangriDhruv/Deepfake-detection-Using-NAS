{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11060404,"sourceType":"datasetVersion","datasetId":6891325}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import roc_curve\nimport soundfile as sf\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport librosa\nimport random\nfrom torch.distributions import Categorical\nimport wandb\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T22:58:15.249598Z","iopub.execute_input":"2025-04-14T22:58:15.249842Z","iopub.status.idle":"2025-04-14T22:58:22.981902Z","shell.execute_reply.started":"2025-04-14T22:58:15.249823Z","shell.execute_reply":"2025-04-14T22:58:22.981392Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ASVSpoofDataset(Dataset):\n    def __init__(self, root_dir, protocol_file, feature_type='mfcc', max_len=None, is_train=True):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the audio files.\n            protocol_file (string): Path to the protocol file.\n            feature_type (string): Type of features to extract ('mfcc', 'spec', 'cqt').\n            max_len (int): Maximum length of features sequence.\n            is_train (bool): Whether this is for training or testing.\n        \"\"\"\n        self.root_dir = root_dir\n        self.feature_type = feature_type\n        self.max_len = max_len\n        self.is_train = is_train\n        \n        # Read protocol file\n        self.data = []\n        \n        print(f\"Reading protocol file: {protocol_file}\")\n        try:\n            with open(protocol_file, 'r') as f:\n                lines = f.readlines()\n                \n                # Use tqdm for loading progress\n                for line in tqdm(lines, desc=f\"Loading {'training' if is_train else 'evaluation'} protocol\"):\n                    parts = line.strip().split()\n                    if len(parts) >= 5:\n                        speaker_id = parts[0]\n                        file_id = parts[1]\n                        label_text = parts[4]\n                        label = 1 if label_text == 'bonafide' else 0  # 0 for bonafide, 1 for spoof\n                        self.data.append((file_id, label))\n            \n            # Count number of bonafide and spoof samples\n            bonafide_count = sum(1 for _, label in self.data if label == 0)\n            spoof_count = sum(1 for _, label in self.data if label == 1)\n            \n            print(f\"Dataset loaded: {len(self.data)} samples ({bonafide_count} bonafide, {spoof_count} spoof)\")\n            \n            if is_train:\n                # Subsample for faster NAS\n                if len(self.data) > 5000:\n                    print(f\"Subsampling training data for faster NAS...\")\n                    np.random.shuffle(self.data)\n                    # Keep balanced class distribution\n                    bonafide_samples = [item for item in self.data if item[1] == 0][:2500]\n                    spoof_samples = [item for item in self.data if item[1] == 1][:2500]\n                    self.data = bonafide_samples + spoof_samples\n                    np.random.shuffle(self.data)\n                    print(f\"Subsampled to {len(self.data)} samples\")\n        \n        except Exception as e:\n            print(f\"Error loading protocol file: {e}\")\n            self.data = []\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        file_id, label = self.data[idx]\n        audio_path = os.path.join(self.root_dir, f\"{file_id}.flac\")\n        \n        try:\n            audio, sr = sf.read(audio_path)\n            \n            # Feature extraction\n            if self.feature_type == 'mfcc':\n                features = extract_mfcc(audio, sr)\n            elif self.feature_type == 'spec':\n                features = extract_spec(audio, sr)\n            elif self.feature_type == 'cqt':\n                features = extract_cqt(audio, sr)\n            else:\n                raise ValueError(f\"Unknown feature type: {self.feature_type}\")\n            \n            # Normalize features\n            features = (features - np.mean(features)) / (np.std(features) + 1e-8)\n            \n            # Handle sequence length\n            seq_len = features.shape[1]\n            if self.max_len is not None:\n                if seq_len > self.max_len:\n                    start = np.random.randint(0, seq_len - self.max_len) if self.is_train else 0\n                    features = features[:, start:start+self.max_len]\n                elif seq_len < self.max_len:\n                    # Pad with zeros\n                    pad_width = ((0, 0), (0, self.max_len - seq_len))\n                    features = np.pad(features, pad_width, mode='constant')\n            \n            return torch.FloatTensor(features), torch.LongTensor([label])[0]\n            \n        except Exception as e:\n            print(f\"Error loading {audio_path}: {e}\")\n            # Return a dummy sample in case of error\n            dummy_features = np.zeros((60, 100 if self.max_len is None else self.max_len))\n            return torch.FloatTensor(dummy_features), torch.LongTensor([label])[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:08.464755Z","iopub.execute_input":"2025-04-14T23:22:08.465045Z","iopub.status.idle":"2025-04-14T23:22:08.480369Z","shell.execute_reply.started":"2025-04-14T23:22:08.465020Z","shell.execute_reply":"2025-04-14T23:22:08.479630Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nset_seed()\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Feature extraction functions\ndef extract_mfcc(audio, sr=16000, n_mfcc=20):\n    \"\"\"Extract MFCC features from audio\"\"\"\n    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n    delta = librosa.feature.delta(mfcc)\n    delta2 = librosa.feature.delta(mfcc, order=2)\n    features = np.concatenate([mfcc, delta, delta2], axis=0)\n    return features\n\ndef extract_spec(audio, sr=16000, n_fft=512, hop_length=256):\n    \"\"\"Extract log mel-spectrogram features from audio\"\"\"\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=80)\n    log_mel_spec = librosa.power_to_db(mel_spec)\n    return log_mel_spec\n\ndef extract_cqt(audio, sr=16000, hop_length=256):\n    \"\"\"Extract Constant-Q Transform features from audio\"\"\"\n    cqt = librosa.cqt(y=audio, sr=sr, hop_length=hop_length)\n    return np.abs(cqt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:10.731378Z","iopub.execute_input":"2025-04-14T23:22:10.731633Z","iopub.status.idle":"2025-04-14T23:22:10.742478Z","shell.execute_reply.started":"2025-04-14T23:22:10.731617Z","shell.execute_reply":"2025-04-14T23:22:10.741636Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Neural Architecture Search (NAS) components\n\n# Define the search space\nclass Operation(nn.Module):\n    \"\"\"Base class for all operations in the search space\"\"\"\n    def __init__(self, channels, stride=1):\n        super(Operation, self).__init__()\n        self.channels = channels\n        self.stride = stride\n    \n    def forward(self, x):\n        raise NotImplementedError\n\nclass ConvBlock(Operation):\n    def __init__(self, channels, kernel_size, stride=1):\n        super(ConvBlock, self).__init__(channels, stride)\n        self.conv = nn.Conv1d(channels, channels, kernel_size, stride=stride, padding=kernel_size//2)\n        self.bn = nn.BatchNorm1d(channels)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))\n\nclass LSTM(Operation):\n    def __init__(self, channels, stride=1):\n        super(LSTM, self).__init__(channels, stride)\n        self.lstm = nn.LSTM(channels, channels, batch_first=True)  # Set batch_first=True for simplicity\n        self.proj = nn.Linear(channels, channels)  # Simplified projection\n        \n        # We'll use a Conv1d for adaptation instead of Linear\n        # This works better with the expected tensor shapes\n        self.input_proj = nn.Conv1d(in_channels=channels, out_channels=channels, kernel_size=1)\n    \n    def forward(self, x):\n        # x shape is expected to be [B, C, T] from previous operations\n        \n        # First, check if we need to adapt the channel dimension\n        if x.size(1) != self.channels:\n            # Use the 1x1 convolution to adapt the channel dimension\n            x = self.input_proj(x)\n        \n        # Now reshape for LSTM\n        batch_size, channels, seq_len = x.size()\n        x = x.permute(0, 2, 1)  # [B, C, T] -> [B, T, C]\n        \n        # LSTM expects [B, T, C] with batch_first=True\n        x, _ = self.lstm(x)\n        \n        # Apply projection if needed\n        x = self.proj(x)\n        \n        # Return to original dimension ordering\n        x = x.permute(0, 2, 1)  # [B, T, C] -> [B, C, T]\n        \n        return x\n\nclass Dilated(Operation):\n    def __init__(self, channels, stride=1):\n        super(Dilated, self).__init__(channels, stride)\n        self.conv = nn.Conv1d(channels, channels, 3, stride=stride, padding=2, dilation=2)\n        self.bn = nn.BatchNorm1d(channels)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))\n\nclass SkipConnect(Operation):\n    def __init__(self, channels, stride=1):\n        super(SkipConnect, self).__init__(channels, stride)\n    \n    def forward(self, x):\n        return x\n\nclass Attention(Operation):\n    def __init__(self, channels, stride=1):\n        super(Attention, self).__init__(channels, stride)\n        self.query = nn.Conv1d(channels, channels, 1)\n        self.key = nn.Conv1d(channels, channels, 1)\n        self.value = nn.Conv1d(channels, channels, 1)\n        self.scale = torch.sqrt(torch.FloatTensor([channels])).to(device)\n    \n    def forward(self, x):\n        # x shape: [C, T, B]\n        q = self.query(x)\n        k = self.key(x)\n        v = self.value(x)\n        \n        # Self-attention\n        attention = torch.matmul(q.permute(0, 2, 1), k) / self.scale\n        attention = F.softmax(attention, dim=-1)\n        x = torch.matmul(attention, v.permute(0, 2, 1)).permute(0, 2, 1)\n        return x\n\n# Define the mixed operation (to be controlled by PPO)\nclass MixedOp(nn.Module):\n    def __init__(self, channels, stride=1):\n        super(MixedOp, self).__init__()\n        self.ops = nn.ModuleList([\n            ConvBlock(channels, 3, stride),\n            ConvBlock(channels, 5, stride),\n            LSTM(channels, stride),\n            Dilated(channels, stride),\n            SkipConnect(channels, stride),\n            Attention(channels, stride)\n        ])\n    \n    def forward(self, x, weights):\n        \"\"\"Forward pass with operation weights\"\"\"\n        return sum(w * op(x) for w, op in zip(weights, self.ops))","metadata":{"_uuid":"7f3edfdc-8a27-4c5d-8ad7-1a77fb834b22","_cell_guid":"c072f101-96dd-447f-92cd-6c6eaa7b97a5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-14T23:22:13.493941Z","iopub.execute_input":"2025-04-14T23:22:13.494231Z","iopub.status.idle":"2025-04-14T23:22:13.509113Z","shell.execute_reply.started":"2025-04-14T23:22:13.494209Z","shell.execute_reply":"2025-04-14T23:22:13.508548Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Cell structure\nclass Cell(nn.Module):\n    def __init__(self, channels, num_nodes=4):\n        super(Cell, self).__init__()\n        self.channels = channels\n        self.num_nodes = num_nodes\n        \n        # For each node, create edges from all previous nodes\n        self.edges = nn.ModuleList()\n        for i in range(num_nodes):\n            for j in range(i+1):  # connections from input and previous nodes\n                self.edges.append(MixedOp(channels))\n        \n        # Output projection - ensure consistent channel dimension\n        self.project = nn.Conv1d(channels * num_nodes, channels, 1)\n    \n    def forward(self, x, weights):\n        \"\"\"\n        Forward pass through the cell\n        Args:\n            x: Input tensor [B, C, T]\n            weights: List of weight tensors for each edge\n        \"\"\"\n        # Add debugging print to check dimensions\n        #print(f\"Cell input shape: {x.shape}\")\n        \n        states = [x]\n        offset = 0\n        \n        # Process each node\n        for i in range(self.num_nodes):\n            # Gather inputs from previous nodes\n            node_inputs = []\n            for j in range(i+1):\n                edge_output = self.edges[offset + j](states[j], weights[offset + j])\n                # Add dimension check\n                if edge_output.size(1) != self.channels:\n                    print(f\"Dimension mismatch at node {i}, edge {j}: expected {self.channels}, got {edge_output.size(1)}\")\n                    # Add adaptive padding or projection if needed\n                    edge_output = F.pad(edge_output, (0, 0, 0, self.channels - edge_output.size(1), 0, 0))\n                node_inputs.append(edge_output)\n            \n            node_input = sum(node_inputs)\n            offset += i+1\n            states.append(node_input)\n        \n        # Concatenate all intermediate nodes and check dimensions\n        cat_states = torch.cat(states[1:], dim=1)\n        #print(f\"Concatenated states shape before projection: {cat_states.shape}\")\n        \n        return self.project(cat_states)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:14.033887Z","iopub.execute_input":"2025-04-14T23:22:14.034095Z","iopub.status.idle":"2025-04-14T23:22:14.042205Z","shell.execute_reply.started":"2025-04-14T23:22:14.034080Z","shell.execute_reply":"2025-04-14T23:22:14.041450Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Complete model with cells\nclass DeepfakeDetectionModel(nn.Module):\n    def __init__(self, input_channels, num_cells=3, num_nodes=4, num_ops=6):\n        super(DeepfakeDetectionModel, self).__init__()\n        self.input_channels = input_channels\n        self.num_cells = num_cells\n        self.num_nodes = num_nodes\n        self.num_ops = num_ops\n        \n        # Initial projection\n        self.stem = nn.Sequential(\n            nn.Conv1d(input_channels, 64, 3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU()\n        )\n        \n        # Cells\n        self.cells = nn.ModuleList()\n        for i in range(num_cells):\n            self.cells.append(Cell(64, num_nodes))\n        \n        # Classification head\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.classifier = nn.Linear(64, 2)  # Binary classification\n        \n        # Calculate total number of weights needed\n        edges_per_cell = sum(range(1, num_nodes+1))\n        self.total_weights = num_cells * edges_per_cell * num_ops\n    \n    def forward(self, x, architecture_weights):\n        \"\"\"\n        Forward pass with specific architecture weights\n        Args:\n            x: Input features [B, C, T]\n            architecture_weights: Architecture weights tensor\n        \"\"\"\n        # Check input format and adjust if needed\n        if x.shape[1] == self.input_channels:\n            # Input is already [B, C, T]\n            pass\n        else:\n            # Input is [B, T, C], convert to [B, C, T]\n            x = x.permute(0, 2, 1)\n    \n        # Process input (no need for permute since we've handled it above)\n        x = self.stem(x)\n    \n        # Reshape weights for each edge\n        edge_weights = []\n        edges_per_cell = sum(range(1, self.num_nodes+1))\n        total_edges = self.num_cells * edges_per_cell\n        \n        # Split weights by cell and edge\n        for i in range(total_edges):\n            start_idx = i * self.num_ops\n            end_idx = start_idx + self.num_ops\n            # Apply softmax to get probability distribution over operations\n            edge_weights.append(F.softmax(architecture_weights[start_idx:end_idx], dim=0))\n        \n        \n        \n        # Process cells\n        offset = 0\n        for i, cell in enumerate(self.cells):\n            cell_weights = edge_weights[offset:offset + edges_per_cell]\n            offset += edges_per_cell\n            x = cell(x, cell_weights)\n        \n        # Classification\n        x = self.pool(x).squeeze(-1)\n        x = self.classifier(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:15.554264Z","iopub.execute_input":"2025-04-14T23:22:15.554513Z","iopub.status.idle":"2025-04-14T23:22:15.563338Z","shell.execute_reply.started":"2025-04-14T23:22:15.554496Z","shell.execute_reply":"2025-04-14T23:22:15.562729Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# PPO for architecture search\nclass PPOController(nn.Module):\n    def __init__(self, state_dim, action_dim, hidden_dim=64):\n        super(PPOController, self).__init__()\n        \n        # Actor network (policy)\n        self.actor = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, action_dim)\n        )\n        \n        # Critic network (value function)\n        self.critic = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, 1)\n        )\n        \n    def forward(self, state):\n        # Returns action probabilities and estimated value\n        action_probs = F.softmax(self.actor(state), dim=-1)\n        value = self.critic(state)\n        return action_probs, value\n    \n    def act(self, state):\n        action_probs, _ = self.forward(state)\n        dist = Categorical(action_probs)\n        action = dist.sample()\n        log_prob = dist.log_prob(action)\n        return action.detach(), log_prob.detach()\n    \n    def evaluate(self, state, action):\n        action_probs, value = self.forward(state)\n        dist = Categorical(action_probs)\n        log_prob = dist.log_prob(action)\n        entropy = dist.entropy()\n        return log_prob, value, entropy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:17.020235Z","iopub.execute_input":"2025-04-14T23:22:17.020898Z","iopub.status.idle":"2025-04-14T23:22:17.028340Z","shell.execute_reply.started":"2025-04-14T23:22:17.020873Z","shell.execute_reply":"2025-04-14T23:22:17.027583Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# PPO Training Function with tqdm progress bar\ndef train_ppo(controller, optimizer, memories, clip_ratio=0.2, epochs=10, entropy_coef=0.01):\n    \"\"\"Train the PPO controller on collected experiences\"\"\"\n    # Unpack memories\n    states = torch.cat([m['state'] for m in memories])\n    actions = torch.cat([m['action'] for m in memories])\n    old_log_probs = torch.cat([m['log_prob'] for m in memories])\n    rewards = torch.cat([m['reward'] for m in memories])\n    \n    # Normalize rewards\n    rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n    \n    # Store metrics for logging\n    metrics = {\n        'actor_loss': 0,\n        'critic_loss': 0,\n        'entropy_loss': 0\n    }\n    \n    # Train for multiple epochs with progress bar\n    ppo_pbar = tqdm(range(epochs), desc=\"PPO Training\", leave=False)\n    \n    for _ in ppo_pbar:\n        # Evaluate actions\n        log_probs, values, entropy = controller.evaluate(states, actions)\n        values = values.squeeze(-1)\n        \n        # Compute ratio and surrogate loss\n        ratio = torch.exp(log_probs - old_log_probs)\n        surr1 = ratio * rewards\n        surr2 = torch.clamp(ratio, 1 - clip_ratio, 1 + clip_ratio) * rewards\n        \n        # PPO loss\n        actor_loss = -torch.min(surr1, surr2).mean()\n        critic_loss = F.mse_loss(values, rewards)\n        entropy_loss = -entropy.mean()\n        \n        # Total loss\n        loss = actor_loss + 0.5 * critic_loss - entropy_coef * entropy_loss\n        \n        # Update\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        # Update metrics\n        metrics['actor_loss'] += actor_loss.item() / epochs\n        metrics['critic_loss'] += critic_loss.item() / epochs\n        metrics['entropy_loss'] += entropy_loss.item() / epochs\n        \n        # Update progress bar\n        ppo_pbar.set_postfix({\n            'actor_loss': f\"{actor_loss.item():.4f}\",\n            'critic_loss': f\"{critic_loss.item():.4f}\",\n            'entropy': f\"{entropy.mean().item():.4f}\"\n        })\n    \n    return metrics['actor_loss'], metrics['critic_loss'], metrics['entropy_loss']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:17.660067Z","iopub.execute_input":"2025-04-14T23:22:17.660531Z","iopub.status.idle":"2025-04-14T23:22:17.669198Z","shell.execute_reply.started":"2025-04-14T23:22:17.660510Z","shell.execute_reply":"2025-04-14T23:22:17.668437Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Main NAS using PPO\ndef search_architecture(train_loader, val_loader, device, input_channels=60, num_cells=3, \n                        num_nodes=4, num_ops=6, epochs=50, ppo_updates=5, project_name=\"deepfake-nas-ppo\"):\n    \"\"\"Perform neural architecture search using PPO\"\"\"\n    # Initialize wandb\n    wandb.init(project=project_name, name=f\"NAS_cells{num_cells}_nodes{num_nodes}\")\n    \n    # Log hyperparameters\n    config = {\n        \"input_channels\": input_channels,\n        \"num_cells\": num_cells,\n        \"num_nodes\": num_nodes,\n        \"num_ops\": num_ops,\n        \"epochs\": epochs,\n        \"ppo_updates\": ppo_updates,\n        \"model_lr\": 0.001,\n        \"controller_lr\": 0.001,\n    }\n    wandb.config.update(config)\n    \n    # Initialize model and controller\n    model = DeepfakeDetectionModel(input_channels, num_cells, num_nodes, num_ops).to(device)\n    \n    # State dimension is the validation performance metric\n    state_dim = 1\n    \n    # Action dimension is the total number of weights\n    edges_per_cell = sum(range(1, num_nodes+1))\n    total_edges = num_cells * edges_per_cell\n    action_dim = num_ops  # Number of operations per edge\n    \n    # Initialize PPO controller\n    controller = PPOController(state_dim, action_dim).to(device)\n    controller_optimizer = optim.Adam(controller.parameters(), lr=config[\"controller_lr\"])\n    \n    # Model optimizer\n    model_optimizer = optim.Adam(model.parameters(), lr=config[\"model_lr\"])\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, 'min', patience=5)\n    \n    # Metrics tracking\n    best_val_eer = 1.0\n    best_architecture = None\n    \n    # Create a progress bar for epochs\n    epoch_pbar = tqdm(range(epochs), desc=\"Architecture Search Progress\")\n    \n    for epoch in epoch_pbar:\n        # Train the model with current architecture\n        model.train()\n        train_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # For PPO\n        memories = []\n        current_architecture = []\n        \n        # Sample architecture for this epoch\n        for i in range(total_edges):\n            # Use current validation EER as state (normalized between 0 and 1)\n            state = torch.FloatTensor([min(best_val_eer, 0.5) * 2]).to(device)  # Scale to [0, 1]\n            \n            # Sample architecture weights for this edge\n            for j in range(num_ops):\n                action, log_prob = controller.act(state)\n                current_architecture.append(action.item())\n                \n                # Store experience for PPO\n                memories.append({\n                    'state': state,\n                    'action': action.unsqueeze(0),\n                    'log_prob': log_prob.unsqueeze(0),\n                    'reward': torch.zeros(1).to(device)  # Will be updated later\n                })\n        \n        # Convert architecture to tensor\n        architecture_weights = torch.FloatTensor(current_architecture).to(device)\n        \n        # Train the model with current architecture\n        train_pbar = tqdm(train_loader, desc=f\"Training\", leave=False)\n        for inputs, targets in train_pbar:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            model_optimizer.zero_grad()\n            outputs = model(inputs, architecture_weights)\n            loss = F.cross_entropy(outputs, targets)\n            loss.backward()\n            model_optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            # Update training progress bar\n            train_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n        \n        train_accuracy = 100 * correct / total\n        avg_train_loss = train_loss / len(train_loader)\n        \n        # Validate the model\n        model.eval()\n        val_loss = 0.0\n        all_targets = []\n        all_scores = []\n        \n        with torch.no_grad():\n            val_pbar = tqdm(val_loader, desc=f\"Validation\", leave=False)\n            for inputs, targets in val_pbar:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs, architecture_weights)\n                loss = F.cross_entropy(outputs, targets)\n                val_loss += loss.item()\n                \n                # Get scores for EER calculation\n                scores = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Score for spoof class\n                all_targets.extend(targets.cpu().numpy())\n                all_scores.extend(scores)\n                \n                # Update validation progress bar\n                val_pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n        \n        # Calculate EER with error handling\n        try:\n            fpr, tpr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n            fnr = 1 - tpr\n    \n            # Check if we have valid values before using nanargmin\n            if np.all(np.isnan(fnr - fpr)):\n                print(\"Warning: Cannot calculate EER - all differences are NaN\")\n                # Provide a fallback value if EER calculation fails\n                eer = 0.5  # Default to random guess performance\n                eer_threshold = 0.5\n            else:\n                # Find the index where the difference is minimum\n                idx = np.nanargmin(np.absolute(fnr - fpr))\n                eer_threshold = thresholds[idx]\n                eer = (fpr[idx] + fnr[idx]) / 2\n        \n        except Exception as e:\n            print(f\"Error calculating EER: {e}\")\n            print(f\"all_targets shape: {np.shape(all_targets)}, unique values: {np.unique(all_targets)}\")\n            print(f\"all_scores shape: {np.shape(all_scores)}, range: [{np.min(all_scores)}, {np.max(all_scores)}]\")\n            # Provide fallback values\n            eer = 0.5\n            eer_threshold = 0.5\n        \n        avg_val_loss = val_loss / len(val_loader)\n        \n        # Update epoch progress bar\n        epoch_pbar.set_postfix({\n            \"Train Loss\": f\"{avg_train_loss:.4f}\",\n            \"Val EER\": f\"{eer:.4f}\",\n            \"Best EER\": f\"{best_val_eer:.4f}\"\n        })\n        \n        # Log metrics to wandb\n        wandb.log({\n            \"epoch\": epoch + 1,\n            \"train_loss\": avg_train_loss,\n            \"train_accuracy\": train_accuracy,\n            \"val_loss\": avg_val_loss,\n            \"val_eer\": eer,\n            \"best_val_eer\": best_val_eer,\n            \"learning_rate\": model_optimizer.param_groups[0]['lr']\n        })\n        \n        # Update PPO rewards based on EER improvement\n        reward = best_val_eer - eer if eer < best_val_eer else 0\n        for memory in memories:\n            memory['reward'] = torch.FloatTensor([reward]).to(device)\n        \n        # Update best architecture if improved\n        if eer < best_val_eer:\n            best_val_eer = eer\n            best_architecture = architecture_weights.clone()\n            \n            # Save best model\n            checkpoint_path = 'best_deepfake_detection_model.pth'\n            torch.save({\n                'model_state_dict': model.state_dict(),\n                'architecture': best_architecture,\n                'eer': best_val_eer,\n                'epoch': epoch + 1\n            }, checkpoint_path)\n            \n            # Log best model to wandb\n            wandb.save(checkpoint_path)\n            \n            # Log best architecture visualization\n            visualize_architecture(best_architecture, num_cells, num_nodes, num_ops, save_to_wandb=True)\n            \n            print(f\"\\nNew best architecture found! EER: {best_val_eer:.4f}\")\n        \n        # Update learning rate\n        scheduler.step(eer)\n        \n        # Update PPO controller if enough data\n        if epoch % ppo_updates == 0 and len(memories) > 0:\n            actor_loss, critic_loss, entropy_loss = train_ppo(\n                controller, controller_optimizer, memories)\n            \n            # Log PPO metrics\n            wandb.log({\n                \"actor_loss\": actor_loss,\n                \"critic_loss\": critic_loss,\n                \"entropy_loss\": entropy_loss\n            })\n    \n    # Finish wandb run\n    wandb.finish()\n    \n    return model, best_architecture, best_val_eer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:19.367262Z","iopub.execute_input":"2025-04-14T23:22:19.367539Z","iopub.status.idle":"2025-04-14T23:22:19.385794Z","shell.execute_reply.started":"2025-04-14T23:22:19.367518Z","shell.execute_reply":"2025-04-14T23:22:19.385016Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Utility functions for evaluation\ndef evaluate_model(model, architecture, test_loader, device, log_to_wandb=True):\n    \"\"\"Evaluate the model with the best architecture\"\"\"\n    model.eval()\n    all_targets = []\n    all_scores = []\n    test_loss = 0.0\n    correct = 0\n    total = 0\n    \n    # Create a progress bar for evaluation\n    eval_pbar = tqdm(test_loader, desc=\"Evaluating\")\n    \n    with torch.no_grad():\n        for inputs, targets in eval_pbar:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs, architecture)\n            \n            # Compute loss\n            loss = F.cross_entropy(outputs, targets)\n            test_loss += loss.item()\n            \n            # Compute accuracy\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            # Get scores for EER calculation\n            scores = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Score for spoof class\n            all_targets.extend(targets.cpu().numpy())\n            all_scores.extend(scores)\n            \n            # Update progress bar with current metrics\n            eval_pbar.set_postfix({\n                \"loss\": f\"{loss.item():.4f}\",\n                \"accuracy\": f\"{100.0 * correct / total:.2f}%\"\n            })\n    \n    # Calculate test accuracy\n    test_accuracy = 100.0 * correct / total\n    avg_test_loss = test_loss / len(test_loader)\n    # Calculate EER\n    try:\n        fpr, tpr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n        fnr = 1 - tpr\n    \n        # Check if we have valid values before using nanargmin\n        if np.all(np.isnan(fnr - fpr)):\n            print(\"Warning: Cannot calculate EER - all differences are NaN\")\n            # Provide a fallback value if EER calculation fails\n            eer = 0.5  # Default to random guess performance\n            eer_threshold = 0.5\n        else:\n            # Find the index where the difference is minimum\n            idx = np.nanargmin(np.absolute(fnr - fpr))\n            eer_threshold = thresholds[idx]\n            eer = (fpr[idx] + fnr[idx]) / 2\n        \n    except Exception as e:\n        print(f\"Error calculating EER: {e}\")\n        print(f\"all_targets shape: {np.shape(all_targets)}, unique values: {np.unique(all_targets)}\")\n        print(f\"all_scores shape: {np.shape(all_scores)}, range: [{np.min(all_scores)}, {np.max(all_scores)}]\")\n        # Provide fallback values\n        eer = 0.5\n        eer_threshold = 0.5\n    \n    # Plot ROC curve\n    plt.figure(figsize=(10, 8))\n    plt.plot(fpr, tpr, label=f'ROC Curve (EER = {eer:.4f})')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve for Deepfake Detection')\n    plt.legend(loc=\"lower right\")\n    \n    # Save ROC curve\n    roc_curve_path = 'roc_curve.png'\n    plt.savefig(roc_curve_path)\n    \n    # Print results\n    print(f\"\\nTest Results - Loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, EER: {eer:.4f}, EER Threshold: {eer_threshold:.4f}\")\n    \n    # Log to wandb if requested\n    if log_to_wandb:\n        # Initialize wandb if it's not already running\n        if wandb.run is None:\n            wandb.init(project=\"deepfake-nas-ppo\", name=\"final_evaluation\")\n        \n        # Log metrics\n        wandb.log({\n            \"test_loss\": avg_test_loss,\n            \"test_accuracy\": test_accuracy,\n            \"test_eer\": eer,\n            \"eer_threshold\": eer_threshold\n        })\n        \n        # Log ROC curve\n        wandb.log({\"roc_curve\": wandb.Image(roc_curve_path)})\n        \n        # Log confusion matrix\n        cm = np.zeros((2, 2))\n        for i in range(len(all_targets)):\n            pred_class = 1 if all_scores[i] > eer_threshold else 0\n            cm[all_targets[i]][pred_class] += 1\n        \n        # Normalize confusion matrix\n        cm_norm = cm / cm.sum(axis=1, keepdims=True)\n        \n        # Plot confusion matrix\n        plt.figure(figsize=(8, 6))\n        plt.imshow(cm_norm, cmap='Blues')\n        plt.colorbar()\n        plt.title('Normalized Confusion Matrix')\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.xticks([0, 1], ['Bonafide', 'Spoof'])\n        plt.yticks([0, 1], ['Bonafide', 'Spoof'])\n        \n        # Add text annotations\n        for i in range(2):\n            for j in range(2):\n                plt.text(j, i, f'{cm[i, j]:.0f}\\n({cm_norm[i, j]:.2f})', \n                         ha='center', va='center', \n                         color='white' if cm_norm[i, j] > 0.5 else 'black')\n        \n        cm_path = 'confusion_matrix.png'\n        plt.savefig(cm_path)\n        wandb.log({\"confusion_matrix\": wandb.Image(cm_path)})\n    \n    return eer, eer_threshold\n\ndef visualize_architecture(architecture, num_cells, num_nodes, num_ops, save_to_wandb=False):\n    \"\"\"Visualize the architecture weights\"\"\"\n    edges_per_cell = sum(range(1, num_nodes+1))\n    \n    plt.figure(figsize=(15, 10))\n    \n    # Operation names for better visualization\n    op_names = ['Conv3x3', 'Conv5x5', 'LSTM', 'Dilated', 'SkipConn', 'Attention']\n    \n    for cell in range(num_cells):\n        plt.subplot(num_cells, 1, cell+1)\n        \n        edge_idx = 0\n        weights_matrix = np.zeros((num_nodes+1, num_nodes))\n        \n        # Create a matrix to store the operation types\n        op_matrix = np.empty((num_nodes+1, num_nodes), dtype=object)\n        \n        for i in range(num_nodes):\n            for j in range(i+1):\n                start_idx = (cell * edges_per_cell + edge_idx) * num_ops\n                edge_weights = F.softmax(architecture[start_idx:start_idx+num_ops].cpu(), dim=0).numpy()\n                strongest_op = np.argmax(edge_weights)\n                weights_matrix[j, i] = strongest_op + 1  # +1 for better visualization\n                op_matrix[j, i] = op_names[strongest_op] if strongest_op < len(op_names) else f\"Op{strongest_op}\"\n                edge_idx += 1\n        \n        # Create heatmap with annotations\n        plt.imshow(weights_matrix, cmap='viridis')\n        plt.colorbar(ticks=range(1, num_ops+2))\n        \n        # Add text annotations for operation types\n        for i in range(num_nodes):\n            for j in range(i+1):\n                if op_matrix[j, i] is not None:\n                    plt.text(i, j, op_matrix[j, i], ha=\"center\", va=\"center\", \n                             color=\"white\" if weights_matrix[j, i] > num_ops/2 else \"black\",\n                             fontsize=8)\n        \n        plt.title(f'Cell {cell+1} Architecture')\n        plt.xlabel('Destination Node')\n        plt.ylabel('Source Node')\n    \n    plt.tight_layout()\n    \n    # Save figure\n    fig_path = 'architecture_visualization.png'\n    plt.savefig(fig_path)\n    \n    # Log to wandb if requested\n    if save_to_wandb:\n        wandb.log({\"architecture_visualization\": wandb.Image(fig_path)})\n    \n    return fig_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:24.172821Z","iopub.execute_input":"2025-04-14T23:22:24.173062Z","iopub.status.idle":"2025-04-14T23:22:24.191607Z","shell.execute_reply.started":"2025-04-14T23:22:24.173044Z","shell.execute_reply":"2025-04-14T23:22:24.190893Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Main function to run the entire pipeline\ndef main():\n    # Import time for experiment naming\n    import time\n    import os\n    \n    # Initialize wandb for the entire experiment\n    experiment_name = f\"ASVspoof2019_NAS_PPO_{int(time.time())}\"\n    \n    print(\"Starting Deepfake Audio Detection with NAS and PPO\")\n    print(\"=\" * 80)\n    \n    # Paths and parameters (based on the provided dataset structure)\n    base_dir = \"/kaggle/input/asvspoof-dataset-2019\"\n    data_dir_train = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_train\", \"flac\")\n    data_dir_dev = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_dev\", \"flac\")\n    data_dir_eval = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_eval\", \"flac\")\n    \n    train_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.train.trn.txt\")\n    dev_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.dev.trl.txt\")\n    eval_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.eval.trl.txt\")\n    \n    # Log dataset information\n    print(f\"Train data directory: {data_dir_train}\")\n    print(f\"Train protocol file: {train_protocol}\")\n    print(f\"Dev data directory: {data_dir_dev}\")\n    print(f\"Dev protocol file: {dev_protocol}\")\n    print(f\"Eval data directory: {data_dir_eval}\")\n    print(f\"Eval protocol file: {eval_protocol}\")\n    \n    # Experiment configuration\n    feature_type = 'mfcc'  # Options: 'mfcc', 'spec', 'cqt'\n    max_seq_len = 400\n    batch_size_train = 32\n    batch_size_eval = 64\n    num_workers = 4\n\n    wandb.login(key=\"373119fa114178ac5e09f36834a61c071debfbb8\")\n    # Initialize wandb\n    wandb.init(\n        project=\"ASVspoof2019-NAS-PPO\",\n        name=experiment_name,\n        config={\n            \"feature_type\": feature_type,\n            \"max_sequence_length\": max_seq_len,\n            \"batch_size_train\": batch_size_train,\n            \"batch_size_eval\": batch_size_eval,\n            \"num_workers\": num_workers,\n            \"dataset\": \"ASVspoof2019 LA\"\n        }\n    )\n    \n    # Create datasets with tqdm progress for loading\n    print(\"Creating datasets...\")\n    \n    print(\"Loading training dataset...\")\n    train_dataset = ASVSpoofDataset(\n        root_dir=data_dir_train,\n        protocol_file=train_protocol,\n        feature_type=feature_type,\n        max_len=max_seq_len,\n        is_train=True\n    )\n    \n    print(\"Loading validation dataset...\")\n    dev_dataset = ASVSpoofDataset(\n        root_dir=data_dir_dev,\n        protocol_file=dev_protocol,\n        feature_type=feature_type,\n        max_len=max_seq_len,\n        is_train=False\n    )\n    \n    print(\"Loading evaluation dataset...\")\n    eval_dataset = ASVSpoofDataset(\n        root_dir=data_dir_eval,\n        protocol_file=eval_protocol,\n        feature_type=feature_type,\n        max_len=max_seq_len,\n        is_train=False\n    )\n    \n    # Log dataset sizes\n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Validation dataset size: {len(dev_dataset)} samples\")\n    print(f\"Evaluation dataset size: {len(eval_dataset)} samples\")\n    wandb.log({\n        \"train_dataset_size\": len(train_dataset),\n        \"val_dataset_size\": len(dev_dataset),\n        \"eval_dataset_size\": len(eval_dataset)\n    })\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size_train, \n        shuffle=True, \n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    dev_loader = DataLoader(\n        dev_dataset, \n        batch_size=batch_size_eval, \n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    eval_loader = DataLoader(\n        eval_dataset, \n        batch_size=batch_size_eval, \n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    # Architecture search parameters\n    nas_config = {\n        \"input_channels\": 60,  # 20 MFCCs x 3 (static, delta, delta-delta)\n        \"num_cells\": 3,\n        \"num_nodes\": 4,\n        \"num_ops\": 6,\n        \"epochs\": 30,\n        \"ppo_updates\": 5,\n        \"project_name\": \"ASVspoof2019-NAS-PPO\"\n    }\n    \n    # Log NAS configuration\n    print(\"\\nNeural Architecture Search Configuration:\")\n    for key, value in nas_config.items():\n        print(f\"  {key}: {value}\")\n    \n    # Create output directory for results\n    output_dir = f\"/kaggle/working/results_{experiment_name}\"\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"\\nResults will be saved to {output_dir}\")\n    \n    # Perform architecture search with wandb logging\n    print(\"\\nStarting Neural Architecture Search...\")\n    model, best_architecture, best_val_eer = search_architecture(\n        train_loader=train_loader,\n        val_loader=dev_loader,\n        device=device,\n        input_channels=nas_config[\"input_channels\"],\n        num_cells=nas_config[\"num_cells\"],\n        num_nodes=nas_config[\"num_nodes\"],\n        num_ops=nas_config[\"num_ops\"],\n        epochs=nas_config[\"epochs\"],\n        ppo_updates=nas_config[\"ppo_updates\"],\n        project_name=nas_config[\"project_name\"]\n    )\n    \n    # Save best architecture\n    torch.save(best_architecture, os.path.join(output_dir, \"best_architecture.pt\"))\n    \n    # Initialize a new wandb run for final evaluation\n    wandb.finish()  # Finish the NAS run\n    wandb.init(\n        project=\"ASVspoof2019-NAS-PPO\",\n        name=f\"{experiment_name}_final_evaluation\",\n        config={\n            \"feature_type\": feature_type,\n            \"best_val_eer\": best_val_eer\n        }\n    )\n    \n    # Evaluate on the evaluation set\n    print(\"\\nPerforming final evaluation on test set...\")\n    test_eer, eer_threshold = evaluate_model(model, best_architecture, eval_loader, device)\n    \n    # Log final metrics\n    wandb.log({\n        \"final_test_eer\": test_eer,\n        \"eer_threshold\": eer_threshold\n    })\n    \n    # Visualize the architecture with annotations\n    print(\"\\nVisualizing the best architecture...\")\n    fig_path = visualize_architecture(best_architecture, \n                                     num_cells=nas_config[\"num_cells\"], \n                                     num_nodes=nas_config[\"num_nodes\"], \n                                     num_ops=nas_config[\"num_ops\"],\n                                     save_to_wandb=True)\n    \n    # Save architecture visualization\n    import shutil\n    shutil.copy(fig_path, os.path.join(output_dir, \"architecture_visualization.png\"))\n    \n    # Create a summary report\n    summary = {\n        \"experiment_name\": experiment_name,\n        \"feature_type\": feature_type,\n        \"best_validation_eer\": best_val_eer,\n        \"test_eer\": test_eer,\n        \"eer_threshold\": eer_threshold,\n        \"model_architecture\": {\n            \"num_cells\": nas_config[\"num_cells\"],\n            \"num_nodes\": nas_config[\"num_nodes\"],\n            \"num_operations\": nas_config[\"num_ops\"]\n        }\n    }\n    \n    # Save summary as JSON\n    import json\n    with open(os.path.join(output_dir, \"summary.json\"), \"w\") as f:\n        json.dump(summary, f, indent=4)\n    \n    # Also save as text for easy reading\n    with open(os.path.join(output_dir, \"summary.txt\"), \"w\") as f:\n        f.write(\"ASVspoof 2019 Deepfake Detection Summary\\n\")\n        f.write(\"=\" * 50 + \"\\n\\n\")\n        f.write(f\"Experiment name: {experiment_name}\\n\")\n        f.write(f\"Feature type: {feature_type}\\n\\n\")\n        f.write(\"Performance metrics:\\n\")\n        f.write(f\"  Best validation EER: {best_val_eer:.4f}\\n\")\n        f.write(f\"  Test EER: {test_eer:.4f}\\n\")\n        f.write(f\"  EER threshold: {eer_threshold:.4f}\\n\\n\")\n        f.write(\"Model architecture:\\n\")\n        f.write(f\"  Number of cells: {nas_config['num_cells']}\\n\")\n        f.write(f\"  Number of nodes per cell: {nas_config['num_nodes']}\\n\")\n        f.write(f\"  Number of operations: {nas_config['num_ops']}\\n\")\n    \n    # Log summary to wandb\n    wandb.save(os.path.join(output_dir, \"summary.txt\"))\n    wandb.save(os.path.join(output_dir, \"summary.json\"))\n    \n    print(\"\\nExperiment completed!\")\n    print(f\"Final Test EER: {test_eer:.4f}, EER Threshold: {eer_threshold:.4f}\")\n    print(f\"All results saved to {output_dir}\")\n    print(\"=\" * 80)\n    \n    # Finish wandb\n    wandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:25.728635Z","iopub.execute_input":"2025-04-14T23:22:25.729316Z","iopub.status.idle":"2025-04-14T23:22:25.746016Z","shell.execute_reply.started":"2025-04-14T23:22:25.729292Z","shell.execute_reply":"2025-04-14T23:22:25.745326Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T23:22:27.261757Z","iopub.execute_input":"2025-04-14T23:22:27.262266Z","iopub.status.idle":"2025-04-14T23:30:58.362190Z","shell.execute_reply.started":"2025-04-14T23:22:27.262241Z","shell.execute_reply":"2025-04-14T23:30:58.361051Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n","output_type":"stream"},{"name":"stdout","text":"Starting Deepfake Audio Detection with NAS and PPO\n================================================================================\nTrain data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_train/flac\nTrain protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\nDev data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_dev/flac\nDev protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\nEval data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_eval/flac\nEval protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\nCreating datasets...\nLoading training dataset...\nReading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\n","output_type":"stream"},{"name":"stderr","text":"Loading training protocol: 100%|██████████| 25380/25380 [00:00<00:00, 1357244.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dataset loaded: 25380 samples (2580 bonafide, 22800 spoof)\nSubsampling training data for faster NAS...\nSubsampled to 5000 samples\nLoading validation dataset...\nReading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\n","output_type":"stream"},{"name":"stderr","text":"Loading evaluation protocol: 100%|██████████| 24844/24844 [00:00<00:00, 1519308.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dataset loaded: 24844 samples (2548 bonafide, 22296 spoof)\nLoading evaluation dataset...\nReading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\n","output_type":"stream"},{"name":"stderr","text":"Loading evaluation protocol: 100%|██████████| 71237/71237 [00:00<00:00, 1461295.52it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset loaded: 71237 samples (7355 bonafide, 63882 spoof)\nTraining dataset size: 5000 samples\nValidation dataset size: 24844 samples\nEvaluation dataset size: 71237 samples\n\nNeural Architecture Search Configuration:\n  input_channels: 60\n  num_cells: 3\n  num_nodes: 4\n  num_ops: 6\n  epochs: 30\n  ppo_updates: 5\n  project_name: ASVspoof2019-NAS-PPO\n\nResults will be saved to /kaggle/working/results_ASVspoof2019_NAS_PPO_1744672947\n\nStarting Neural Architecture Search...\n","output_type":"stream"},{"name":"stderr","text":"\nArchitecture Search Progress:   0%|          | 0/30 [00:00<?, ?it/s]\nTraining:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\nTraining:   0%|          | 0/157 [00:04<?, ?it/s, loss=0.6888]\u001b[A\nTraining:   1%|          | 1/157 [00:04<10:48,  4.16s/it, loss=0.6888]\u001b[A\nTraining:   1%|          | 1/157 [00:04<10:48,  4.16s/it, loss=0.8899]\u001b[A\nTraining:   1%|▏         | 2/157 [00:04<05:40,  2.19s/it, loss=0.8899]\u001b[A\nTraining:   1%|▏         | 2/157 [00:05<05:40,  2.19s/it, loss=0.5772]\u001b[A\nTraining:   2%|▏         | 3/157 [00:05<03:53,  1.52s/it, loss=0.5772]\u001b[A\nTraining:   2%|▏         | 3/157 [00:06<03:53,  1.52s/it, loss=0.5717]\u001b[A\nTraining:   3%|▎         | 4/157 [00:06<03:04,  1.21s/it, loss=0.5717]\u001b[A\nTraining:   3%|▎         | 4/157 [00:07<03:04,  1.21s/it, loss=0.5573]\u001b[A\nTraining:   3%|▎         | 5/157 [00:07<02:41,  1.06s/it, loss=0.5573]\u001b[A\nTraining:   3%|▎         | 5/157 [00:07<02:41,  1.06s/it, loss=0.4165]\u001b[A\nTraining:   4%|▍         | 6/157 [00:07<02:24,  1.05it/s, loss=0.4165]\u001b[A\nTraining:   4%|▍         | 6/157 [00:08<02:24,  1.05it/s, loss=0.5969]\u001b[A\nTraining:   4%|▍         | 7/157 [00:08<02:12,  1.13it/s, loss=0.5969]\u001b[A\nTraining:   4%|▍         | 7/157 [00:09<02:12,  1.13it/s, loss=0.4331]\u001b[A\nTraining:   5%|▌         | 8/157 [00:09<02:10,  1.14it/s, loss=0.4331]\u001b[A\nTraining:   5%|▌         | 8/157 [00:10<02:10,  1.14it/s, loss=0.4224]\u001b[A\nTraining:   6%|▌         | 9/157 [00:10<02:02,  1.20it/s, loss=0.4224]\u001b[A\nTraining:   6%|▌         | 9/157 [00:11<02:02,  1.20it/s, loss=0.2642]\u001b[A\nTraining:   6%|▋         | 10/157 [00:11<01:57,  1.25it/s, loss=0.2642]\u001b[A\nTraining:   6%|▋         | 10/157 [00:11<01:57,  1.25it/s, loss=0.5790]\u001b[A\nTraining:   7%|▋         | 11/157 [00:11<01:57,  1.25it/s, loss=0.5790]\u001b[A\nTraining:   7%|▋         | 11/157 [00:12<01:57,  1.25it/s, loss=0.3629]\u001b[A\nTraining:   8%|▊         | 12/157 [00:12<01:55,  1.25it/s, loss=0.3629]\u001b[A\nTraining:   8%|▊         | 12/157 [00:13<01:55,  1.25it/s, loss=0.3447]\u001b[A\nTraining:   8%|▊         | 13/157 [00:13<01:54,  1.26it/s, loss=0.3447]\u001b[A\nTraining:   8%|▊         | 13/157 [00:14<01:54,  1.26it/s, loss=0.2200]\u001b[A\nTraining:   9%|▉         | 14/157 [00:14<01:51,  1.28it/s, loss=0.2200]\u001b[A\nTraining:   9%|▉         | 14/157 [00:14<01:51,  1.28it/s, loss=0.3030]\u001b[A\nTraining:  10%|▉         | 15/157 [00:14<01:49,  1.30it/s, loss=0.3030]\u001b[A\nTraining:  10%|▉         | 15/157 [00:15<01:49,  1.30it/s, loss=0.2991]\u001b[A\nTraining:  10%|█         | 16/157 [00:15<01:46,  1.32it/s, loss=0.2991]\u001b[A\nTraining:  10%|█         | 16/157 [00:16<01:46,  1.32it/s, loss=0.5022]\u001b[A\nTraining:  11%|█         | 17/157 [00:16<01:44,  1.34it/s, loss=0.5022]\u001b[A\nTraining:  11%|█         | 17/157 [00:17<01:44,  1.34it/s, loss=0.2581]\u001b[A\nTraining:  11%|█▏        | 18/157 [00:17<01:43,  1.34it/s, loss=0.2581]\u001b[A\nTraining:  11%|█▏        | 18/157 [00:17<01:43,  1.34it/s, loss=0.2768]\u001b[A\nTraining:  12%|█▏        | 19/157 [00:17<01:42,  1.35it/s, loss=0.2768]\u001b[A\nTraining:  12%|█▏        | 19/157 [00:18<01:42,  1.35it/s, loss=0.1786]\u001b[A\nTraining:  13%|█▎        | 20/157 [00:18<01:40,  1.36it/s, loss=0.1786]\u001b[A\nTraining:  13%|█▎        | 20/157 [00:19<01:40,  1.36it/s, loss=0.1448]\u001b[A\nTraining:  13%|█▎        | 21/157 [00:19<01:40,  1.35it/s, loss=0.1448]\u001b[A\nTraining:  13%|█▎        | 21/157 [00:20<01:40,  1.35it/s, loss=0.2693]\u001b[A\nTraining:  14%|█▍        | 22/157 [00:20<01:43,  1.31it/s, loss=0.2693]\u001b[A\nTraining:  14%|█▍        | 22/157 [00:20<01:43,  1.31it/s, loss=0.4896]\u001b[A\nTraining:  15%|█▍        | 23/157 [00:20<01:42,  1.30it/s, loss=0.4896]\u001b[A\nTraining:  15%|█▍        | 23/157 [00:21<01:42,  1.30it/s, loss=0.2702]\u001b[A\nTraining:  15%|█▌        | 24/157 [00:21<01:40,  1.32it/s, loss=0.2702]\u001b[A\nTraining:  15%|█▌        | 24/157 [00:22<01:40,  1.32it/s, loss=0.3812]\u001b[A\nTraining:  16%|█▌        | 25/157 [00:22<01:39,  1.33it/s, loss=0.3812]\u001b[A\nTraining:  16%|█▌        | 25/157 [00:23<01:39,  1.33it/s, loss=0.1178]\u001b[A\nTraining:  17%|█▋        | 26/157 [00:23<01:40,  1.30it/s, loss=0.1178]\u001b[A\nTraining:  17%|█▋        | 26/157 [00:23<01:40,  1.30it/s, loss=0.3864]\u001b[A\nTraining:  17%|█▋        | 27/157 [00:23<01:38,  1.32it/s, loss=0.3864]\u001b[A\nTraining:  17%|█▋        | 27/157 [00:24<01:38,  1.32it/s, loss=0.3636]\u001b[A\nTraining:  18%|█▊        | 28/157 [00:24<01:36,  1.34it/s, loss=0.3636]\u001b[A\nTraining:  18%|█▊        | 28/157 [00:25<01:36,  1.34it/s, loss=0.1575]\u001b[A\nTraining:  18%|█▊        | 29/157 [00:25<01:36,  1.33it/s, loss=0.1575]\u001b[A\nTraining:  18%|█▊        | 29/157 [00:26<01:36,  1.33it/s, loss=0.2214]\u001b[A\nTraining:  19%|█▉        | 30/157 [00:26<01:39,  1.27it/s, loss=0.2214]\u001b[A\nTraining:  19%|█▉        | 30/157 [00:27<01:39,  1.27it/s, loss=0.3268]\u001b[A\nTraining:  20%|█▉        | 31/157 [00:27<01:39,  1.27it/s, loss=0.3268]\u001b[A\nTraining:  20%|█▉        | 31/157 [00:27<01:39,  1.27it/s, loss=0.4141]\u001b[A\nTraining:  20%|██        | 32/157 [00:27<01:36,  1.30it/s, loss=0.4141]\u001b[A\nTraining:  20%|██        | 32/157 [00:28<01:36,  1.30it/s, loss=0.1777]\u001b[A\nTraining:  21%|██        | 33/157 [00:28<01:37,  1.27it/s, loss=0.1777]\u001b[A\nTraining:  21%|██        | 33/157 [00:29<01:37,  1.27it/s, loss=0.1713]\u001b[A\nTraining:  22%|██▏       | 34/157 [00:29<01:36,  1.28it/s, loss=0.1713]\u001b[A\nTraining:  22%|██▏       | 34/157 [00:30<01:36,  1.28it/s, loss=0.2328]\u001b[A\nTraining:  22%|██▏       | 35/157 [00:30<01:36,  1.27it/s, loss=0.2328]\u001b[A\nTraining:  22%|██▏       | 35/157 [00:30<01:36,  1.27it/s, loss=0.2520]\u001b[A\nTraining:  23%|██▎       | 36/157 [00:30<01:34,  1.28it/s, loss=0.2520]\u001b[A\nTraining:  23%|██▎       | 36/157 [00:31<01:34,  1.28it/s, loss=0.0944]\u001b[A\nTraining:  24%|██▎       | 37/157 [00:31<01:32,  1.30it/s, loss=0.0944]\u001b[A\nTraining:  24%|██▎       | 37/157 [00:32<01:32,  1.30it/s, loss=0.2900]\u001b[A\nTraining:  24%|██▍       | 38/157 [00:32<01:33,  1.27it/s, loss=0.2900]\u001b[A\nTraining:  24%|██▍       | 38/157 [00:33<01:33,  1.27it/s, loss=0.2738]\u001b[A\nTraining:  25%|██▍       | 39/157 [00:33<01:32,  1.28it/s, loss=0.2738]\u001b[A\nTraining:  25%|██▍       | 39/157 [00:34<01:32,  1.28it/s, loss=0.1927]\u001b[A\nTraining:  25%|██▌       | 40/157 [00:34<01:29,  1.31it/s, loss=0.1927]\u001b[A\nTraining:  25%|██▌       | 40/157 [00:34<01:29,  1.31it/s, loss=0.2061]\u001b[A\nTraining:  26%|██▌       | 41/157 [00:34<01:27,  1.32it/s, loss=0.2061]\u001b[A\nTraining:  26%|██▌       | 41/157 [00:35<01:27,  1.32it/s, loss=0.1304]\u001b[A\nTraining:  27%|██▋       | 42/157 [00:35<01:26,  1.34it/s, loss=0.1304]\u001b[A\nTraining:  27%|██▋       | 42/157 [00:36<01:26,  1.34it/s, loss=0.1699]\u001b[A\nTraining:  27%|██▋       | 43/157 [00:36<01:24,  1.34it/s, loss=0.1699]\u001b[A\nTraining:  27%|██▋       | 43/157 [00:37<01:24,  1.34it/s, loss=0.2495]\u001b[A\nTraining:  28%|██▊       | 44/157 [00:37<01:26,  1.30it/s, loss=0.2495]\u001b[A\nTraining:  28%|██▊       | 44/157 [00:37<01:26,  1.30it/s, loss=0.2666]\u001b[A\nTraining:  29%|██▊       | 45/157 [00:37<01:24,  1.32it/s, loss=0.2666]\u001b[A\nTraining:  29%|██▊       | 45/157 [00:38<01:24,  1.32it/s, loss=0.1880]\u001b[A\nTraining:  29%|██▉       | 46/157 [00:38<01:27,  1.27it/s, loss=0.1880]\u001b[A\nTraining:  29%|██▉       | 46/157 [00:39<01:27,  1.27it/s, loss=0.2189]\u001b[A\nTraining:  30%|██▉       | 47/157 [00:39<01:25,  1.29it/s, loss=0.2189]\u001b[A\nTraining:  30%|██▉       | 47/157 [00:40<01:25,  1.29it/s, loss=0.2138]\u001b[A\nTraining:  31%|███       | 48/157 [00:40<01:23,  1.31it/s, loss=0.2138]\u001b[A\nTraining:  31%|███       | 48/157 [00:40<01:23,  1.31it/s, loss=0.1958]\u001b[A\nTraining:  31%|███       | 49/157 [00:40<01:21,  1.32it/s, loss=0.1958]\u001b[A\nTraining:  31%|███       | 49/157 [00:41<01:21,  1.32it/s, loss=0.1283]\u001b[A\nTraining:  32%|███▏      | 50/157 [00:41<01:23,  1.29it/s, loss=0.1283]\u001b[A\nTraining:  32%|███▏      | 50/157 [00:42<01:23,  1.29it/s, loss=0.1477]\u001b[A\nTraining:  32%|███▏      | 51/157 [00:42<01:21,  1.30it/s, loss=0.1477]\u001b[A\nTraining:  32%|███▏      | 51/157 [00:43<01:21,  1.30it/s, loss=0.0484]\u001b[A\nTraining:  33%|███▎      | 52/157 [00:43<01:21,  1.30it/s, loss=0.0484]\u001b[A\nTraining:  33%|███▎      | 52/157 [00:43<01:21,  1.30it/s, loss=0.1028]\u001b[A\nTraining:  34%|███▍      | 53/157 [00:43<01:18,  1.32it/s, loss=0.1028]\u001b[A\nTraining:  34%|███▍      | 53/157 [00:44<01:18,  1.32it/s, loss=0.0628]\u001b[A\nTraining:  34%|███▍      | 54/157 [00:44<01:20,  1.28it/s, loss=0.0628]\u001b[A\nTraining:  34%|███▍      | 54/157 [00:45<01:20,  1.28it/s, loss=0.1060]\u001b[A\nTraining:  35%|███▌      | 55/157 [00:45<01:18,  1.30it/s, loss=0.1060]\u001b[A\nTraining:  35%|███▌      | 55/157 [00:46<01:18,  1.30it/s, loss=0.3517]\u001b[A\nTraining:  36%|███▌      | 56/157 [00:46<01:16,  1.31it/s, loss=0.3517]\u001b[A\nTraining:  36%|███▌      | 56/157 [00:47<01:16,  1.31it/s, loss=0.1601]\u001b[A\nTraining:  36%|███▋      | 57/157 [00:47<01:16,  1.30it/s, loss=0.1601]\u001b[A\nTraining:  36%|███▋      | 57/157 [00:47<01:16,  1.30it/s, loss=0.1736]\u001b[A\nTraining:  37%|███▋      | 58/157 [00:47<01:14,  1.32it/s, loss=0.1736]\u001b[A\nTraining:  37%|███▋      | 58/157 [00:48<01:14,  1.32it/s, loss=0.1280]\u001b[A\nTraining:  38%|███▊      | 59/157 [00:48<01:14,  1.32it/s, loss=0.1280]\u001b[A\nTraining:  38%|███▊      | 59/157 [00:49<01:14,  1.32it/s, loss=0.0671]\u001b[A\nTraining:  38%|███▊      | 60/157 [00:49<01:13,  1.33it/s, loss=0.0671]\u001b[A\nTraining:  38%|███▊      | 60/157 [00:49<01:13,  1.33it/s, loss=0.2109]\u001b[A\nTraining:  39%|███▉      | 61/157 [00:49<01:12,  1.33it/s, loss=0.2109]\u001b[A\nTraining:  39%|███▉      | 61/157 [00:50<01:12,  1.33it/s, loss=0.1178]\u001b[A\nTraining:  39%|███▉      | 62/157 [00:50<01:10,  1.34it/s, loss=0.1178]\u001b[A\nTraining:  39%|███▉      | 62/157 [00:51<01:10,  1.34it/s, loss=0.2937]\u001b[A\nTraining:  40%|████      | 63/157 [00:51<01:10,  1.34it/s, loss=0.2937]\u001b[A\nTraining:  40%|████      | 63/157 [00:52<01:10,  1.34it/s, loss=0.1187]\u001b[A\nTraining:  41%|████      | 64/157 [00:52<01:11,  1.30it/s, loss=0.1187]\u001b[A\nTraining:  41%|████      | 64/157 [00:53<01:11,  1.30it/s, loss=0.0495]\u001b[A\nTraining:  41%|████▏     | 65/157 [00:53<01:10,  1.31it/s, loss=0.0495]\u001b[A\nTraining:  41%|████▏     | 65/157 [00:53<01:10,  1.31it/s, loss=0.2971]\u001b[A\nTraining:  42%|████▏     | 66/157 [00:53<01:08,  1.33it/s, loss=0.2971]\u001b[A\nTraining:  42%|████▏     | 66/157 [00:54<01:08,  1.33it/s, loss=0.1884]\u001b[A\nTraining:  43%|████▎     | 67/157 [00:54<01:07,  1.33it/s, loss=0.1884]\u001b[A\nTraining:  43%|████▎     | 67/157 [00:55<01:07,  1.33it/s, loss=0.3775]\u001b[A\nTraining:  43%|████▎     | 68/157 [00:55<01:07,  1.33it/s, loss=0.3775]\u001b[A\nTraining:  43%|████▎     | 68/157 [00:56<01:07,  1.33it/s, loss=0.1241]\u001b[A\nTraining:  44%|████▍     | 69/157 [00:56<01:05,  1.33it/s, loss=0.1241]\u001b[A\nTraining:  44%|████▍     | 69/157 [00:56<01:05,  1.33it/s, loss=0.1194]\u001b[A\nTraining:  45%|████▍     | 70/157 [00:56<01:05,  1.32it/s, loss=0.1194]\u001b[A\nTraining:  45%|████▍     | 70/157 [00:57<01:05,  1.32it/s, loss=0.0869]\u001b[A\nTraining:  45%|████▌     | 71/157 [00:57<01:08,  1.26it/s, loss=0.0869]\u001b[A\nTraining:  45%|████▌     | 71/157 [00:58<01:08,  1.26it/s, loss=0.0959]\u001b[A\nTraining:  46%|████▌     | 72/157 [00:58<01:08,  1.23it/s, loss=0.0959]\u001b[A\nTraining:  46%|████▌     | 72/157 [00:59<01:08,  1.23it/s, loss=0.0591]\u001b[A\nTraining:  46%|████▋     | 73/157 [00:59<01:06,  1.26it/s, loss=0.0591]\u001b[A\nTraining:  46%|████▋     | 73/157 [00:59<01:06,  1.26it/s, loss=0.4633]\u001b[A\nTraining:  47%|████▋     | 74/157 [00:59<01:04,  1.29it/s, loss=0.4633]\u001b[A\nTraining:  47%|████▋     | 74/157 [01:00<01:04,  1.29it/s, loss=0.1837]\u001b[A\nTraining:  48%|████▊     | 75/157 [01:00<01:02,  1.32it/s, loss=0.1837]\u001b[A\nTraining:  48%|████▊     | 75/157 [01:01<01:02,  1.32it/s, loss=0.0749]\u001b[A\nTraining:  48%|████▊     | 76/157 [01:01<01:01,  1.32it/s, loss=0.0749]\u001b[A\nTraining:  48%|████▊     | 76/157 [01:02<01:01,  1.32it/s, loss=0.1725]\u001b[A\nTraining:  49%|████▉     | 77/157 [01:02<01:01,  1.31it/s, loss=0.1725]\u001b[A\nTraining:  49%|████▉     | 77/157 [01:03<01:01,  1.31it/s, loss=0.2226]\u001b[A\nTraining:  50%|████▉     | 78/157 [01:03<01:00,  1.31it/s, loss=0.2226]\u001b[A\nTraining:  50%|████▉     | 78/157 [01:03<01:00,  1.31it/s, loss=0.1050]\u001b[A\nTraining:  50%|█████     | 79/157 [01:03<00:58,  1.33it/s, loss=0.1050]\u001b[A\nTraining:  50%|█████     | 79/157 [01:04<00:58,  1.33it/s, loss=0.2617]\u001b[A\nTraining:  51%|█████     | 80/157 [01:04<00:57,  1.33it/s, loss=0.2617]\u001b[A\nTraining:  51%|█████     | 80/157 [01:05<00:57,  1.33it/s, loss=0.0965]\u001b[A\nTraining:  52%|█████▏    | 81/157 [01:05<00:57,  1.32it/s, loss=0.0965]\u001b[A\nTraining:  52%|█████▏    | 81/157 [01:06<00:57,  1.32it/s, loss=0.1790]\u001b[A\nTraining:  52%|█████▏    | 82/157 [01:06<00:56,  1.32it/s, loss=0.1790]\u001b[A\nTraining:  52%|█████▏    | 82/157 [01:06<00:56,  1.32it/s, loss=0.5772]\u001b[A\nTraining:  53%|█████▎    | 83/157 [01:06<00:58,  1.27it/s, loss=0.5772]\u001b[A\nTraining:  53%|█████▎    | 83/157 [01:07<00:58,  1.27it/s, loss=0.2549]\u001b[A\nTraining:  54%|█████▎    | 84/157 [01:07<00:56,  1.29it/s, loss=0.2549]\u001b[A\nTraining:  54%|█████▎    | 84/157 [01:08<00:56,  1.29it/s, loss=0.1933]\u001b[A\nTraining:  54%|█████▍    | 85/157 [01:08<00:55,  1.29it/s, loss=0.1933]\u001b[A\nTraining:  54%|█████▍    | 85/157 [01:09<00:55,  1.29it/s, loss=0.0868]\u001b[A\nTraining:  55%|█████▍    | 86/157 [01:09<00:54,  1.31it/s, loss=0.0868]\u001b[A\nTraining:  55%|█████▍    | 86/157 [01:09<00:54,  1.31it/s, loss=0.1472]\u001b[A\nTraining:  55%|█████▌    | 87/157 [01:09<00:52,  1.33it/s, loss=0.1472]\u001b[A\nTraining:  55%|█████▌    | 87/157 [01:10<00:52,  1.33it/s, loss=0.0857]\u001b[A\nTraining:  56%|█████▌    | 88/157 [01:10<00:51,  1.34it/s, loss=0.0857]\u001b[A\nTraining:  56%|█████▌    | 88/157 [01:11<00:51,  1.34it/s, loss=0.1055]\u001b[A\nTraining:  57%|█████▋    | 89/157 [01:11<00:50,  1.34it/s, loss=0.1055]\u001b[A\nTraining:  57%|█████▋    | 89/157 [01:12<00:50,  1.34it/s, loss=0.2224]\u001b[A\nTraining:  57%|█████▋    | 90/157 [01:12<00:50,  1.33it/s, loss=0.2224]\u001b[A\nTraining:  57%|█████▋    | 90/157 [01:12<00:50,  1.33it/s, loss=0.1856]\u001b[A\nTraining:  58%|█████▊    | 91/157 [01:12<00:49,  1.34it/s, loss=0.1856]\u001b[A\nTraining:  58%|█████▊    | 91/157 [01:13<00:49,  1.34it/s, loss=0.0716]\u001b[A\nTraining:  59%|█████▊    | 92/157 [01:13<00:49,  1.31it/s, loss=0.0716]\u001b[A\nTraining:  59%|█████▊    | 92/157 [01:14<00:49,  1.31it/s, loss=0.3026]\u001b[A\nTraining:  59%|█████▉    | 93/157 [01:14<00:48,  1.33it/s, loss=0.3026]\u001b[A\nTraining:  59%|█████▉    | 93/157 [01:15<00:48,  1.33it/s, loss=0.0634]\u001b[A\nTraining:  60%|█████▉    | 94/157 [01:15<00:47,  1.34it/s, loss=0.0634]\u001b[A\nTraining:  60%|█████▉    | 94/157 [01:15<00:47,  1.34it/s, loss=0.0805]\u001b[A\nTraining:  61%|██████    | 95/157 [01:15<00:46,  1.34it/s, loss=0.0805]\u001b[A\nTraining:  61%|██████    | 95/157 [01:16<00:46,  1.34it/s, loss=0.0496]\u001b[A\nTraining:  61%|██████    | 96/157 [01:16<00:45,  1.34it/s, loss=0.0496]\u001b[A\nTraining:  61%|██████    | 96/157 [01:17<00:45,  1.34it/s, loss=0.2072]\u001b[A\nTraining:  62%|██████▏   | 97/157 [01:17<00:44,  1.35it/s, loss=0.2072]\u001b[A\nTraining:  62%|██████▏   | 97/157 [01:18<00:44,  1.35it/s, loss=0.1976]\u001b[A\nTraining:  62%|██████▏   | 98/157 [01:18<00:43,  1.35it/s, loss=0.1976]\u001b[A\nTraining:  62%|██████▏   | 98/157 [01:18<00:43,  1.35it/s, loss=0.0783]\u001b[A\nTraining:  63%|██████▎   | 99/157 [01:18<00:42,  1.36it/s, loss=0.0783]\u001b[A\nTraining:  63%|██████▎   | 99/157 [01:19<00:42,  1.36it/s, loss=0.1561]\u001b[A\nTraining:  64%|██████▎   | 100/157 [01:19<00:42,  1.35it/s, loss=0.1561]\u001b[A\nTraining:  64%|██████▎   | 100/157 [01:20<00:42,  1.35it/s, loss=0.0674]\u001b[A\nTraining:  64%|██████▍   | 101/157 [01:20<00:41,  1.35it/s, loss=0.0674]\u001b[A\nTraining:  64%|██████▍   | 101/157 [01:21<00:41,  1.35it/s, loss=0.1663]\u001b[A\nTraining:  65%|██████▍   | 102/157 [01:21<00:40,  1.36it/s, loss=0.1663]\u001b[A\nTraining:  65%|██████▍   | 102/157 [01:21<00:40,  1.36it/s, loss=0.1311]\u001b[A\nTraining:  66%|██████▌   | 103/157 [01:21<00:39,  1.36it/s, loss=0.1311]\u001b[A\nTraining:  66%|██████▌   | 103/157 [01:22<00:39,  1.36it/s, loss=0.1189]\u001b[A\nTraining:  66%|██████▌   | 104/157 [01:22<00:40,  1.30it/s, loss=0.1189]\u001b[A\nTraining:  66%|██████▌   | 104/157 [01:23<00:40,  1.30it/s, loss=0.0702]\u001b[A\nTraining:  67%|██████▋   | 105/157 [01:23<00:40,  1.27it/s, loss=0.0702]\u001b[A\nTraining:  67%|██████▋   | 105/157 [01:24<00:40,  1.27it/s, loss=0.0305]\u001b[A\nTraining:  68%|██████▊   | 106/157 [01:24<00:39,  1.28it/s, loss=0.0305]\u001b[A\nTraining:  68%|██████▊   | 106/157 [01:24<00:39,  1.28it/s, loss=0.1040]\u001b[A\nTraining:  68%|██████▊   | 107/157 [01:24<00:38,  1.30it/s, loss=0.1040]\u001b[A\nTraining:  68%|██████▊   | 107/157 [01:25<00:38,  1.30it/s, loss=0.0341]\u001b[A\nTraining:  69%|██████▉   | 108/157 [01:25<00:37,  1.31it/s, loss=0.0341]\u001b[A\nTraining:  69%|██████▉   | 108/157 [01:26<00:37,  1.31it/s, loss=0.1045]\u001b[A\nTraining:  69%|██████▉   | 109/157 [01:26<00:37,  1.28it/s, loss=0.1045]\u001b[A\nTraining:  69%|██████▉   | 109/157 [01:27<00:37,  1.28it/s, loss=0.0706]\u001b[A\nTraining:  70%|███████   | 110/157 [01:27<00:36,  1.29it/s, loss=0.0706]\u001b[A\nTraining:  70%|███████   | 110/157 [01:28<00:36,  1.29it/s, loss=0.0665]\u001b[A\nTraining:  71%|███████   | 111/157 [01:28<00:35,  1.31it/s, loss=0.0665]\u001b[A\nTraining:  71%|███████   | 111/157 [01:28<00:35,  1.31it/s, loss=0.1279]\u001b[A\nTraining:  71%|███████▏  | 112/157 [01:28<00:35,  1.26it/s, loss=0.1279]\u001b[A\nTraining:  71%|███████▏  | 112/157 [01:29<00:35,  1.26it/s, loss=0.2906]\u001b[A\nTraining:  72%|███████▏  | 113/157 [01:29<00:34,  1.29it/s, loss=0.2906]\u001b[A\nTraining:  72%|███████▏  | 113/157 [01:30<00:34,  1.29it/s, loss=0.1565]\u001b[A\nTraining:  73%|███████▎  | 114/157 [01:30<00:33,  1.27it/s, loss=0.1565]\u001b[A\nTraining:  73%|███████▎  | 114/157 [01:31<00:33,  1.27it/s, loss=0.1153]\u001b[A\nTraining:  73%|███████▎  | 115/157 [01:31<00:32,  1.29it/s, loss=0.1153]\u001b[A\nTraining:  73%|███████▎  | 115/157 [01:31<00:32,  1.29it/s, loss=0.1723]\u001b[A\nTraining:  74%|███████▍  | 116/157 [01:31<00:31,  1.30it/s, loss=0.1723]\u001b[A\nTraining:  74%|███████▍  | 116/157 [01:32<00:31,  1.30it/s, loss=0.2357]\u001b[A\nTraining:  75%|███████▍  | 117/157 [01:32<00:30,  1.31it/s, loss=0.2357]\u001b[A\nTraining:  75%|███████▍  | 117/157 [01:33<00:30,  1.31it/s, loss=0.1090]\u001b[A\nTraining:  75%|███████▌  | 118/157 [01:33<00:30,  1.29it/s, loss=0.1090]\u001b[A\nTraining:  75%|███████▌  | 118/157 [01:34<00:30,  1.29it/s, loss=0.3506]\u001b[A\nTraining:  76%|███████▌  | 119/157 [01:34<00:29,  1.30it/s, loss=0.3506]\u001b[A\nTraining:  76%|███████▌  | 119/157 [01:35<00:29,  1.30it/s, loss=0.0631]\u001b[A\nTraining:  76%|███████▋  | 120/157 [01:35<00:29,  1.27it/s, loss=0.0631]\u001b[A\nTraining:  76%|███████▋  | 120/157 [01:35<00:29,  1.27it/s, loss=0.0404]\u001b[A\nTraining:  77%|███████▋  | 121/157 [01:35<00:27,  1.29it/s, loss=0.0404]\u001b[A\nTraining:  77%|███████▋  | 121/157 [01:36<00:27,  1.29it/s, loss=0.3071]\u001b[A\nTraining:  78%|███████▊  | 122/157 [01:36<00:26,  1.31it/s, loss=0.3071]\u001b[A\nTraining:  78%|███████▊  | 122/157 [01:37<00:26,  1.31it/s, loss=0.0931]\u001b[A\nTraining:  78%|███████▊  | 123/157 [01:37<00:25,  1.32it/s, loss=0.0931]\u001b[A\nTraining:  78%|███████▊  | 123/157 [01:38<00:25,  1.32it/s, loss=0.1585]\u001b[A\nTraining:  79%|███████▉  | 124/157 [01:38<00:25,  1.31it/s, loss=0.1585]\u001b[A\nTraining:  79%|███████▉  | 124/157 [01:38<00:25,  1.31it/s, loss=0.0629]\u001b[A\nTraining:  80%|███████▉  | 125/157 [01:38<00:24,  1.32it/s, loss=0.0629]\u001b[A\nTraining:  80%|███████▉  | 125/157 [01:39<00:24,  1.32it/s, loss=0.0357]\u001b[A\nTraining:  80%|████████  | 126/157 [01:39<00:23,  1.33it/s, loss=0.0357]\u001b[A\nTraining:  80%|████████  | 126/157 [01:40<00:23,  1.33it/s, loss=0.0510]\u001b[A\nTraining:  81%|████████  | 127/157 [01:40<00:22,  1.34it/s, loss=0.0510]\u001b[A\nTraining:  81%|████████  | 127/157 [01:41<00:22,  1.34it/s, loss=0.1845]\u001b[A\nTraining:  82%|████████▏ | 128/157 [01:41<00:22,  1.32it/s, loss=0.1845]\u001b[A\nTraining:  82%|████████▏ | 128/157 [01:41<00:22,  1.32it/s, loss=0.0722]\u001b[A\nTraining:  82%|████████▏ | 129/157 [01:41<00:21,  1.31it/s, loss=0.0722]\u001b[A\nTraining:  82%|████████▏ | 129/157 [01:42<00:21,  1.31it/s, loss=0.3288]\u001b[A\nTraining:  83%|████████▎ | 130/157 [01:42<00:20,  1.32it/s, loss=0.3288]\u001b[A\nTraining:  83%|████████▎ | 130/157 [01:43<00:20,  1.32it/s, loss=0.0923]\u001b[A\nTraining:  83%|████████▎ | 131/157 [01:43<00:20,  1.29it/s, loss=0.0923]\u001b[A\nTraining:  83%|████████▎ | 131/157 [01:44<00:20,  1.29it/s, loss=0.1008]\u001b[A\nTraining:  84%|████████▍ | 132/157 [01:44<00:19,  1.29it/s, loss=0.1008]\u001b[A\nTraining:  84%|████████▍ | 132/157 [01:44<00:19,  1.29it/s, loss=0.1152]\u001b[A\nTraining:  85%|████████▍ | 133/157 [01:44<00:18,  1.29it/s, loss=0.1152]\u001b[A\nTraining:  85%|████████▍ | 133/157 [01:45<00:18,  1.29it/s, loss=0.5131]\u001b[A\nTraining:  85%|████████▌ | 134/157 [01:45<00:17,  1.31it/s, loss=0.5131]\u001b[A\nTraining:  85%|████████▌ | 134/157 [01:46<00:17,  1.31it/s, loss=0.0592]\u001b[A\nTraining:  86%|████████▌ | 135/157 [01:46<00:16,  1.32it/s, loss=0.0592]\u001b[A\nTraining:  86%|████████▌ | 135/157 [01:47<00:16,  1.32it/s, loss=0.1006]\u001b[A\nTraining:  87%|████████▋ | 136/157 [01:47<00:15,  1.32it/s, loss=0.1006]\u001b[A\nTraining:  87%|████████▋ | 136/157 [01:47<00:15,  1.32it/s, loss=0.2377]\u001b[A\nTraining:  87%|████████▋ | 137/157 [01:47<00:15,  1.33it/s, loss=0.2377]\u001b[A\nTraining:  87%|████████▋ | 137/157 [01:48<00:15,  1.33it/s, loss=0.0476]\u001b[A\nTraining:  88%|████████▊ | 138/157 [01:48<00:14,  1.29it/s, loss=0.0476]\u001b[A\nTraining:  88%|████████▊ | 138/157 [01:49<00:14,  1.29it/s, loss=0.1195]\u001b[A\nTraining:  89%|████████▊ | 139/157 [01:49<00:13,  1.29it/s, loss=0.1195]\u001b[A\nTraining:  89%|████████▊ | 139/157 [01:50<00:13,  1.29it/s, loss=0.1431]\u001b[A\nTraining:  89%|████████▉ | 140/157 [01:50<00:13,  1.30it/s, loss=0.1431]\u001b[A\nTraining:  89%|████████▉ | 140/157 [01:51<00:13,  1.30it/s, loss=0.1260]\u001b[A\nTraining:  90%|████████▉ | 141/157 [01:51<00:12,  1.32it/s, loss=0.1260]\u001b[A\nTraining:  90%|████████▉ | 141/157 [01:51<00:12,  1.32it/s, loss=0.1786]\u001b[A\nTraining:  90%|█████████ | 142/157 [01:51<00:11,  1.30it/s, loss=0.1786]\u001b[A\nTraining:  90%|█████████ | 142/157 [01:52<00:11,  1.30it/s, loss=0.3160]\u001b[A\nTraining:  91%|█████████ | 143/157 [01:52<00:10,  1.31it/s, loss=0.3160]\u001b[A\nTraining:  91%|█████████ | 143/157 [01:53<00:10,  1.31it/s, loss=0.0943]\u001b[A\nTraining:  92%|█████████▏| 144/157 [01:53<00:10,  1.28it/s, loss=0.0943]\u001b[A\nTraining:  92%|█████████▏| 144/157 [01:54<00:10,  1.28it/s, loss=0.3376]\u001b[A\nTraining:  92%|█████████▏| 145/157 [01:54<00:09,  1.31it/s, loss=0.3376]\u001b[A\nTraining:  92%|█████████▏| 145/157 [01:54<00:09,  1.31it/s, loss=0.1270]\u001b[A\nTraining:  93%|█████████▎| 146/157 [01:54<00:08,  1.31it/s, loss=0.1270]\u001b[A\nTraining:  93%|█████████▎| 146/157 [01:55<00:08,  1.31it/s, loss=0.0853]\u001b[A\nTraining:  94%|█████████▎| 147/157 [01:55<00:07,  1.33it/s, loss=0.0853]\u001b[A\nTraining:  94%|█████████▎| 147/157 [01:56<00:07,  1.33it/s, loss=0.0379]\u001b[A\nTraining:  94%|█████████▍| 148/157 [01:56<00:06,  1.33it/s, loss=0.0379]\u001b[A\nTraining:  94%|█████████▍| 148/157 [01:57<00:06,  1.33it/s, loss=0.0420]\u001b[A\nTraining:  95%|█████████▍| 149/157 [01:57<00:05,  1.34it/s, loss=0.0420]\u001b[A\nTraining:  95%|█████████▍| 149/157 [01:57<00:05,  1.34it/s, loss=0.1262]\u001b[A\nTraining:  96%|█████████▌| 150/157 [01:57<00:05,  1.36it/s, loss=0.1262]\u001b[A\nTraining:  96%|█████████▌| 150/157 [01:58<00:05,  1.36it/s, loss=0.0504]\u001b[A\nTraining:  96%|█████████▌| 151/157 [01:58<00:04,  1.37it/s, loss=0.0504]\u001b[A\nTraining:  96%|█████████▌| 151/157 [01:59<00:04,  1.37it/s, loss=0.1241]\u001b[A\nTraining:  97%|█████████▋| 152/157 [01:59<00:03,  1.38it/s, loss=0.1241]\u001b[A\nTraining:  97%|█████████▋| 152/157 [01:59<00:03,  1.38it/s, loss=0.0541]\u001b[A\nTraining:  97%|█████████▋| 153/157 [01:59<00:02,  1.38it/s, loss=0.0541]\u001b[A\nTraining:  97%|█████████▋| 153/157 [02:00<00:02,  1.38it/s, loss=0.1477]\u001b[A\nTraining:  98%|█████████▊| 154/157 [02:00<00:02,  1.36it/s, loss=0.1477]\u001b[A\nTraining:  98%|█████████▊| 154/157 [02:01<00:02,  1.36it/s, loss=0.0179]\u001b[A\nTraining:  99%|█████████▊| 155/157 [02:01<00:01,  1.36it/s, loss=0.0179]\u001b[A\nTraining:  99%|█████████▊| 155/157 [02:02<00:01,  1.36it/s, loss=0.1387]\u001b[A\nTraining:  99%|█████████▉| 156/157 [02:02<00:00,  1.37it/s, loss=0.1387]\u001b[A\nTraining:  99%|█████████▉| 156/157 [02:02<00:00,  1.37it/s, loss=0.1449]\u001b[A\nTraining: 100%|██████████| 157/157 [02:02<00:00,  1.65it/s, loss=0.1449]\u001b[A\n                                                                        \u001b[A\nValidation:   0%|          | 0/389 [00:00<?, ?it/s]\u001b[A\nValidation:   0%|          | 0/389 [00:05<?, ?it/s, loss=0.0001]\u001b[A\nValidation:   0%|          | 1/389 [00:05<33:32,  5.19s/it, loss=0.0001]\u001b[A\nValidation:   0%|          | 1/389 [00:06<33:32,  5.19s/it, loss=0.0004]\u001b[A\nValidation:   1%|          | 2/389 [00:06<18:04,  2.80s/it, loss=0.0004]\u001b[A\nValidation:   1%|          | 2/389 [00:07<18:04,  2.80s/it, loss=0.0001]\u001b[A\nValidation:   1%|          | 3/389 [00:07<12:36,  1.96s/it, loss=0.0001]\u001b[A\nValidation:   1%|          | 3/389 [00:08<12:36,  1.96s/it, loss=0.0024]\u001b[A\nValidation:   1%|          | 4/389 [00:08<09:58,  1.55s/it, loss=0.0024]\u001b[A\nValidation:   1%|          | 4/389 [00:09<09:58,  1.55s/it, loss=0.0003]\u001b[A\nValidation:   1%|▏         | 5/389 [00:09<08:31,  1.33s/it, loss=0.0003]\u001b[A\nValidation:   1%|▏         | 5/389 [00:10<08:31,  1.33s/it, loss=0.0176]\u001b[A\nValidation:   2%|▏         | 6/389 [00:10<07:58,  1.25s/it, loss=0.0176]\u001b[A\nValidation:   2%|▏         | 6/389 [00:11<07:58,  1.25s/it, loss=0.0579]\u001b[A\nValidation:   2%|▏         | 7/389 [00:11<07:26,  1.17s/it, loss=0.0579]\u001b[A\nValidation:   2%|▏         | 7/389 [00:12<07:26,  1.17s/it, loss=0.0000]\u001b[A\nValidation:   2%|▏         | 8/389 [00:12<06:57,  1.10s/it, loss=0.0000]\u001b[A\nValidation:   2%|▏         | 8/389 [00:13<06:57,  1.10s/it, loss=0.0000]\u001b[A\nValidation:   2%|▏         | 9/389 [00:13<06:36,  1.04s/it, loss=0.0000]\u001b[A\nValidation:   2%|▏         | 9/389 [00:14<06:36,  1.04s/it, loss=0.0001]\u001b[A\nValidation:   3%|▎         | 10/389 [00:14<06:24,  1.01s/it, loss=0.0001]\u001b[A\nValidation:   3%|▎         | 10/389 [00:15<06:24,  1.01s/it, loss=0.0001]\u001b[A\nValidation:   3%|▎         | 11/389 [00:15<06:17,  1.00it/s, loss=0.0001]\u001b[A\nValidation:   3%|▎         | 11/389 [00:15<06:17,  1.00it/s, loss=0.0000]\u001b[A\nValidation:   3%|▎         | 12/389 [00:15<06:08,  1.02it/s, loss=0.0000]\u001b[A\nValidation:   3%|▎         | 12/389 [00:16<06:08,  1.02it/s, loss=0.0000]\u001b[A\nValidation:   3%|▎         | 13/389 [00:16<06:02,  1.04it/s, loss=0.0000]\u001b[A\nValidation:   3%|▎         | 13/389 [00:17<06:02,  1.04it/s, loss=0.0000]\u001b[A\nValidation:   4%|▎         | 14/389 [00:17<05:59,  1.04it/s, loss=0.0000]\u001b[A\nValidation:   4%|▎         | 14/389 [00:18<05:59,  1.04it/s, loss=0.0000]\u001b[A\nValidation:   4%|▍         | 15/389 [00:18<05:56,  1.05it/s, loss=0.0000]\u001b[A\nValidation:   4%|▍         | 15/389 [00:19<05:56,  1.05it/s, loss=0.0000]\u001b[A\nValidation:   4%|▍         | 16/389 [00:19<05:58,  1.04it/s, loss=0.0000]\u001b[A\nValidation:   4%|▍         | 16/389 [00:20<05:58,  1.04it/s, loss=0.0014]\u001b[A\nValidation:   4%|▍         | 17/389 [00:20<06:00,  1.03it/s, loss=0.0014]\u001b[A\nValidation:   4%|▍         | 17/389 [00:21<06:00,  1.03it/s, loss=0.0012]\u001b[A\nValidation:   5%|▍         | 18/389 [00:21<05:56,  1.04it/s, loss=0.0012]\u001b[A\nValidation:   5%|▍         | 18/389 [00:22<05:56,  1.04it/s, loss=0.0225]\u001b[A\nValidation:   5%|▍         | 19/389 [00:22<05:54,  1.04it/s, loss=0.0225]\u001b[A\nValidation:   5%|▍         | 19/389 [00:23<05:54,  1.04it/s, loss=0.0096]\u001b[A\nValidation:   5%|▌         | 20/389 [00:23<06:29,  1.06s/it, loss=0.0096]\u001b[A\nValidation:   5%|▌         | 20/389 [00:24<06:29,  1.06s/it, loss=0.0190]\u001b[A\nValidation:   5%|▌         | 21/389 [00:24<06:17,  1.03s/it, loss=0.0190]\u001b[A\nValidation:   5%|▌         | 21/389 [00:25<06:17,  1.03s/it, loss=0.0000]\u001b[A\nValidation:   6%|▌         | 22/389 [00:25<06:08,  1.01s/it, loss=0.0000]\u001b[A\nValidation:   6%|▌         | 22/389 [00:26<06:08,  1.01s/it, loss=0.0000]\u001b[A\nValidation:   6%|▌         | 23/389 [00:26<06:14,  1.02s/it, loss=0.0000]\u001b[A\nValidation:   6%|▌         | 23/389 [00:27<06:14,  1.02s/it, loss=0.0859]\u001b[A\nValidation:   6%|▌         | 24/389 [00:27<06:07,  1.01s/it, loss=0.0859]\u001b[A\nValidation:   6%|▌         | 24/389 [00:28<06:07,  1.01s/it, loss=0.0288]\u001b[A\nValidation:   6%|▋         | 25/389 [00:28<06:01,  1.01it/s, loss=0.0288]\u001b[A\nValidation:   6%|▋         | 25/389 [00:30<06:01,  1.01it/s, loss=0.0777]\u001b[A\nValidation:   7%|▋         | 26/389 [00:30<06:36,  1.09s/it, loss=0.0777]\u001b[A\nValidation:   7%|▋         | 26/389 [00:31<06:36,  1.09s/it, loss=0.1042]\u001b[A\nValidation:   7%|▋         | 27/389 [00:31<06:26,  1.07s/it, loss=0.1042]\u001b[A\nValidation:   7%|▋         | 27/389 [00:32<06:26,  1.07s/it, loss=0.0003]\u001b[A\nValidation:   7%|▋         | 28/389 [00:32<06:14,  1.04s/it, loss=0.0003]\u001b[A\nValidation:   7%|▋         | 28/389 [00:33<06:14,  1.04s/it, loss=0.0053]\u001b[A\nValidation:   7%|▋         | 29/389 [00:33<06:03,  1.01s/it, loss=0.0053]\u001b[A\nValidation:   7%|▋         | 29/389 [00:34<06:03,  1.01s/it, loss=0.1043]\u001b[A\nValidation:   8%|▊         | 30/389 [00:34<05:55,  1.01it/s, loss=0.1043]\u001b[A\nValidation:   8%|▊         | 30/389 [00:34<05:55,  1.01it/s, loss=0.0411]\u001b[A\nValidation:   8%|▊         | 31/389 [00:34<05:50,  1.02it/s, loss=0.0411]\u001b[A\nValidation:   8%|▊         | 31/389 [00:36<05:50,  1.02it/s, loss=0.0002]\u001b[A\nValidation:   8%|▊         | 32/389 [00:36<05:56,  1.00it/s, loss=0.0002]\u001b[A\nValidation:   8%|▊         | 32/389 [00:36<05:56,  1.00it/s, loss=0.0501]\u001b[A\nValidation:   8%|▊         | 33/389 [00:36<05:48,  1.02it/s, loss=0.0501]\u001b[A\nValidation:   8%|▊         | 33/389 [00:38<05:48,  1.02it/s, loss=0.2277]\u001b[A\nValidation:   9%|▊         | 34/389 [00:38<06:04,  1.03s/it, loss=0.2277]\u001b[A\nValidation:   9%|▊         | 34/389 [00:39<06:04,  1.03s/it, loss=0.0159]\u001b[A\nValidation:   9%|▉         | 35/389 [00:39<05:57,  1.01s/it, loss=0.0159]\u001b[A\nValidation:   9%|▉         | 35/389 [00:40<05:57,  1.01s/it, loss=0.0011]\u001b[A\nValidation:   9%|▉         | 36/389 [00:40<05:51,  1.00it/s, loss=0.0011]\u001b[A\nValidation:   9%|▉         | 36/389 [00:41<05:51,  1.00it/s, loss=0.0009]\u001b[A\nValidation:  10%|▉         | 37/389 [00:41<05:50,  1.01it/s, loss=0.0009]\u001b[A\nValidation:  10%|▉         | 37/389 [00:41<05:50,  1.01it/s, loss=0.0007]\u001b[A\nValidation:  10%|▉         | 38/389 [00:41<05:43,  1.02it/s, loss=0.0007]\u001b[A\nValidation:  10%|▉         | 38/389 [00:42<05:43,  1.02it/s, loss=0.0008]\u001b[A\nValidation:  10%|█         | 39/389 [00:42<05:38,  1.04it/s, loss=0.0008]\u001b[A\nValidation:  10%|█         | 39/389 [00:43<05:38,  1.04it/s, loss=0.0232]\u001b[A\nValidation:  10%|█         | 40/389 [00:43<05:37,  1.03it/s, loss=0.0232]\u001b[A\nValidation:  10%|█         | 40/389 [00:44<05:37,  1.03it/s, loss=0.2208]\u001b[A\nValidation:  11%|█         | 41/389 [00:44<05:55,  1.02s/it, loss=0.2208]\u001b[A\nValidation:  11%|█         | 41/389 [00:45<05:55,  1.02s/it, loss=0.2053]\u001b[A\nValidation:  11%|█         | 42/389 [00:45<05:48,  1.01s/it, loss=0.2053]\u001b[A\nValidation:  11%|█         | 42/389 [00:46<05:48,  1.01s/it, loss=0.2404]\u001b[A\nValidation:  11%|█         | 43/389 [00:46<05:42,  1.01it/s, loss=0.2404]\u001b[A\nValidation:  11%|█         | 43/389 [00:47<05:42,  1.01it/s, loss=0.2181]\u001b[A\nValidation:  11%|█▏        | 44/389 [00:47<05:35,  1.03it/s, loss=0.2181]\u001b[A\nValidation:  11%|█▏        | 44/389 [00:48<05:35,  1.03it/s, loss=0.2080]\u001b[A\nValidation:  12%|█▏        | 45/389 [00:48<05:32,  1.03it/s, loss=0.2080]\u001b[A\nValidation:  12%|█▏        | 45/389 [00:49<05:32,  1.03it/s, loss=0.2448]\u001b[A\nValidation:  12%|█▏        | 46/389 [00:49<05:30,  1.04it/s, loss=0.2448]\u001b[A\nValidation:  12%|█▏        | 46/389 [00:50<05:30,  1.04it/s, loss=0.0704]\u001b[A\nValidation:  12%|█▏        | 47/389 [00:50<05:35,  1.02it/s, loss=0.0704]\u001b[A\nValidation:  12%|█▏        | 47/389 [00:51<05:35,  1.02it/s, loss=0.0463]\u001b[A\nValidation:  12%|█▏        | 48/389 [00:51<05:30,  1.03it/s, loss=0.0463]\u001b[A\nValidation:  12%|█▏        | 48/389 [00:52<05:30,  1.03it/s, loss=0.0462]\u001b[A\nValidation:  13%|█▎        | 49/389 [00:52<05:27,  1.04it/s, loss=0.0462]\u001b[A\nValidation:  13%|█▎        | 49/389 [00:53<05:27,  1.04it/s, loss=0.0661]\u001b[A\nValidation:  13%|█▎        | 50/389 [00:53<05:23,  1.05it/s, loss=0.0661]\u001b[A\nValidation:  13%|█▎        | 50/389 [00:54<05:23,  1.05it/s, loss=0.0146]\u001b[A\nValidation:  13%|█▎        | 51/389 [00:54<05:22,  1.05it/s, loss=0.0146]\u001b[A\nValidation:  13%|█▎        | 51/389 [00:55<05:22,  1.05it/s, loss=0.0183]\u001b[A\nValidation:  13%|█▎        | 52/389 [00:55<05:40,  1.01s/it, loss=0.0183]\u001b[A\nValidation:  13%|█▎        | 52/389 [00:56<05:40,  1.01s/it, loss=0.0847]\u001b[A\nValidation:  14%|█▎        | 53/389 [00:56<05:32,  1.01it/s, loss=0.0847]\u001b[A\nValidation:  14%|█▎        | 53/389 [00:57<05:32,  1.01it/s, loss=0.0186]\u001b[A\nValidation:  14%|█▍        | 54/389 [00:57<05:31,  1.01it/s, loss=0.0186]\u001b[A\nValidation:  14%|█▍        | 54/389 [00:58<05:31,  1.01it/s, loss=0.0371]\u001b[A\nValidation:  14%|█▍        | 55/389 [00:58<05:26,  1.02it/s, loss=0.0371]\u001b[A\nValidation:  14%|█▍        | 55/389 [00:59<05:26,  1.02it/s, loss=0.0700]\u001b[A\nValidation:  14%|█▍        | 56/389 [00:59<05:23,  1.03it/s, loss=0.0700]\u001b[A\nValidation:  14%|█▍        | 56/389 [01:00<05:23,  1.03it/s, loss=0.0894]\u001b[A\nValidation:  15%|█▍        | 57/389 [01:00<05:30,  1.01it/s, loss=0.0894]\u001b[A\nValidation:  15%|█▍        | 57/389 [01:01<05:30,  1.01it/s, loss=0.0804]\u001b[A\nValidation:  15%|█▍        | 58/389 [01:01<05:30,  1.00it/s, loss=0.0804]\u001b[A\nValidation:  15%|█▍        | 58/389 [01:02<05:30,  1.00it/s, loss=0.1307]\u001b[A\nValidation:  15%|█▌        | 59/389 [01:02<05:39,  1.03s/it, loss=0.1307]\u001b[A\nValidation:  15%|█▌        | 59/389 [01:03<05:39,  1.03s/it, loss=0.0887]\u001b[A\nValidation:  15%|█▌        | 60/389 [01:03<05:31,  1.01s/it, loss=0.0887]\u001b[A\nValidation:  15%|█▌        | 60/389 [01:04<05:31,  1.01s/it, loss=0.0615]\u001b[A\nValidation:  16%|█▌        | 61/389 [01:04<05:23,  1.01it/s, loss=0.0615]\u001b[A\nValidation:  16%|█▌        | 61/389 [01:05<05:23,  1.01it/s, loss=0.1129]\u001b[A\nValidation:  16%|█▌        | 62/389 [01:05<05:20,  1.02it/s, loss=0.1129]\u001b[A\nValidation:  16%|█▌        | 62/389 [01:06<05:20,  1.02it/s, loss=0.0280]\u001b[A\nValidation:  16%|█▌        | 63/389 [01:06<05:15,  1.03it/s, loss=0.0280]\u001b[A\nValidation:  16%|█▌        | 63/389 [01:07<05:15,  1.03it/s, loss=0.0157]\u001b[A\nValidation:  16%|█▋        | 64/389 [01:07<05:11,  1.04it/s, loss=0.0157]\u001b[A\nValidation:  16%|█▋        | 64/389 [01:08<05:11,  1.04it/s, loss=0.0061]\u001b[A\nValidation:  17%|█▋        | 65/389 [01:08<05:07,  1.05it/s, loss=0.0061]\u001b[A\nValidation:  17%|█▋        | 65/389 [01:09<05:07,  1.05it/s, loss=0.0163]\u001b[A\nValidation:  17%|█▋        | 66/389 [01:09<05:08,  1.05it/s, loss=0.0163]\u001b[A\nValidation:  17%|█▋        | 66/389 [01:10<05:08,  1.05it/s, loss=0.0077]\u001b[A\nValidation:  17%|█▋        | 67/389 [01:10<05:10,  1.04it/s, loss=0.0077]\u001b[A\nValidation:  17%|█▋        | 67/389 [01:11<05:10,  1.04it/s, loss=0.1373]\u001b[A\nValidation:  17%|█▋        | 68/389 [01:11<05:09,  1.04it/s, loss=0.1373]\u001b[A\nValidation:  17%|█▋        | 68/389 [01:12<05:09,  1.04it/s, loss=0.2312]\u001b[A\nValidation:  18%|█▊        | 69/389 [01:12<05:08,  1.04it/s, loss=0.2312]\u001b[A\nValidation:  18%|█▊        | 69/389 [01:13<05:08,  1.04it/s, loss=0.1287]\u001b[A\nValidation:  18%|█▊        | 70/389 [01:13<05:06,  1.04it/s, loss=0.1287]\u001b[A\nValidation:  18%|█▊        | 70/389 [01:14<05:06,  1.04it/s, loss=0.1993]\u001b[A\nValidation:  18%|█▊        | 71/389 [01:14<05:15,  1.01it/s, loss=0.1993]\u001b[A\nValidation:  18%|█▊        | 71/389 [01:15<05:15,  1.01it/s, loss=0.1584]\u001b[A\nValidation:  19%|█▊        | 72/389 [01:15<05:20,  1.01s/it, loss=0.1584]\u001b[A\nValidation:  19%|█▊        | 72/389 [01:16<05:20,  1.01s/it, loss=0.1324]\u001b[A\nValidation:  19%|█▉        | 73/389 [01:16<05:20,  1.01s/it, loss=0.1324]\u001b[A\nValidation:  19%|█▉        | 73/389 [01:17<05:20,  1.01s/it, loss=0.1173]\u001b[A\nValidation:  19%|█▉        | 74/389 [01:17<05:12,  1.01it/s, loss=0.1173]\u001b[A\nValidation:  19%|█▉        | 74/389 [01:18<05:12,  1.01it/s, loss=0.0047]\u001b[A\nValidation:  19%|█▉        | 75/389 [01:18<05:06,  1.03it/s, loss=0.0047]\u001b[A\nValidation:  19%|█▉        | 75/389 [01:19<05:06,  1.03it/s, loss=0.0192]\u001b[A\nValidation:  20%|█▉        | 76/389 [01:19<05:02,  1.04it/s, loss=0.0192]\u001b[A\nValidation:  20%|█▉        | 76/389 [01:20<05:02,  1.04it/s, loss=0.0093]\u001b[A\nValidation:  20%|█▉        | 77/389 [01:20<05:13,  1.00s/it, loss=0.0093]\u001b[A\nValidation:  20%|█▉        | 77/389 [01:21<05:13,  1.00s/it, loss=0.0064]\u001b[A\nValidation:  20%|██        | 78/389 [01:21<05:13,  1.01s/it, loss=0.0064]\u001b[A\nValidation:  20%|██        | 78/389 [01:22<05:13,  1.01s/it, loss=0.0361]\u001b[A\nValidation:  20%|██        | 79/389 [01:22<05:05,  1.01it/s, loss=0.0361]\u001b[A\nValidation:  20%|██        | 79/389 [01:23<05:05,  1.01it/s, loss=0.0083]\u001b[A\nValidation:  21%|██        | 80/389 [01:23<05:20,  1.04s/it, loss=0.0083]\u001b[A\nValidation:  21%|██        | 80/389 [01:24<05:20,  1.04s/it, loss=0.0220]\u001b[A\nValidation:  21%|██        | 81/389 [01:24<05:20,  1.04s/it, loss=0.0220]\u001b[A\nValidation:  21%|██        | 81/389 [01:25<05:20,  1.04s/it, loss=0.0291]\u001b[A\nValidation:  21%|██        | 82/389 [01:25<05:14,  1.02s/it, loss=0.0291]\u001b[A\nValidation:  21%|██        | 82/389 [01:26<05:14,  1.02s/it, loss=0.0179]\u001b[A\nValidation:  21%|██▏       | 83/389 [01:26<05:09,  1.01s/it, loss=0.0179]\u001b[A\nValidation:  21%|██▏       | 83/389 [01:27<05:09,  1.01s/it, loss=0.0419]\u001b[A\nValidation:  22%|██▏       | 84/389 [01:27<05:05,  1.00s/it, loss=0.0419]\u001b[A\nValidation:  22%|██▏       | 84/389 [01:28<05:05,  1.00s/it, loss=0.0221]\u001b[A\nValidation:  22%|██▏       | 85/389 [01:28<05:03,  1.00it/s, loss=0.0221]\u001b[A\nValidation:  22%|██▏       | 85/389 [01:29<05:03,  1.00it/s, loss=0.0672]\u001b[A\nValidation:  22%|██▏       | 86/389 [01:29<04:58,  1.02it/s, loss=0.0672]\u001b[A\nValidation:  22%|██▏       | 86/389 [01:30<04:58,  1.02it/s, loss=0.2183]\u001b[A\nValidation:  22%|██▏       | 87/389 [01:30<04:54,  1.02it/s, loss=0.2183]\u001b[A\nValidation:  22%|██▏       | 87/389 [01:31<04:54,  1.02it/s, loss=0.1525]\u001b[A\nValidation:  23%|██▎       | 88/389 [01:31<04:57,  1.01it/s, loss=0.1525]\u001b[A\nValidation:  23%|██▎       | 88/389 [01:32<04:57,  1.01it/s, loss=0.1847]\u001b[A\nValidation:  23%|██▎       | 89/389 [01:32<04:57,  1.01it/s, loss=0.1847]\u001b[A\nValidation:  23%|██▎       | 89/389 [01:33<04:57,  1.01it/s, loss=0.0876]\u001b[A\nValidation:  23%|██▎       | 90/389 [01:33<05:16,  1.06s/it, loss=0.0876]\u001b[A\nValidation:  23%|██▎       | 90/389 [01:34<05:16,  1.06s/it, loss=0.2100]\u001b[A\nValidation:  23%|██▎       | 91/389 [01:34<05:14,  1.06s/it, loss=0.2100]\u001b[A\nValidation:  23%|██▎       | 91/389 [01:35<05:14,  1.06s/it, loss=0.3185]\u001b[A\nValidation:  24%|██▎       | 92/389 [01:35<05:05,  1.03s/it, loss=0.3185]\u001b[A\nValidation:  24%|██▎       | 92/389 [01:36<05:05,  1.03s/it, loss=0.2944]\u001b[A\nValidation:  24%|██▍       | 93/389 [01:36<04:57,  1.00s/it, loss=0.2944]\u001b[A\nValidation:  24%|██▍       | 93/389 [01:37<04:57,  1.00s/it, loss=0.1813]\u001b[A\nValidation:  24%|██▍       | 94/389 [01:37<05:08,  1.05s/it, loss=0.1813]\u001b[A\nValidation:  24%|██▍       | 94/389 [01:38<05:08,  1.05s/it, loss=0.2074]\u001b[A\nValidation:  24%|██▍       | 95/389 [01:38<05:08,  1.05s/it, loss=0.2074]\u001b[A\nValidation:  24%|██▍       | 95/389 [01:39<05:08,  1.05s/it, loss=0.3255]\u001b[A\nValidation:  25%|██▍       | 96/389 [01:39<05:05,  1.04s/it, loss=0.3255]\u001b[A\nValidation:  25%|██▍       | 96/389 [01:40<05:05,  1.04s/it, loss=0.5330]\u001b[A\nValidation:  25%|██▍       | 97/389 [01:40<05:01,  1.03s/it, loss=0.5330]\u001b[A\nValidation:  25%|██▍       | 97/389 [01:41<05:01,  1.03s/it, loss=0.1781]\u001b[A\nValidation:  25%|██▌       | 98/389 [01:41<04:54,  1.01s/it, loss=0.1781]\u001b[A\nValidation:  25%|██▌       | 98/389 [01:42<04:54,  1.01s/it, loss=0.1999]\u001b[A\nValidation:  25%|██▌       | 99/389 [01:42<04:48,  1.00it/s, loss=0.1999]\u001b[A\nValidation:  25%|██▌       | 99/389 [01:43<04:48,  1.00it/s, loss=0.2028]\u001b[A\nValidation:  26%|██▌       | 100/389 [01:43<04:44,  1.02it/s, loss=0.2028]\u001b[A\nValidation:  26%|██▌       | 100/389 [01:44<04:44,  1.02it/s, loss=0.3190]\u001b[A\nValidation:  26%|██▌       | 101/389 [01:44<04:40,  1.03it/s, loss=0.3190]\u001b[A\nValidation:  26%|██▌       | 101/389 [01:45<04:40,  1.03it/s, loss=0.2566]\u001b[A\nValidation:  26%|██▌       | 102/389 [01:45<04:38,  1.03it/s, loss=0.2566]\u001b[A\nValidation:  26%|██▌       | 102/389 [01:46<04:38,  1.03it/s, loss=0.1715]\u001b[A\nValidation:  26%|██▋       | 103/389 [01:46<04:35,  1.04it/s, loss=0.1715]\u001b[A\nValidation:  26%|██▋       | 103/389 [01:47<04:35,  1.04it/s, loss=0.2182]\u001b[A\nValidation:  27%|██▋       | 104/389 [01:47<04:34,  1.04it/s, loss=0.2182]\u001b[A\nValidation:  27%|██▋       | 104/389 [01:48<04:34,  1.04it/s, loss=0.1370]\u001b[A\nValidation:  27%|██▋       | 105/389 [01:48<04:33,  1.04it/s, loss=0.1370]\u001b[A\nValidation:  27%|██▋       | 105/389 [01:49<04:33,  1.04it/s, loss=0.1089]\u001b[A\nValidation:  27%|██▋       | 106/389 [01:49<04:31,  1.04it/s, loss=0.1089]\u001b[A\nValidation:  27%|██▋       | 106/389 [01:50<04:31,  1.04it/s, loss=0.0597]\u001b[A\nValidation:  28%|██▊       | 107/389 [01:50<04:30,  1.04it/s, loss=0.0597]\u001b[A\nValidation:  28%|██▊       | 107/389 [01:51<04:30,  1.04it/s, loss=0.0904]\u001b[A\nValidation:  28%|██▊       | 108/389 [01:51<04:37,  1.01it/s, loss=0.0904]\u001b[A\nValidation:  28%|██▊       | 108/389 [01:52<04:37,  1.01it/s, loss=0.1017]\u001b[A\nValidation:  28%|██▊       | 109/389 [01:52<04:33,  1.02it/s, loss=0.1017]\u001b[A\nValidation:  28%|██▊       | 109/389 [01:53<04:33,  1.02it/s, loss=0.4154]\u001b[A\nValidation:  28%|██▊       | 110/389 [01:53<04:29,  1.03it/s, loss=0.4154]\u001b[A\nValidation:  28%|██▊       | 110/389 [01:54<04:29,  1.03it/s, loss=0.4911]\u001b[A\nValidation:  29%|██▊       | 111/389 [01:54<04:28,  1.04it/s, loss=0.4911]\u001b[A\nValidation:  29%|██▊       | 111/389 [01:55<04:28,  1.04it/s, loss=0.4920]\u001b[A\nValidation:  29%|██▉       | 112/389 [01:55<04:26,  1.04it/s, loss=0.4920]\u001b[A\nValidation:  29%|██▉       | 112/389 [01:56<04:26,  1.04it/s, loss=0.5163]\u001b[A\nValidation:  29%|██▉       | 113/389 [01:56<04:26,  1.04it/s, loss=0.5163]\u001b[A\nValidation:  29%|██▉       | 113/389 [01:57<04:26,  1.04it/s, loss=0.4849]\u001b[A\nValidation:  29%|██▉       | 114/389 [01:57<04:30,  1.02it/s, loss=0.4849]\u001b[A\nValidation:  29%|██▉       | 114/389 [01:58<04:30,  1.02it/s, loss=0.1790]\u001b[A\nValidation:  30%|██▉       | 115/389 [01:58<04:28,  1.02it/s, loss=0.1790]\u001b[A\nValidation:  30%|██▉       | 115/389 [01:59<04:28,  1.02it/s, loss=0.1892]\u001b[A\nValidation:  30%|██▉       | 116/389 [01:59<04:38,  1.02s/it, loss=0.1892]\u001b[A\nValidation:  30%|██▉       | 116/389 [02:00<04:38,  1.02s/it, loss=0.2229]\u001b[A\nValidation:  30%|███       | 117/389 [02:00<04:32,  1.00s/it, loss=0.2229]\u001b[A\nValidation:  30%|███       | 117/389 [02:01<04:32,  1.00s/it, loss=0.1245]\u001b[A\nValidation:  30%|███       | 118/389 [02:01<04:33,  1.01s/it, loss=0.1245]\u001b[A\nValidation:  30%|███       | 118/389 [02:02<04:33,  1.01s/it, loss=0.1990]\u001b[A\nValidation:  31%|███       | 119/389 [02:02<04:27,  1.01it/s, loss=0.1990]\u001b[A\nValidation:  31%|███       | 119/389 [02:03<04:27,  1.01it/s, loss=0.1998]\u001b[A\nValidation:  31%|███       | 120/389 [02:03<04:31,  1.01s/it, loss=0.1998]\u001b[A\nValidation:  31%|███       | 120/389 [02:04<04:31,  1.01s/it, loss=0.0838]\u001b[A\nValidation:  31%|███       | 121/389 [02:04<04:39,  1.04s/it, loss=0.0838]\u001b[A\nValidation:  31%|███       | 121/389 [02:05<04:39,  1.04s/it, loss=0.0469]\u001b[A\nValidation:  31%|███▏      | 122/389 [02:05<04:57,  1.11s/it, loss=0.0469]\u001b[A\nValidation:  31%|███▏      | 122/389 [02:06<04:57,  1.11s/it, loss=0.0984]\u001b[A\nValidation:  32%|███▏      | 123/389 [02:06<04:45,  1.07s/it, loss=0.0984]\u001b[A\nValidation:  32%|███▏      | 123/389 [02:07<04:45,  1.07s/it, loss=0.0586]\u001b[A\nValidation:  32%|███▏      | 124/389 [02:07<04:35,  1.04s/it, loss=0.0586]\u001b[A\nValidation:  32%|███▏      | 124/389 [02:08<04:35,  1.04s/it, loss=0.0816]\u001b[A\nValidation:  32%|███▏      | 125/389 [02:08<04:26,  1.01s/it, loss=0.0816]\u001b[A\nValidation:  32%|███▏      | 125/389 [02:09<04:26,  1.01s/it, loss=0.1918]\u001b[A\nValidation:  32%|███▏      | 126/389 [02:09<04:20,  1.01it/s, loss=0.1918]\u001b[A\nValidation:  32%|███▏      | 126/389 [02:10<04:20,  1.01it/s, loss=0.3010]\u001b[A\nValidation:  33%|███▎      | 127/389 [02:10<04:20,  1.00it/s, loss=0.3010]\u001b[A\nValidation:  33%|███▎      | 127/389 [02:11<04:20,  1.00it/s, loss=0.2817]\u001b[A\nValidation:  33%|███▎      | 128/389 [02:11<04:15,  1.02it/s, loss=0.2817]\u001b[A\nValidation:  33%|███▎      | 128/389 [02:12<04:15,  1.02it/s, loss=0.2843]\u001b[A\nValidation:  33%|███▎      | 129/389 [02:12<04:10,  1.04it/s, loss=0.2843]\u001b[A\nValidation:  33%|███▎      | 129/389 [02:13<04:10,  1.04it/s, loss=0.2296]\u001b[A\nValidation:  33%|███▎      | 130/389 [02:13<04:09,  1.04it/s, loss=0.2296]\u001b[A\nValidation:  33%|███▎      | 130/389 [02:14<04:09,  1.04it/s, loss=0.2522]\u001b[A\nValidation:  34%|███▎      | 131/389 [02:14<04:09,  1.03it/s, loss=0.2522]\u001b[A\nValidation:  34%|███▎      | 131/389 [02:15<04:09,  1.03it/s, loss=0.1999]\u001b[A\nValidation:  34%|███▍      | 132/389 [02:15<04:05,  1.05it/s, loss=0.1999]\u001b[A\nValidation:  34%|███▍      | 132/389 [02:16<04:05,  1.05it/s, loss=0.0294]\u001b[A\nValidation:  34%|███▍      | 133/389 [02:16<04:03,  1.05it/s, loss=0.0294]\u001b[A\nValidation:  34%|███▍      | 133/389 [02:17<04:03,  1.05it/s, loss=0.0279]\u001b[A\nValidation:  34%|███▍      | 134/389 [02:17<04:01,  1.06it/s, loss=0.0279]\u001b[A\nValidation:  34%|███▍      | 134/389 [02:18<04:01,  1.06it/s, loss=0.0216]\u001b[A\nValidation:  35%|███▍      | 135/389 [02:18<04:02,  1.05it/s, loss=0.0216]\u001b[A\nValidation:  35%|███▍      | 135/389 [02:18<04:02,  1.05it/s, loss=0.0306]\u001b[A\nValidation:  35%|███▍      | 136/389 [02:18<04:01,  1.05it/s, loss=0.0306]\u001b[A\nValidation:  35%|███▍      | 136/389 [02:19<04:01,  1.05it/s, loss=0.0223]\u001b[A\nValidation:  35%|███▌      | 137/389 [02:19<03:59,  1.05it/s, loss=0.0223]\u001b[A\nValidation:  35%|███▌      | 137/389 [02:20<03:59,  1.05it/s, loss=0.0205]\u001b[A\nValidation:  35%|███▌      | 138/389 [02:20<04:01,  1.04it/s, loss=0.0205]\u001b[A\nValidation:  35%|███▌      | 138/389 [02:22<04:01,  1.04it/s, loss=0.0506]\u001b[A\nValidation:  36%|███▌      | 139/389 [02:22<04:20,  1.04s/it, loss=0.0506]\u001b[A\nValidation:  36%|███▌      | 139/389 [02:23<04:20,  1.04s/it, loss=0.0544]\u001b[A\nValidation:  36%|███▌      | 140/389 [02:23<04:11,  1.01s/it, loss=0.0544]\u001b[A\nValidation:  36%|███▌      | 140/389 [02:24<04:11,  1.01s/it, loss=0.0603]\u001b[A\nValidation:  36%|███▌      | 141/389 [02:24<04:06,  1.01it/s, loss=0.0603]\u001b[A\nValidation:  36%|███▌      | 141/389 [02:24<04:06,  1.01it/s, loss=0.0905]\u001b[A\nValidation:  37%|███▋      | 142/389 [02:24<04:01,  1.02it/s, loss=0.0905]\u001b[A\nValidation:  37%|███▋      | 142/389 [02:26<04:01,  1.02it/s, loss=0.0561]\u001b[A\nValidation:  37%|███▋      | 143/389 [02:26<04:08,  1.01s/it, loss=0.0561]\u001b[A\nValidation:  37%|███▋      | 143/389 [02:27<04:08,  1.01s/it, loss=0.6858]\u001b[A\nValidation:  37%|███▋      | 144/389 [02:27<04:06,  1.01s/it, loss=0.6858]\u001b[A\nValidation:  37%|███▋      | 144/389 [02:28<04:06,  1.01s/it, loss=0.6004]\u001b[A\nValidation:  37%|███▋      | 145/389 [02:28<04:02,  1.01it/s, loss=0.6004]\u001b[A\nValidation:  37%|███▋      | 145/389 [02:29<04:02,  1.01it/s, loss=0.5681]\u001b[A\nValidation:  38%|███▊      | 146/389 [02:29<04:05,  1.01s/it, loss=0.5681]\u001b[A\nValidation:  38%|███▊      | 146/389 [02:29<04:05,  1.01s/it, loss=0.6797]\u001b[A\nValidation:  38%|███▊      | 147/389 [02:29<03:59,  1.01it/s, loss=0.6797]\u001b[A\nValidation:  38%|███▊      | 147/389 [02:30<03:59,  1.01it/s, loss=0.5378]\u001b[A\nValidation:  38%|███▊      | 148/389 [02:30<03:57,  1.01it/s, loss=0.5378]\u001b[A\nValidation:  38%|███▊      | 148/389 [02:32<03:57,  1.01it/s, loss=0.5919]\u001b[A\nValidation:  38%|███▊      | 149/389 [02:32<04:01,  1.01s/it, loss=0.5919]\u001b[A\nValidation:  38%|███▊      | 149/389 [02:33<04:01,  1.01s/it, loss=1.0468]\u001b[A\nValidation:  39%|███▊      | 150/389 [02:33<04:06,  1.03s/it, loss=1.0468]\u001b[A\nValidation:  39%|███▊      | 150/389 [02:34<04:06,  1.03s/it, loss=1.3136]\u001b[A\nValidation:  39%|███▉      | 151/389 [02:34<04:00,  1.01s/it, loss=1.3136]\u001b[A\nValidation:  39%|███▉      | 151/389 [02:35<04:00,  1.01s/it, loss=1.7401]\u001b[A\nValidation:  39%|███▉      | 152/389 [02:35<03:54,  1.01it/s, loss=1.7401]\u001b[A\nValidation:  39%|███▉      | 152/389 [02:36<03:54,  1.01it/s, loss=1.5318]\u001b[A\nValidation:  39%|███▉      | 153/389 [02:36<04:03,  1.03s/it, loss=1.5318]\u001b[A\nValidation:  39%|███▉      | 153/389 [02:37<04:03,  1.03s/it, loss=1.2937]\u001b[A\nValidation:  40%|███▉      | 154/389 [02:37<04:23,  1.12s/it, loss=1.2937]\u001b[A\nValidation:  40%|███▉      | 154/389 [02:38<04:23,  1.12s/it, loss=1.3507]\u001b[A\nValidation:  40%|███▉      | 155/389 [02:38<04:08,  1.06s/it, loss=1.3507]\u001b[A\nValidation:  40%|███▉      | 155/389 [02:39<04:08,  1.06s/it, loss=1.4888]\u001b[A\nValidation:  40%|████      | 156/389 [02:39<04:00,  1.03s/it, loss=1.4888]\u001b[A\nValidation:  40%|████      | 156/389 [02:40<04:00,  1.03s/it, loss=1.3370]\u001b[A\nValidation:  40%|████      | 157/389 [02:40<03:54,  1.01s/it, loss=1.3370]\u001b[A\nValidation:  40%|████      | 157/389 [02:41<03:54,  1.01s/it, loss=0.9875]\u001b[A\nValidation:  41%|████      | 158/389 [02:41<03:50,  1.00it/s, loss=0.9875]\u001b[A\nValidation:  41%|████      | 158/389 [02:42<03:50,  1.00it/s, loss=1.4095]\u001b[A\nValidation:  41%|████      | 159/389 [02:42<03:49,  1.00it/s, loss=1.4095]\u001b[A\nValidation:  41%|████      | 159/389 [02:43<03:49,  1.00it/s, loss=1.4708]\u001b[A\nValidation:  41%|████      | 160/389 [02:43<03:48,  1.00it/s, loss=1.4708]\u001b[A\nValidation:  41%|████      | 160/389 [02:44<03:48,  1.00it/s, loss=1.4743]\u001b[A\nValidation:  41%|████▏     | 161/389 [02:44<03:43,  1.02it/s, loss=1.4743]\u001b[A\nValidation:  41%|████▏     | 161/389 [02:45<03:43,  1.02it/s, loss=1.4914]\u001b[A\nValidation:  42%|████▏     | 162/389 [02:45<03:40,  1.03it/s, loss=1.4914]\u001b[A\nValidation:  42%|████▏     | 162/389 [02:46<03:40,  1.03it/s, loss=0.7189]\u001b[A\nValidation:  42%|████▏     | 163/389 [02:46<03:42,  1.01it/s, loss=0.7189]\u001b[A\nValidation:  42%|████▏     | 163/389 [02:47<03:42,  1.01it/s, loss=0.1105]\u001b[A\nValidation:  42%|████▏     | 164/389 [02:47<03:38,  1.03it/s, loss=0.1105]\u001b[A\nValidation:  42%|████▏     | 164/389 [02:48<03:38,  1.03it/s, loss=0.0512]\u001b[A\nValidation:  42%|████▏     | 165/389 [02:48<03:34,  1.04it/s, loss=0.0512]\u001b[A\nValidation:  42%|████▏     | 165/389 [02:48<03:34,  1.04it/s, loss=0.1398]\u001b[A\nValidation:  43%|████▎     | 166/389 [02:48<03:32,  1.05it/s, loss=0.1398]\u001b[A\nValidation:  43%|████▎     | 166/389 [02:49<03:32,  1.05it/s, loss=0.0904]\u001b[A\nValidation:  43%|████▎     | 167/389 [02:49<03:31,  1.05it/s, loss=0.0904]\u001b[A\nValidation:  43%|████▎     | 167/389 [02:50<03:31,  1.05it/s, loss=0.2716]\u001b[A\nValidation:  43%|████▎     | 168/389 [02:50<03:33,  1.03it/s, loss=0.2716]\u001b[A\nValidation:  43%|████▎     | 168/389 [02:51<03:33,  1.03it/s, loss=0.2884]\u001b[A\nValidation:  43%|████▎     | 169/389 [02:51<03:29,  1.05it/s, loss=0.2884]\u001b[A\nValidation:  43%|████▎     | 169/389 [02:52<03:29,  1.05it/s, loss=0.2241]\u001b[A\nValidation:  44%|████▎     | 170/389 [02:52<03:27,  1.05it/s, loss=0.2241]\u001b[A\nValidation:  44%|████▎     | 170/389 [02:53<03:27,  1.05it/s, loss=0.2397]\u001b[A\nValidation:  44%|████▍     | 171/389 [02:53<03:26,  1.05it/s, loss=0.2397]\u001b[A\nValidation:  44%|████▍     | 171/389 [02:54<03:26,  1.05it/s, loss=0.3553]\u001b[A\nValidation:  44%|████▍     | 172/389 [02:54<03:25,  1.06it/s, loss=0.3553]\u001b[A\nValidation:  44%|████▍     | 172/389 [02:55<03:25,  1.06it/s, loss=0.1768]\u001b[A\nValidation:  44%|████▍     | 173/389 [02:55<03:24,  1.06it/s, loss=0.1768]\u001b[A\nValidation:  44%|████▍     | 173/389 [02:56<03:24,  1.06it/s, loss=0.1545]\u001b[A\nValidation:  45%|████▍     | 174/389 [02:56<03:25,  1.05it/s, loss=0.1545]\u001b[A\nValidation:  45%|████▍     | 174/389 [02:57<03:25,  1.05it/s, loss=0.2354]\u001b[A\nValidation:  45%|████▍     | 175/389 [02:57<03:23,  1.05it/s, loss=0.2354]\u001b[A\nValidation:  45%|████▍     | 175/389 [02:58<03:23,  1.05it/s, loss=0.2487]\u001b[A\nValidation:  45%|████▌     | 176/389 [02:58<03:24,  1.04it/s, loss=0.2487]\u001b[A\nValidation:  45%|████▌     | 176/389 [02:59<03:24,  1.04it/s, loss=0.1638]\u001b[A\nValidation:  46%|████▌     | 177/389 [02:59<03:23,  1.04it/s, loss=0.1638]\u001b[A\nValidation:  46%|████▌     | 177/389 [03:00<03:23,  1.04it/s, loss=0.2296]\u001b[A\nValidation:  46%|████▌     | 178/389 [03:00<03:26,  1.02it/s, loss=0.2296]\u001b[A\nValidation:  46%|████▌     | 178/389 [03:01<03:26,  1.02it/s, loss=0.1397]\u001b[A\nValidation:  46%|████▌     | 179/389 [03:01<03:22,  1.04it/s, loss=0.1397]\u001b[A\nValidation:  46%|████▌     | 179/389 [03:02<03:22,  1.04it/s, loss=0.0475]\u001b[A\nValidation:  46%|████▋     | 180/389 [03:02<03:19,  1.05it/s, loss=0.0475]\u001b[A\nValidation:  46%|████▋     | 180/389 [03:03<03:19,  1.05it/s, loss=0.0522]\u001b[A\nValidation:  47%|████▋     | 181/389 [03:03<03:17,  1.05it/s, loss=0.0522]\u001b[A\nValidation:  47%|████▋     | 181/389 [03:04<03:17,  1.05it/s, loss=0.0288]\u001b[A\nValidation:  47%|████▋     | 182/389 [03:04<03:16,  1.06it/s, loss=0.0288]\u001b[A\nValidation:  47%|████▋     | 182/389 [03:05<03:16,  1.06it/s, loss=0.0295]\u001b[A\nValidation:  47%|████▋     | 183/389 [03:05<03:16,  1.05it/s, loss=0.0295]\u001b[A\nValidation:  47%|████▋     | 183/389 [03:06<03:16,  1.05it/s, loss=1.3718]\u001b[A\nValidation:  47%|████▋     | 184/389 [03:06<03:28,  1.02s/it, loss=1.3718]\u001b[A\nValidation:  47%|████▋     | 184/389 [03:07<03:28,  1.02s/it, loss=1.3120]\u001b[A\nValidation:  48%|████▊     | 185/389 [03:07<03:44,  1.10s/it, loss=1.3120]\u001b[A\nValidation:  48%|████▊     | 185/389 [03:09<03:44,  1.10s/it, loss=1.5708]\u001b[A\nValidation:  48%|████▊     | 186/389 [03:09<03:56,  1.16s/it, loss=1.5708]\u001b[A\nValidation:  48%|████▊     | 186/389 [03:09<03:56,  1.16s/it, loss=1.4706]\u001b[A\nValidation:  48%|████▊     | 187/389 [03:09<03:42,  1.10s/it, loss=1.4706]\u001b[A\nValidation:  48%|████▊     | 187/389 [03:10<03:42,  1.10s/it, loss=1.8893]\u001b[A\nValidation:  48%|████▊     | 188/389 [03:10<03:36,  1.08s/it, loss=1.8893]\u001b[A\nValidation:  48%|████▊     | 188/389 [03:11<03:36,  1.08s/it, loss=1.2500]\u001b[A\nValidation:  49%|████▊     | 189/389 [03:11<03:28,  1.04s/it, loss=1.2500]\u001b[A\nValidation:  49%|████▊     | 189/389 [03:12<03:28,  1.04s/it, loss=1.5832]\u001b[A\nValidation:  49%|████▉     | 190/389 [03:12<03:22,  1.02s/it, loss=1.5832]\u001b[A\nValidation:  49%|████▉     | 190/389 [03:13<03:22,  1.02s/it, loss=0.2992]\u001b[A\nValidation:  49%|████▉     | 191/389 [03:13<03:17,  1.00it/s, loss=0.2992]\u001b[A\nValidation:  49%|████▉     | 191/389 [03:14<03:17,  1.00it/s, loss=0.1012]\u001b[A\nValidation:  49%|████▉     | 192/389 [03:14<03:15,  1.01it/s, loss=0.1012]\u001b[A\nValidation:  49%|████▉     | 192/389 [03:15<03:15,  1.01it/s, loss=0.1832]\u001b[A\nValidation:  50%|████▉     | 193/389 [03:15<03:15,  1.00it/s, loss=0.1832]\u001b[A\nValidation:  50%|████▉     | 193/389 [03:16<03:15,  1.00it/s, loss=0.1044]\u001b[A\nValidation:  50%|████▉     | 194/389 [03:16<03:11,  1.02it/s, loss=0.1044]\u001b[A\nValidation:  50%|████▉     | 194/389 [03:17<03:11,  1.02it/s, loss=0.1550]\u001b[A\nValidation:  50%|█████     | 195/389 [03:17<03:08,  1.03it/s, loss=0.1550]\u001b[A\nValidation:  50%|█████     | 195/389 [03:18<03:08,  1.03it/s, loss=0.1440]\u001b[A\nValidation:  50%|█████     | 196/389 [03:18<03:06,  1.03it/s, loss=0.1440]\u001b[A\nValidation:  50%|█████     | 196/389 [03:19<03:06,  1.03it/s, loss=0.1137]\u001b[A\nValidation:  51%|█████     | 197/389 [03:19<03:04,  1.04it/s, loss=0.1137]\u001b[A\nValidation:  51%|█████     | 197/389 [03:20<03:04,  1.04it/s, loss=0.1539]\u001b[A\nValidation:  51%|█████     | 198/389 [03:20<03:06,  1.02it/s, loss=0.1539]\u001b[A\nValidation:  51%|█████     | 198/389 [03:21<03:06,  1.02it/s, loss=0.1570]\u001b[A\nValidation:  51%|█████     | 199/389 [03:21<03:05,  1.03it/s, loss=0.1570]\u001b[A\nValidation:  51%|█████     | 199/389 [03:22<03:05,  1.03it/s, loss=0.1512]\u001b[A\nValidation:  51%|█████▏    | 200/389 [03:22<03:02,  1.04it/s, loss=0.1512]\u001b[A\nValidation:  51%|█████▏    | 200/389 [03:23<03:02,  1.04it/s, loss=0.1353]\u001b[A\nValidation:  52%|█████▏    | 201/389 [03:23<02:59,  1.05it/s, loss=0.1353]\u001b[A\nValidation:  52%|█████▏    | 201/389 [03:24<02:59,  1.05it/s, loss=0.1564]\u001b[A\nValidation:  52%|█████▏    | 202/389 [03:24<03:01,  1.03it/s, loss=0.1564]\u001b[A\nValidation:  52%|█████▏    | 202/389 [03:25<03:01,  1.03it/s, loss=0.0657]\u001b[A\nValidation:  52%|█████▏    | 203/389 [03:25<02:58,  1.04it/s, loss=0.0657]\u001b[A\nValidation:  52%|█████▏    | 203/389 [03:26<02:58,  1.04it/s, loss=0.0520]\u001b[A\nValidation:  52%|█████▏    | 204/389 [03:26<02:57,  1.04it/s, loss=0.0520]\u001b[A\nValidation:  52%|█████▏    | 204/389 [03:27<02:57,  1.04it/s, loss=0.0798]\u001b[A\nValidation:  53%|█████▎    | 205/389 [03:27<02:55,  1.05it/s, loss=0.0798]\u001b[A\nValidation:  53%|█████▎    | 205/389 [03:28<02:55,  1.05it/s, loss=0.0848]\u001b[A\nValidation:  53%|█████▎    | 206/389 [03:28<02:54,  1.05it/s, loss=0.0848]\u001b[A\nValidation:  53%|█████▎    | 206/389 [03:29<02:54,  1.05it/s, loss=0.0579]\u001b[A\nValidation:  53%|█████▎    | 207/389 [03:29<03:06,  1.02s/it, loss=0.0579]\u001b[A\nValidation:  53%|█████▎    | 207/389 [03:30<03:06,  1.02s/it, loss=0.5504]\u001b[A\nValidation:  53%|█████▎    | 208/389 [03:30<03:07,  1.04s/it, loss=0.5504]\u001b[A\nValidation:  53%|█████▎    | 208/389 [03:31<03:07,  1.04s/it, loss=0.8056]\u001b[A\nValidation:  54%|█████▎    | 209/389 [03:31<03:01,  1.01s/it, loss=0.8056]\u001b[A\nValidation:  54%|█████▎    | 209/389 [03:32<03:01,  1.01s/it, loss=0.9260]\u001b[A\nValidation:  54%|█████▍    | 210/389 [03:32<02:57,  1.01it/s, loss=0.9260]\u001b[A\nValidation:  54%|█████▍    | 210/389 [03:33<02:57,  1.01it/s, loss=0.7780]\u001b[A\nValidation:  54%|█████▍    | 211/389 [03:33<02:54,  1.02it/s, loss=0.7780]\u001b[A\nValidation:  54%|█████▍    | 211/389 [03:34<02:54,  1.02it/s, loss=1.1390]\u001b[A\nValidation:  54%|█████▍    | 212/389 [03:34<03:00,  1.02s/it, loss=1.1390]\u001b[A\nValidation:  54%|█████▍    | 212/389 [03:35<03:00,  1.02s/it, loss=1.1649]\u001b[A\nValidation:  55%|█████▍    | 213/389 [03:35<02:56,  1.00s/it, loss=1.1649]\u001b[A\nValidation:  55%|█████▍    | 213/389 [03:36<02:56,  1.00s/it, loss=0.9699]\u001b[A\nValidation:  55%|█████▌    | 214/389 [03:36<02:52,  1.02it/s, loss=0.9699]\u001b[A\nValidation:  55%|█████▌    | 214/389 [03:37<02:52,  1.02it/s, loss=2.1867]\u001b[A\nValidation:  55%|█████▌    | 215/389 [03:37<02:48,  1.03it/s, loss=2.1867]\u001b[A\nValidation:  55%|█████▌    | 215/389 [03:38<02:48,  1.03it/s, loss=1.6701]\u001b[A\nValidation:  56%|█████▌    | 216/389 [03:38<02:46,  1.04it/s, loss=1.6701]\u001b[A\nValidation:  56%|█████▌    | 216/389 [03:39<02:46,  1.04it/s, loss=1.8308]\u001b[A\nValidation:  56%|█████▌    | 217/389 [03:39<03:03,  1.07s/it, loss=1.8308]\u001b[A\nValidation:  56%|█████▌    | 217/389 [03:40<03:03,  1.07s/it, loss=2.0450]\u001b[A\nValidation:  56%|█████▌    | 218/389 [03:40<03:03,  1.07s/it, loss=2.0450]\u001b[A\nValidation:  56%|█████▌    | 218/389 [03:41<03:03,  1.07s/it, loss=2.2863]\u001b[A\nValidation:  56%|█████▋    | 219/389 [03:41<02:56,  1.04s/it, loss=2.2863]\u001b[A\nValidation:  56%|█████▋    | 219/389 [03:42<02:56,  1.04s/it, loss=2.1612]\u001b[A\nValidation:  57%|█████▋    | 220/389 [03:42<02:54,  1.03s/it, loss=2.1612]\u001b[A\nValidation:  57%|█████▋    | 220/389 [03:43<02:54,  1.03s/it, loss=1.1456]\u001b[A\nValidation:  57%|█████▋    | 221/389 [03:43<02:48,  1.00s/it, loss=1.1456]\u001b[A\nValidation:  57%|█████▋    | 221/389 [03:44<02:48,  1.00s/it, loss=0.7457]\u001b[A\nValidation:  57%|█████▋    | 222/389 [03:44<02:44,  1.02it/s, loss=0.7457]\u001b[A\nValidation:  57%|█████▋    | 222/389 [03:45<02:44,  1.02it/s, loss=0.5769]\u001b[A\nValidation:  57%|█████▋    | 223/389 [03:45<02:41,  1.03it/s, loss=0.5769]\u001b[A\nValidation:  57%|█████▋    | 223/389 [03:46<02:41,  1.03it/s, loss=1.0153]\u001b[A\nValidation:  58%|█████▊    | 224/389 [03:46<02:39,  1.03it/s, loss=1.0153]\u001b[A\nValidation:  58%|█████▊    | 224/389 [03:47<02:39,  1.03it/s, loss=0.8093]\u001b[A\nValidation:  58%|█████▊    | 225/389 [03:47<02:37,  1.04it/s, loss=0.8093]\u001b[A\nValidation:  58%|█████▊    | 225/389 [03:48<02:37,  1.04it/s, loss=0.2092]\u001b[A\nValidation:  58%|█████▊    | 226/389 [03:48<02:36,  1.04it/s, loss=0.2092]\u001b[A\nValidation:  58%|█████▊    | 226/389 [03:49<02:36,  1.04it/s, loss=0.0123]\u001b[A\nValidation:  58%|█████▊    | 227/389 [03:49<02:35,  1.04it/s, loss=0.0123]\u001b[A\nValidation:  58%|█████▊    | 227/389 [03:50<02:35,  1.04it/s, loss=0.0536]\u001b[A\nValidation:  59%|█████▊    | 228/389 [03:50<02:34,  1.04it/s, loss=0.0536]\u001b[A\nValidation:  59%|█████▊    | 228/389 [03:51<02:34,  1.04it/s, loss=0.0617]\u001b[A\nValidation:  59%|█████▉    | 229/389 [03:51<02:33,  1.04it/s, loss=0.0617]\u001b[A\nValidation:  59%|█████▉    | 229/389 [03:52<02:33,  1.04it/s, loss=0.1048]\u001b[A\nValidation:  59%|█████▉    | 230/389 [03:52<02:31,  1.05it/s, loss=0.1048]\u001b[A\nValidation:  59%|█████▉    | 230/389 [03:53<02:31,  1.05it/s, loss=0.0969]\u001b[A\nValidation:  59%|█████▉    | 231/389 [03:53<02:30,  1.05it/s, loss=0.0969]\u001b[A\nValidation:  59%|█████▉    | 231/389 [03:54<02:30,  1.05it/s, loss=0.1082]\u001b[A\nValidation:  60%|█████▉    | 232/389 [03:54<02:28,  1.05it/s, loss=0.1082]\u001b[A\nValidation:  60%|█████▉    | 232/389 [03:54<02:28,  1.05it/s, loss=0.0759]\u001b[A\nValidation:  60%|█████▉    | 233/389 [03:54<02:27,  1.06it/s, loss=0.0759]\u001b[A\nValidation:  60%|█████▉    | 233/389 [03:55<02:27,  1.06it/s, loss=0.1078]\u001b[A\nValidation:  60%|██████    | 234/389 [03:55<02:26,  1.06it/s, loss=0.1078]\u001b[A\nValidation:  60%|██████    | 234/389 [03:56<02:26,  1.06it/s, loss=0.1868]\u001b[A\nValidation:  60%|██████    | 235/389 [03:56<02:24,  1.06it/s, loss=0.1868]\u001b[A\nValidation:  60%|██████    | 235/389 [03:57<02:24,  1.06it/s, loss=0.1449]\u001b[A\nValidation:  61%|██████    | 236/389 [03:57<02:24,  1.06it/s, loss=0.1449]\u001b[A\nValidation:  61%|██████    | 236/389 [03:58<02:24,  1.06it/s, loss=0.1079]\u001b[A\nValidation:  61%|██████    | 237/389 [03:58<02:23,  1.06it/s, loss=0.1079]\u001b[A\nValidation:  61%|██████    | 237/389 [03:59<02:23,  1.06it/s, loss=0.0631]\u001b[A\nValidation:  61%|██████    | 238/389 [03:59<02:25,  1.04it/s, loss=0.0631]\u001b[A\nValidation:  61%|██████    | 238/389 [04:00<02:25,  1.04it/s, loss=0.0432]\u001b[A\nValidation:  61%|██████▏   | 239/389 [04:00<02:26,  1.02it/s, loss=0.0432]\u001b[A\nValidation:  61%|██████▏   | 239/389 [04:01<02:26,  1.02it/s, loss=0.0482]\u001b[A\nValidation:  62%|██████▏   | 240/389 [04:01<02:23,  1.04it/s, loss=0.0482]\u001b[A\nValidation:  62%|██████▏   | 240/389 [04:02<02:23,  1.04it/s, loss=0.0548]\u001b[A\nValidation:  62%|██████▏   | 241/389 [04:02<02:23,  1.03it/s, loss=0.0548]\u001b[A\nValidation:  62%|██████▏   | 241/389 [04:03<02:23,  1.03it/s, loss=0.6936]\u001b[A\nValidation:  62%|██████▏   | 242/389 [04:03<02:21,  1.04it/s, loss=0.6936]\u001b[A\nValidation:  62%|██████▏   | 242/389 [04:04<02:21,  1.04it/s, loss=1.4595]\u001b[A\nValidation:  62%|██████▏   | 243/389 [04:04<02:20,  1.04it/s, loss=1.4595]\u001b[A\nValidation:  62%|██████▏   | 243/389 [04:05<02:20,  1.04it/s, loss=0.9629]\u001b[A\nValidation:  63%|██████▎   | 244/389 [04:05<02:19,  1.04it/s, loss=0.9629]\u001b[A\nValidation:  63%|██████▎   | 244/389 [04:06<02:19,  1.04it/s, loss=1.0293]\u001b[A\nValidation:  63%|██████▎   | 245/389 [04:06<02:17,  1.04it/s, loss=1.0293]\u001b[A\nValidation:  63%|██████▎   | 245/389 [04:07<02:17,  1.04it/s, loss=1.0793]\u001b[A\nValidation:  63%|██████▎   | 246/389 [04:07<02:16,  1.05it/s, loss=1.0793]\u001b[A\nValidation:  63%|██████▎   | 246/389 [04:08<02:16,  1.05it/s, loss=1.0319]\u001b[A\nValidation:  63%|██████▎   | 247/389 [04:08<02:15,  1.05it/s, loss=1.0319]\u001b[A\nValidation:  63%|██████▎   | 247/389 [04:09<02:15,  1.05it/s, loss=1.1520]\u001b[A\nValidation:  64%|██████▍   | 248/389 [04:09<02:13,  1.06it/s, loss=1.1520]\u001b[A\nValidation:  64%|██████▍   | 248/389 [04:10<02:13,  1.06it/s, loss=0.0558]\u001b[A\nValidation:  64%|██████▍   | 249/389 [04:10<02:16,  1.02it/s, loss=0.0558]\u001b[A\nValidation:  64%|██████▍   | 249/389 [04:11<02:16,  1.02it/s, loss=0.2573]\u001b[A\nValidation:  64%|██████▍   | 250/389 [04:11<02:29,  1.07s/it, loss=0.2573]\u001b[A\nValidation:  64%|██████▍   | 250/389 [04:12<02:29,  1.07s/it, loss=0.2102]\u001b[A\nValidation:  65%|██████▍   | 251/389 [04:12<02:22,  1.03s/it, loss=0.2102]\u001b[A\nValidation:  65%|██████▍   | 251/389 [04:13<02:22,  1.03s/it, loss=0.2961]\u001b[A\nValidation:  65%|██████▍   | 252/389 [04:13<02:28,  1.08s/it, loss=0.2961]\u001b[A\nValidation:  65%|██████▍   | 252/389 [04:14<02:28,  1.08s/it, loss=0.3085]\u001b[A\nValidation:  65%|██████▌   | 253/389 [04:14<02:21,  1.04s/it, loss=0.3085]\u001b[A\nValidation:  65%|██████▌   | 253/389 [04:15<02:21,  1.04s/it, loss=0.1560]\u001b[A\nValidation:  65%|██████▌   | 254/389 [04:15<02:16,  1.01s/it, loss=0.1560]\u001b[A\nValidation:  65%|██████▌   | 254/389 [04:16<02:16,  1.01s/it, loss=0.1195]\u001b[A\nValidation:  66%|██████▌   | 255/389 [04:16<02:12,  1.01it/s, loss=0.1195]\u001b[A\nValidation:  66%|██████▌   | 255/389 [04:17<02:12,  1.01it/s, loss=0.3377]\u001b[A\nValidation:  66%|██████▌   | 256/389 [04:17<02:09,  1.03it/s, loss=0.3377]\u001b[A\nValidation:  66%|██████▌   | 256/389 [04:18<02:09,  1.03it/s, loss=0.2292]\u001b[A\nValidation:  66%|██████▌   | 257/389 [04:18<02:07,  1.03it/s, loss=0.2292]\u001b[A\nValidation:  66%|██████▌   | 257/389 [04:19<02:07,  1.03it/s, loss=0.2351]\u001b[A\nValidation:  66%|██████▋   | 258/389 [04:19<02:07,  1.03it/s, loss=0.2351]\u001b[A\nValidation:  66%|██████▋   | 258/389 [04:20<02:07,  1.03it/s, loss=0.3893]\u001b[A\nValidation:  67%|██████▋   | 259/389 [04:20<02:06,  1.03it/s, loss=0.3893]\u001b[A\nValidation:  67%|██████▋   | 259/389 [04:21<02:06,  1.03it/s, loss=0.3546]\u001b[A\nValidation:  67%|██████▋   | 260/389 [04:21<02:03,  1.04it/s, loss=0.3546]\u001b[A\nValidation:  67%|██████▋   | 260/389 [04:22<02:03,  1.04it/s, loss=0.2656]\u001b[A\nValidation:  67%|██████▋   | 261/389 [04:22<02:01,  1.05it/s, loss=0.2656]\u001b[A\nValidation:  67%|██████▋   | 261/389 [04:23<02:01,  1.05it/s, loss=0.2644]\u001b[A\nValidation:  67%|██████▋   | 262/389 [04:23<01:59,  1.06it/s, loss=0.2644]\u001b[A\nValidation:  67%|██████▋   | 262/389 [04:24<01:59,  1.06it/s, loss=0.0907]\u001b[A\nValidation:  68%|██████▊   | 263/389 [04:24<01:58,  1.06it/s, loss=0.0907]\u001b[A\nValidation:  68%|██████▊   | 263/389 [04:25<01:58,  1.06it/s, loss=0.4186]\u001b[A\nValidation:  68%|██████▊   | 264/389 [04:25<01:58,  1.06it/s, loss=0.4186]\u001b[A\nValidation:  68%|██████▊   | 264/389 [04:26<01:58,  1.06it/s, loss=0.3070]\u001b[A\nValidation:  68%|██████▊   | 265/389 [04:26<01:59,  1.04it/s, loss=0.3070]\u001b[A\nValidation:  68%|██████▊   | 265/389 [04:27<01:59,  1.04it/s, loss=0.9188]\u001b[A\nValidation:  68%|██████▊   | 266/389 [04:27<02:01,  1.02it/s, loss=0.9188]\u001b[A\nValidation:  68%|██████▊   | 266/389 [04:28<02:01,  1.02it/s, loss=1.0666]\u001b[A\nValidation:  69%|██████▊   | 267/389 [04:28<01:58,  1.03it/s, loss=1.0666]\u001b[A\nValidation:  69%|██████▊   | 267/389 [04:29<01:58,  1.03it/s, loss=1.4849]\u001b[A\nValidation:  69%|██████▉   | 268/389 [04:29<01:56,  1.04it/s, loss=1.4849]\u001b[A\nValidation:  69%|██████▉   | 268/389 [04:30<01:56,  1.04it/s, loss=1.4573]\u001b[A\nValidation:  69%|██████▉   | 269/389 [04:30<01:54,  1.04it/s, loss=1.4573]\u001b[A\nValidation:  69%|██████▉   | 269/389 [04:31<01:54,  1.04it/s, loss=1.5196]\u001b[A\nValidation:  69%|██████▉   | 270/389 [04:31<01:55,  1.03it/s, loss=1.5196]\u001b[A\nValidation:  69%|██████▉   | 270/389 [04:32<01:55,  1.03it/s, loss=1.8985]\u001b[A\nValidation:  70%|██████▉   | 271/389 [04:32<01:53,  1.04it/s, loss=1.8985]\u001b[A\nValidation:  70%|██████▉   | 271/389 [04:32<01:53,  1.04it/s, loss=1.6673]\u001b[A\nValidation:  70%|██████▉   | 272/389 [04:32<01:52,  1.04it/s, loss=1.6673]\u001b[A\nValidation:  70%|██████▉   | 272/389 [04:34<01:52,  1.04it/s, loss=0.7613]\u001b[A\nValidation:  70%|███████   | 273/389 [04:34<01:59,  1.03s/it, loss=0.7613]\u001b[A\nValidation:  70%|███████   | 273/389 [04:35<01:59,  1.03s/it, loss=0.5366]\u001b[A\nValidation:  70%|███████   | 274/389 [04:35<01:55,  1.00s/it, loss=0.5366]\u001b[A\nValidation:  70%|███████   | 274/389 [04:36<01:55,  1.00s/it, loss=0.8489]\u001b[A\nValidation:  71%|███████   | 275/389 [04:36<01:55,  1.02s/it, loss=0.8489]\u001b[A\nValidation:  71%|███████   | 275/389 [04:37<01:55,  1.02s/it, loss=0.5362]\u001b[A\nValidation:  71%|███████   | 276/389 [04:37<01:51,  1.01it/s, loss=0.5362]\u001b[A\nValidation:  71%|███████   | 276/389 [04:38<01:51,  1.01it/s, loss=0.6527]\u001b[A\nValidation:  71%|███████   | 277/389 [04:38<01:49,  1.02it/s, loss=0.6527]\u001b[A\nValidation:  71%|███████   | 277/389 [04:38<01:49,  1.02it/s, loss=0.5513]\u001b[A\nValidation:  71%|███████▏  | 278/389 [04:38<01:47,  1.03it/s, loss=0.5513]\u001b[A\nValidation:  71%|███████▏  | 278/389 [04:39<01:47,  1.03it/s, loss=0.2467]\u001b[A\nValidation:  72%|███████▏  | 279/389 [04:39<01:46,  1.04it/s, loss=0.2467]\u001b[A\nValidation:  72%|███████▏  | 279/389 [04:40<01:46,  1.04it/s, loss=0.1765]\u001b[A\nValidation:  72%|███████▏  | 280/389 [04:40<01:46,  1.03it/s, loss=0.1765]\u001b[A\nValidation:  72%|███████▏  | 280/389 [04:42<01:46,  1.03it/s, loss=0.0579]\u001b[A\nValidation:  72%|███████▏  | 281/389 [04:42<01:48,  1.01s/it, loss=0.0579]\u001b[A\nValidation:  72%|███████▏  | 281/389 [04:43<01:48,  1.01s/it, loss=0.0677]\u001b[A\nValidation:  72%|███████▏  | 282/389 [04:43<01:57,  1.09s/it, loss=0.0677]\u001b[A\nValidation:  72%|███████▏  | 282/389 [04:44<01:57,  1.09s/it, loss=0.0631]\u001b[A\nValidation:  73%|███████▎  | 283/389 [04:44<01:51,  1.05s/it, loss=0.0631]\u001b[A\nValidation:  73%|███████▎  | 283/389 [04:45<01:51,  1.05s/it, loss=0.5000]\u001b[A\nValidation:  73%|███████▎  | 284/389 [04:45<01:47,  1.02s/it, loss=0.5000]\u001b[A\nValidation:  73%|███████▎  | 284/389 [04:46<01:47,  1.02s/it, loss=0.4898]\u001b[A\nValidation:  73%|███████▎  | 285/389 [04:46<01:43,  1.01it/s, loss=0.4898]\u001b[A\nValidation:  73%|███████▎  | 285/389 [04:47<01:43,  1.01it/s, loss=0.4137]\u001b[A\nValidation:  74%|███████▎  | 286/389 [04:47<01:40,  1.02it/s, loss=0.4137]\u001b[A\nValidation:  74%|███████▎  | 286/389 [04:48<01:40,  1.02it/s, loss=0.3590]\u001b[A\nValidation:  74%|███████▍  | 287/389 [04:48<01:39,  1.03it/s, loss=0.3590]\u001b[A\nValidation:  74%|███████▍  | 287/389 [04:48<01:39,  1.03it/s, loss=0.5446]\u001b[A\nValidation:  74%|███████▍  | 288/389 [04:48<01:37,  1.04it/s, loss=0.5446]\u001b[A\nValidation:  74%|███████▍  | 288/389 [04:49<01:37,  1.04it/s, loss=0.5433]\u001b[A\nValidation:  74%|███████▍  | 289/389 [04:49<01:35,  1.04it/s, loss=0.5433]\u001b[A\nValidation:  74%|███████▍  | 289/389 [04:50<01:35,  1.04it/s, loss=0.3789]\u001b[A\nValidation:  75%|███████▍  | 290/389 [04:50<01:35,  1.03it/s, loss=0.3789]\u001b[A\nValidation:  75%|███████▍  | 290/389 [04:51<01:35,  1.03it/s, loss=0.3623]\u001b[A\nValidation:  75%|███████▍  | 291/389 [04:51<01:34,  1.04it/s, loss=0.3623]\u001b[A\nValidation:  75%|███████▍  | 291/389 [04:52<01:34,  1.04it/s, loss=0.5021]\u001b[A\nValidation:  75%|███████▌  | 292/389 [04:52<01:32,  1.05it/s, loss=0.5021]\u001b[A\nValidation:  75%|███████▌  | 292/389 [04:53<01:32,  1.05it/s, loss=0.5652]\u001b[A\nValidation:  75%|███████▌  | 293/389 [04:53<01:31,  1.05it/s, loss=0.5652]\u001b[A\nValidation:  75%|███████▌  | 293/389 [04:54<01:31,  1.05it/s, loss=0.5015]\u001b[A\nValidation:  76%|███████▌  | 294/389 [04:54<01:30,  1.05it/s, loss=0.5015]\u001b[A\nValidation:  76%|███████▌  | 294/389 [04:55<01:30,  1.05it/s, loss=0.4465]\u001b[A\nValidation:  76%|███████▌  | 295/389 [04:55<01:28,  1.06it/s, loss=0.4465]\u001b[A\nValidation:  76%|███████▌  | 295/389 [04:56<01:28,  1.06it/s, loss=0.4084]\u001b[A\nValidation:  76%|███████▌  | 296/389 [04:56<01:27,  1.06it/s, loss=0.4084]\u001b[A\nValidation:  76%|███████▌  | 296/389 [04:57<01:27,  1.06it/s, loss=0.3610]\u001b[A\nValidation:  76%|███████▋  | 297/389 [04:57<01:26,  1.06it/s, loss=0.3610]\u001b[A\nValidation:  76%|███████▋  | 297/389 [04:58<01:26,  1.06it/s, loss=0.5006]\u001b[A\nValidation:  77%|███████▋  | 298/389 [04:58<01:25,  1.07it/s, loss=0.5006]\u001b[A\nValidation:  77%|███████▋  | 298/389 [04:59<01:25,  1.07it/s, loss=0.4578]\u001b[A\nValidation:  77%|███████▋  | 299/389 [04:59<01:24,  1.06it/s, loss=0.4578]\u001b[A\nValidation:  77%|███████▋  | 299/389 [05:00<01:24,  1.06it/s, loss=0.8664]\u001b[A\nValidation:  77%|███████▋  | 300/389 [05:00<01:24,  1.06it/s, loss=0.8664]\u001b[A\nValidation:  77%|███████▋  | 300/389 [05:01<01:24,  1.06it/s, loss=1.2424]\u001b[A\nValidation:  77%|███████▋  | 301/389 [05:01<01:23,  1.06it/s, loss=1.2424]\u001b[A\nValidation:  77%|███████▋  | 301/389 [05:02<01:23,  1.06it/s, loss=1.3932]\u001b[A\nValidation:  78%|███████▊  | 302/389 [05:02<01:22,  1.06it/s, loss=1.3932]\u001b[A\nValidation:  78%|███████▊  | 302/389 [05:03<01:22,  1.06it/s, loss=1.0270]\u001b[A\nValidation:  78%|███████▊  | 303/389 [05:03<01:20,  1.07it/s, loss=1.0270]\u001b[A\nValidation:  78%|███████▊  | 303/389 [05:04<01:20,  1.07it/s, loss=1.3349]\u001b[A\nValidation:  78%|███████▊  | 304/389 [05:04<01:19,  1.07it/s, loss=1.3349]\u001b[A\nValidation:  78%|███████▊  | 304/389 [05:05<01:19,  1.07it/s, loss=1.2089]\u001b[A\nValidation:  78%|███████▊  | 305/389 [05:05<01:18,  1.07it/s, loss=1.2089]\u001b[A\nValidation:  78%|███████▊  | 305/389 [05:05<01:18,  1.07it/s, loss=1.2384]\u001b[A\nValidation:  79%|███████▊  | 306/389 [05:05<01:18,  1.06it/s, loss=1.2384]\u001b[A\nValidation:  79%|███████▊  | 306/389 [05:06<01:18,  1.06it/s, loss=0.2606]\u001b[A\nValidation:  79%|███████▉  | 307/389 [05:06<01:17,  1.06it/s, loss=0.2606]\u001b[A\nValidation:  79%|███████▉  | 307/389 [05:07<01:17,  1.06it/s, loss=0.2087]\u001b[A\nValidation:  79%|███████▉  | 308/389 [05:07<01:16,  1.06it/s, loss=0.2087]\u001b[A\nValidation:  79%|███████▉  | 308/389 [05:08<01:16,  1.06it/s, loss=0.2278]\u001b[A\nValidation:  79%|███████▉  | 309/389 [05:08<01:14,  1.07it/s, loss=0.2278]\u001b[A\nValidation:  79%|███████▉  | 309/389 [05:09<01:14,  1.07it/s, loss=0.2927]\u001b[A\nValidation:  80%|███████▉  | 310/389 [05:09<01:14,  1.06it/s, loss=0.2927]\u001b[A\nValidation:  80%|███████▉  | 310/389 [05:10<01:14,  1.06it/s, loss=0.2272]\u001b[A\nValidation:  80%|███████▉  | 311/389 [05:10<01:14,  1.05it/s, loss=0.2272]\u001b[A\nValidation:  80%|███████▉  | 311/389 [05:11<01:14,  1.05it/s, loss=0.1481]\u001b[A\nValidation:  80%|████████  | 312/389 [05:11<01:13,  1.05it/s, loss=0.1481]\u001b[A\nValidation:  80%|████████  | 312/389 [05:12<01:13,  1.05it/s, loss=0.3521]\u001b[A\nValidation:  80%|████████  | 313/389 [05:12<01:11,  1.06it/s, loss=0.3521]\u001b[A\nValidation:  80%|████████  | 313/389 [05:13<01:11,  1.06it/s, loss=0.5862]\u001b[A\nValidation:  81%|████████  | 314/389 [05:13<01:17,  1.03s/it, loss=0.5862]\u001b[A\nValidation:  81%|████████  | 314/389 [05:14<01:17,  1.03s/it, loss=0.5575]\u001b[A\nValidation:  81%|████████  | 315/389 [05:14<01:17,  1.05s/it, loss=0.5575]\u001b[A\nValidation:  81%|████████  | 315/389 [05:16<01:17,  1.05s/it, loss=0.5771]\u001b[A\nValidation:  81%|████████  | 316/389 [05:16<01:18,  1.07s/it, loss=0.5771]\u001b[A\nValidation:  81%|████████  | 316/389 [05:16<01:18,  1.07s/it, loss=0.3846]\u001b[A\nValidation:  81%|████████▏ | 317/389 [05:16<01:14,  1.03s/it, loss=0.3846]\u001b[A\nValidation:  81%|████████▏ | 317/389 [05:17<01:14,  1.03s/it, loss=0.2579]\u001b[A\nValidation:  82%|████████▏ | 318/389 [05:17<01:11,  1.00s/it, loss=0.2579]\u001b[A\nValidation:  82%|████████▏ | 318/389 [05:18<01:11,  1.00s/it, loss=0.0567]\u001b[A\nValidation:  82%|████████▏ | 319/389 [05:18<01:08,  1.02it/s, loss=0.0567]\u001b[A\nValidation:  82%|████████▏ | 319/389 [05:19<01:08,  1.02it/s, loss=0.1178]\u001b[A\nValidation:  82%|████████▏ | 320/389 [05:19<01:06,  1.03it/s, loss=0.1178]\u001b[A\nValidation:  82%|████████▏ | 320/389 [05:20<01:06,  1.03it/s, loss=0.1302]\u001b[A\nValidation:  83%|████████▎ | 321/389 [05:20<01:07,  1.01it/s, loss=0.1302]\u001b[A\nValidation:  83%|████████▎ | 321/389 [05:21<01:07,  1.01it/s, loss=0.2100]\u001b[A\nValidation:  83%|████████▎ | 322/389 [05:21<01:04,  1.03it/s, loss=0.2100]\u001b[A\nValidation:  83%|████████▎ | 322/389 [05:22<01:04,  1.03it/s, loss=0.0909]\u001b[A\nValidation:  83%|████████▎ | 323/389 [05:22<01:03,  1.05it/s, loss=0.0909]\u001b[A\nValidation:  83%|████████▎ | 323/389 [05:23<01:03,  1.05it/s, loss=0.3311]\u001b[A\nValidation:  83%|████████▎ | 324/389 [05:23<01:01,  1.05it/s, loss=0.3311]\u001b[A\nValidation:  83%|████████▎ | 324/389 [05:24<01:01,  1.05it/s, loss=0.6479]\u001b[A\nValidation:  84%|████████▎ | 325/389 [05:24<01:00,  1.06it/s, loss=0.6479]\u001b[A\nValidation:  84%|████████▎ | 325/389 [05:25<01:00,  1.06it/s, loss=0.9074]\u001b[A\nValidation:  84%|████████▍ | 326/389 [05:25<00:59,  1.06it/s, loss=0.9074]\u001b[A\nValidation:  84%|████████▍ | 326/389 [05:26<00:59,  1.06it/s, loss=1.0061]\u001b[A\nValidation:  84%|████████▍ | 327/389 [05:26<00:58,  1.06it/s, loss=1.0061]\u001b[A\nValidation:  84%|████████▍ | 327/389 [05:27<00:58,  1.06it/s, loss=0.8261]\u001b[A\nValidation:  84%|████████▍ | 328/389 [05:27<00:57,  1.06it/s, loss=0.8261]\u001b[A\nValidation:  84%|████████▍ | 328/389 [05:28<00:57,  1.06it/s, loss=0.8448]\u001b[A\nValidation:  85%|████████▍ | 329/389 [05:28<00:56,  1.06it/s, loss=0.8448]\u001b[A\nValidation:  85%|████████▍ | 329/389 [05:29<00:56,  1.06it/s, loss=0.8264]\u001b[A\nValidation:  85%|████████▍ | 330/389 [05:29<00:56,  1.05it/s, loss=0.8264]\u001b[A\nValidation:  85%|████████▍ | 330/389 [05:30<00:56,  1.05it/s, loss=4.6965]\u001b[A\nValidation:  85%|████████▌ | 331/389 [05:30<00:55,  1.05it/s, loss=4.6965]\u001b[A\nValidation:  85%|████████▌ | 331/389 [05:31<00:55,  1.05it/s, loss=3.6597]\u001b[A\nValidation:  85%|████████▌ | 332/389 [05:31<00:54,  1.04it/s, loss=3.6597]\u001b[A\nValidation:  85%|████████▌ | 332/389 [05:32<00:54,  1.04it/s, loss=3.8803]\u001b[A\nValidation:  86%|████████▌ | 333/389 [05:32<00:53,  1.05it/s, loss=3.8803]\u001b[A\nValidation:  86%|████████▌ | 333/389 [05:33<00:53,  1.05it/s, loss=4.1029]\u001b[A\nValidation:  86%|████████▌ | 334/389 [05:33<00:52,  1.05it/s, loss=4.1029]\u001b[A\nValidation:  86%|████████▌ | 334/389 [05:34<00:52,  1.05it/s, loss=4.0136]\u001b[A\nValidation:  86%|████████▌ | 335/389 [05:34<00:51,  1.05it/s, loss=4.0136]\u001b[A\nValidation:  86%|████████▌ | 335/389 [05:34<00:51,  1.05it/s, loss=4.4605]\u001b[A\nValidation:  86%|████████▋ | 336/389 [05:34<00:50,  1.05it/s, loss=4.4605]\u001b[A\nValidation:  86%|████████▋ | 336/389 [05:36<00:50,  1.05it/s, loss=2.8404]\u001b[A\nValidation:  87%|████████▋ | 337/389 [05:36<00:51,  1.01it/s, loss=2.8404]\u001b[A\nValidation:  87%|████████▋ | 337/389 [05:37<00:51,  1.01it/s, loss=0.4810]\u001b[A\nValidation:  87%|████████▋ | 338/389 [05:37<00:49,  1.02it/s, loss=0.4810]\u001b[A\nValidation:  87%|████████▋ | 338/389 [05:37<00:49,  1.02it/s, loss=0.6451]\u001b[A\nValidation:  87%|████████▋ | 339/389 [05:37<00:48,  1.03it/s, loss=0.6451]\u001b[A\nValidation:  87%|████████▋ | 339/389 [05:38<00:48,  1.03it/s, loss=0.5067]\u001b[A\nValidation:  87%|████████▋ | 340/389 [05:38<00:48,  1.01it/s, loss=0.5067]\u001b[A\nValidation:  87%|████████▋ | 340/389 [05:39<00:48,  1.01it/s, loss=0.7730]\u001b[A\nValidation:  88%|████████▊ | 341/389 [05:39<00:46,  1.02it/s, loss=0.7730]\u001b[A\nValidation:  88%|████████▊ | 341/389 [05:40<00:46,  1.02it/s, loss=1.3128]\u001b[A\nValidation:  88%|████████▊ | 342/389 [05:40<00:46,  1.02it/s, loss=1.3128]\u001b[A\nValidation:  88%|████████▊ | 342/389 [05:41<00:46,  1.02it/s, loss=1.8869]\u001b[A\nValidation:  88%|████████▊ | 343/389 [05:41<00:44,  1.02it/s, loss=1.8869]\u001b[A\nValidation:  88%|████████▊ | 343/389 [05:42<00:44,  1.02it/s, loss=2.0747]\u001b[A\nValidation:  88%|████████▊ | 344/389 [05:42<00:45,  1.00s/it, loss=2.0747]\u001b[A\nValidation:  88%|████████▊ | 344/389 [05:43<00:45,  1.00s/it, loss=2.1689]\u001b[A\nValidation:  89%|████████▊ | 345/389 [05:43<00:43,  1.02it/s, loss=2.1689]\u001b[A\nValidation:  89%|████████▊ | 345/389 [05:44<00:43,  1.02it/s, loss=2.4424]\u001b[A\nValidation:  89%|████████▉ | 346/389 [05:44<00:42,  1.01it/s, loss=2.4424]\u001b[A\nValidation:  89%|████████▉ | 346/389 [05:46<00:42,  1.01it/s, loss=2.4817]\u001b[A\nValidation:  89%|████████▉ | 347/389 [05:46<00:45,  1.09s/it, loss=2.4817]\u001b[A\nValidation:  89%|████████▉ | 347/389 [05:47<00:45,  1.09s/it, loss=2.9430]\u001b[A\nValidation:  89%|████████▉ | 348/389 [05:47<00:42,  1.05s/it, loss=2.9430]\u001b[A\nValidation:  89%|████████▉ | 348/389 [05:48<00:42,  1.05s/it, loss=2.9177]\u001b[A\nValidation:  90%|████████▉ | 349/389 [05:48<00:40,  1.02s/it, loss=2.9177]\u001b[A\nValidation:  90%|████████▉ | 349/389 [05:49<00:40,  1.02s/it, loss=2.2405]\u001b[A\nValidation:  90%|████████▉ | 350/389 [05:49<00:38,  1.00it/s, loss=2.2405]\u001b[A\nValidation:  90%|████████▉ | 350/389 [05:50<00:38,  1.00it/s, loss=3.1674]\u001b[A\nValidation:  90%|█████████ | 351/389 [05:50<00:37,  1.03it/s, loss=3.1674]\u001b[A\nValidation:  90%|█████████ | 351/389 [05:51<00:37,  1.03it/s, loss=2.7731]\u001b[A\nValidation:  90%|█████████ | 352/389 [05:51<00:36,  1.01it/s, loss=2.7731]\u001b[A\nValidation:  90%|█████████ | 352/389 [05:51<00:36,  1.01it/s, loss=1.7469]\u001b[A\nValidation:  91%|█████████ | 353/389 [05:51<00:35,  1.02it/s, loss=1.7469]\u001b[A\nValidation:  91%|█████████ | 353/389 [05:52<00:35,  1.02it/s, loss=0.6685]\u001b[A\nValidation:  91%|█████████ | 354/389 [05:52<00:33,  1.04it/s, loss=0.6685]\u001b[A\nValidation:  91%|█████████ | 354/389 [05:53<00:33,  1.04it/s, loss=0.7003]\u001b[A\nValidation:  91%|█████████▏| 355/389 [05:53<00:32,  1.04it/s, loss=0.7003]\u001b[A\nValidation:  91%|█████████▏| 355/389 [05:54<00:32,  1.04it/s, loss=0.6361]\u001b[A\nValidation:  92%|█████████▏| 356/389 [05:54<00:32,  1.00it/s, loss=0.6361]\u001b[A\nValidation:  92%|█████████▏| 356/389 [05:55<00:32,  1.00it/s, loss=0.7142]\u001b[A\nValidation:  92%|█████████▏| 357/389 [05:55<00:31,  1.02it/s, loss=0.7142]\u001b[A\nValidation:  92%|█████████▏| 357/389 [05:57<00:31,  1.02it/s, loss=3.2719]\u001b[A\nValidation:  92%|█████████▏| 358/389 [05:57<00:31,  1.03s/it, loss=3.2719]\u001b[A\nValidation:  92%|█████████▏| 358/389 [05:58<00:31,  1.03s/it, loss=6.2507]\u001b[A\nValidation:  92%|█████████▏| 359/389 [05:58<00:30,  1.01s/it, loss=6.2507]\u001b[A\nValidation:  92%|█████████▏| 359/389 [05:58<00:30,  1.01s/it, loss=6.9532]\u001b[A\nValidation:  93%|█████████▎| 360/389 [05:58<00:29,  1.00s/it, loss=6.9532]\u001b[A\nValidation:  93%|█████████▎| 360/389 [05:59<00:29,  1.00s/it, loss=7.0191]\u001b[A\nValidation:  93%|█████████▎| 361/389 [05:59<00:27,  1.01it/s, loss=7.0191]\u001b[A\nValidation:  93%|█████████▎| 361/389 [06:01<00:27,  1.01it/s, loss=6.6618]\u001b[A\nValidation:  93%|█████████▎| 362/389 [06:01<00:27,  1.03s/it, loss=6.6618]\u001b[A\nValidation:  93%|█████████▎| 362/389 [06:02<00:27,  1.03s/it, loss=6.7874]\u001b[A\nValidation:  93%|█████████▎| 363/389 [06:02<00:27,  1.06s/it, loss=6.7874]\u001b[A\nValidation:  93%|█████████▎| 363/389 [06:03<00:27,  1.06s/it, loss=6.4623]\u001b[A\nValidation:  94%|█████████▎| 364/389 [06:03<00:25,  1.02s/it, loss=6.4623]\u001b[A\nValidation:  94%|█████████▎| 364/389 [06:04<00:25,  1.02s/it, loss=2.0496]\u001b[A\nValidation:  94%|█████████▍| 365/389 [06:04<00:23,  1.01it/s, loss=2.0496]\u001b[A\nValidation:  94%|█████████▍| 365/389 [06:04<00:23,  1.01it/s, loss=2.4892]\u001b[A\nValidation:  94%|█████████▍| 366/389 [06:04<00:22,  1.03it/s, loss=2.4892]\u001b[A\nValidation:  94%|█████████▍| 366/389 [06:05<00:22,  1.03it/s, loss=2.5287]\u001b[A\nValidation:  94%|█████████▍| 367/389 [06:05<00:21,  1.02it/s, loss=2.5287]\u001b[A\nValidation:  94%|█████████▍| 367/389 [06:06<00:21,  1.02it/s, loss=2.8434]\u001b[A\nValidation:  95%|█████████▍| 368/389 [06:06<00:20,  1.03it/s, loss=2.8434]\u001b[A\nValidation:  95%|█████████▍| 368/389 [06:07<00:20,  1.03it/s, loss=2.6308]\u001b[A\nValidation:  95%|█████████▍| 369/389 [06:07<00:19,  1.01it/s, loss=2.6308]\u001b[A\nValidation:  95%|█████████▍| 369/389 [06:08<00:19,  1.01it/s, loss=2.1724]\u001b[A\nValidation:  95%|█████████▌| 370/389 [06:08<00:18,  1.02it/s, loss=2.1724]\u001b[A\nValidation:  95%|█████████▌| 370/389 [06:09<00:18,  1.02it/s, loss=1.7129]\u001b[A\nValidation:  95%|█████████▌| 371/389 [06:09<00:17,  1.03it/s, loss=1.7129]\u001b[A\nValidation:  95%|█████████▌| 371/389 [06:10<00:17,  1.03it/s, loss=1.0964]\u001b[A\nValidation:  96%|█████████▌| 372/389 [06:10<00:16,  1.02it/s, loss=1.0964]\u001b[A\nValidation:  96%|█████████▌| 372/389 [06:11<00:16,  1.02it/s, loss=0.9313]\u001b[A\nValidation:  96%|█████████▌| 373/389 [06:11<00:15,  1.03it/s, loss=0.9313]\u001b[A\nValidation:  96%|█████████▌| 373/389 [06:12<00:15,  1.03it/s, loss=1.1016]\u001b[A\nValidation:  96%|█████████▌| 374/389 [06:12<00:14,  1.04it/s, loss=1.1016]\u001b[A\nValidation:  96%|█████████▌| 374/389 [06:13<00:14,  1.04it/s, loss=1.0318]\u001b[A\nValidation:  96%|█████████▋| 375/389 [06:13<00:13,  1.04it/s, loss=1.0318]\u001b[A\nValidation:  96%|█████████▋| 375/389 [06:14<00:13,  1.04it/s, loss=2.0650]\u001b[A\nValidation:  97%|█████████▋| 376/389 [06:14<00:12,  1.05it/s, loss=2.0650]\u001b[A\nValidation:  97%|█████████▋| 376/389 [06:15<00:12,  1.05it/s, loss=3.2183]\u001b[A\nValidation:  97%|█████████▋| 377/389 [06:15<00:11,  1.05it/s, loss=3.2183]\u001b[A\nValidation:  97%|█████████▋| 377/389 [06:16<00:11,  1.05it/s, loss=2.6106]\u001b[A\nValidation:  97%|█████████▋| 378/389 [06:16<00:11,  1.01s/it, loss=2.6106]\u001b[A\nValidation:  97%|█████████▋| 378/389 [06:17<00:11,  1.01s/it, loss=2.8056]\u001b[A\nValidation:  97%|█████████▋| 379/389 [06:17<00:10,  1.02s/it, loss=2.8056]\u001b[A\nValidation:  97%|█████████▋| 379/389 [06:18<00:10,  1.02s/it, loss=2.2552]\u001b[A\nValidation:  98%|█████████▊| 380/389 [06:18<00:09,  1.01s/it, loss=2.2552]\u001b[A\nValidation:  98%|█████████▊| 380/389 [06:19<00:09,  1.01s/it, loss=2.2879]\u001b[A\nValidation:  98%|█████████▊| 381/389 [06:19<00:07,  1.01it/s, loss=2.2879]\u001b[A\nValidation:  98%|█████████▊| 381/389 [06:20<00:07,  1.01it/s, loss=3.8886]\u001b[A\nValidation:  98%|█████████▊| 382/389 [06:20<00:06,  1.02it/s, loss=3.8886]\u001b[A\nValidation:  98%|█████████▊| 382/389 [06:21<00:06,  1.02it/s, loss=6.5122]\u001b[A\nValidation:  98%|█████████▊| 383/389 [06:21<00:05,  1.04it/s, loss=6.5122]\u001b[A\nValidation:  98%|█████████▊| 383/389 [06:22<00:05,  1.04it/s, loss=6.4628]\u001b[A\nValidation:  99%|█████████▊| 384/389 [06:22<00:04,  1.06it/s, loss=6.4628]\u001b[A\nValidation:  99%|█████████▊| 384/389 [06:23<00:04,  1.06it/s, loss=6.3020]\u001b[A\nValidation:  99%|█████████▉| 385/389 [06:23<00:03,  1.07it/s, loss=6.3020]\u001b[A\nValidation:  99%|█████████▉| 385/389 [06:24<00:03,  1.07it/s, loss=6.6912]\u001b[A\nValidation:  99%|█████████▉| 386/389 [06:24<00:02,  1.08it/s, loss=6.6912]\u001b[A\nValidation:  99%|█████████▉| 386/389 [06:25<00:02,  1.08it/s, loss=6.6964]\u001b[A\nValidation:  99%|█████████▉| 387/389 [06:25<00:01,  1.09it/s, loss=6.6964]\u001b[A\nValidation:  99%|█████████▉| 387/389 [06:26<00:01,  1.09it/s, loss=6.2497]\u001b[A\nValidation: 100%|█████████▉| 388/389 [06:26<00:00,  1.09it/s, loss=6.2497]\u001b[A\nValidation: 100%|█████████▉| 388/389 [06:26<00:00,  1.09it/s, loss=6.9115]\u001b[A\nValidation: 100%|██████████| 389/389 [06:26<00:00,  1.40it/s, loss=6.9115]\u001b[A\nArchitecture Search Progress:   0%|          | 0/30 [08:29<?, ?it/s, Train Loss=0.2028, Val EER=0.0660, Best EER=1.0000]","output_type":"stream"},{"name":"stdout","text":"\nNew best architecture found! EER: 0.0660\n","output_type":"stream"},{"name":"stderr","text":"\nPPO Training:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\nArchitecture Search Progress:   0%|          | 0/30 [08:30<?, ?it/s, Train Loss=0.2028, Val EER=0.0660, Best EER=1.0000]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3832242952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/2469065156.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# Perform architecture search with wandb logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting Neural Architecture Search...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     model, best_architecture, best_val_eer = search_architecture(\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1287677979.py\u001b[0m in \u001b[0;36msearch_architecture\u001b[0;34m(train_loader, val_loader, device, input_channels, num_cells, num_nodes, num_ops, epochs, ppo_updates, project_name)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Update PPO controller if enough data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mppo_updates\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemories\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             actor_loss, critic_loss, entropy_loss = train_ppo(\n\u001b[0m\u001b[1;32m    201\u001b[0m                 controller, controller_optimizer, memories)\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2129246363.py\u001b[0m in \u001b[0;36mtrain_ppo\u001b[0;34m(controller, optimizer, memories, clip_ratio, epochs, entropy_coef)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mppo_pbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Evaluate actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontroller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1133620567.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1133620567.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Returns action probabilities and estimated value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0maction_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x180 and 1x64)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (1x180 and 1x64)","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x1000 with 6 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}