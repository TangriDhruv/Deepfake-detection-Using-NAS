{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11060404,"sourceType":"datasetVersion","datasetId":6891325}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.metrics import roc_curve\nimport soundfile as sf\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nimport librosa\nimport random\nfrom torch.distributions import Categorical\nimport wandb\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:31.611576Z","iopub.execute_input":"2025-04-15T02:16:31.611833Z","iopub.status.idle":"2025-04-15T02:16:39.312561Z","shell.execute_reply.started":"2025-04-15T02:16:31.611809Z","shell.execute_reply":"2025-04-15T02:16:39.311827Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class ASVSpoofDataset(Dataset):\n    def __init__(self, root_dir, protocol_file, feature_type='mfcc', max_len=None, is_train=True):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the audio files.\n            protocol_file (string): Path to the protocol file.\n            feature_type (string): Type of features to extract ('mfcc', 'spec', 'cqt').\n            max_len (int): Maximum length of features sequence.\n            is_train (bool): Whether this is for training or testing.\n        \"\"\"\n        self.root_dir = root_dir\n        self.feature_type = feature_type\n        self.max_len = max_len\n        self.is_train = is_train\n        \n        # Read protocol file\n        self.data = []\n        \n        print(f\"Reading protocol file: {protocol_file}\")\n        try:\n            with open(protocol_file, 'r') as f:\n                lines = f.readlines()\n                \n                # Use tqdm for loading progress\n                for line in tqdm(lines, desc=f\"Loading {'training' if is_train else 'evaluation'} protocol\"):\n                    parts = line.strip().split()\n                    if len(parts) >= 5:\n                        speaker_id = parts[0]\n                        file_id = parts[1]\n                        label_text = parts[4]\n                        label = 1 if label_text == 'bonafide' else 0  # 0 for bonafide, 1 for spoof\n                        self.data.append((file_id, label))\n            \n            # Count number of bonafide and spoof samples\n            bonafide_count = sum(1 for _, label in self.data if label == 0)\n            spoof_count = sum(1 for _, label in self.data if label == 1)\n            \n            print(f\"Dataset loaded: {len(self.data)} samples ({bonafide_count} bonafide, {spoof_count} spoof)\")\n            \n            if is_train:\n                # Subsample for faster NAS\n                if len(self.data) > 5000:\n                    print(f\"Subsampling training data for faster NAS...\")\n                    np.random.shuffle(self.data)\n                    # Keep balanced class distribution\n                    bonafide_samples = [item for item in self.data if item[1] == 0][:2500]\n                    spoof_samples = [item for item in self.data if item[1] == 1][:2500]\n                    self.data = bonafide_samples + spoof_samples\n                    np.random.shuffle(self.data)\n                    print(f\"Subsampled to {len(self.data)} samples\")\n        \n        except Exception as e:\n            print(f\"Error loading protocol file: {e}\")\n            self.data = []\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        file_id, label = self.data[idx]\n        audio_path = os.path.join(self.root_dir, f\"{file_id}.flac\")\n        \n        try:\n            audio, sr = sf.read(audio_path)\n            \n            # Feature extraction\n            if self.feature_type == 'mfcc':\n                features = extract_mfcc(audio, sr)\n            elif self.feature_type == 'spec':\n                features = extract_spec(audio, sr)\n            elif self.feature_type == 'cqt':\n                features = extract_cqt(audio, sr)\n            else:\n                raise ValueError(f\"Unknown feature type: {self.feature_type}\")\n            \n            # Normalize features\n            features = (features - np.mean(features)) / (np.std(features) + 1e-8)\n            \n            # Handle sequence length\n            seq_len = features.shape[1]\n            if self.max_len is not None:\n                if seq_len > self.max_len:\n                    start = np.random.randint(0, seq_len - self.max_len) if self.is_train else 0\n                    features = features[:, start:start+self.max_len]\n                elif seq_len < self.max_len:\n                    # Pad with zeros\n                    pad_width = ((0, 0), (0, self.max_len - seq_len))\n                    features = np.pad(features, pad_width, mode='constant')\n            \n            return torch.FloatTensor(features), torch.LongTensor([label])[0]\n            \n        except Exception as e:\n            print(f\"Error loading {audio_path}: {e}\")\n            # Return a dummy sample in case of error\n            dummy_features = np.zeros((60, 100 if self.max_len is None else self.max_len))\n            return torch.FloatTensor(dummy_features), torch.LongTensor([label])[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.314035Z","iopub.execute_input":"2025-04-15T02:16:39.314245Z","iopub.status.idle":"2025-04-15T02:16:39.326366Z","shell.execute_reply.started":"2025-04-15T02:16:39.314228Z","shell.execute_reply":"2025-04-15T02:16:39.325654Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nset_seed()\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Feature extraction functions\ndef extract_mfcc(audio, sr=16000, n_mfcc=20):\n    \"\"\"Extract MFCC features from audio\"\"\"\n    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)\n    delta = librosa.feature.delta(mfcc)\n    delta2 = librosa.feature.delta(mfcc, order=2)\n    features = np.concatenate([mfcc, delta, delta2], axis=0)\n    return features\n\ndef extract_spec(audio, sr=16000, n_fft=512, hop_length=256):\n    \"\"\"Extract log mel-spectrogram features from audio\"\"\"\n    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=80)\n    log_mel_spec = librosa.power_to_db(mel_spec)\n    return log_mel_spec\n\ndef extract_cqt(audio, sr=16000, hop_length=256):\n    \"\"\"Extract Constant-Q Transform features from audio\"\"\"\n    cqt = librosa.cqt(y=audio, sr=sr, hop_length=hop_length)\n    return np.abs(cqt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.327181Z","iopub.execute_input":"2025-04-15T02:16:39.327403Z","iopub.status.idle":"2025-04-15T02:16:39.435519Z","shell.execute_reply.started":"2025-04-15T02:16:39.327382Z","shell.execute_reply":"2025-04-15T02:16:39.434944Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Neural Architecture Search (NAS) components\n\n# Define the search space\nclass Operation(nn.Module):\n    \"\"\"Base class for all operations in the search space\"\"\"\n    def __init__(self, channels, stride=1):\n        super(Operation, self).__init__()\n        self.channels = channels\n        self.stride = stride\n    \n    def forward(self, x):\n        raise NotImplementedError\n\nclass ConvBlock(Operation):\n    def __init__(self, channels, kernel_size, stride=1):\n        super(ConvBlock, self).__init__(channels, stride)\n        self.conv = nn.Conv1d(channels, channels, kernel_size, stride=stride, padding=kernel_size//2)\n        self.bn = nn.BatchNorm1d(channels)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))\n\nclass LSTM(Operation):\n    def __init__(self, channels, stride=1):\n        super(LSTM, self).__init__(channels, stride)\n        self.lstm = nn.LSTM(channels, channels, batch_first=True)  # Set batch_first=True for simplicity\n        self.proj = nn.Linear(channels, channels)  # Simplified projection\n        \n        # We'll use a Conv1d for adaptation instead of Linear\n        # This works better with the expected tensor shapes\n        self.input_proj = nn.Conv1d(in_channels=channels, out_channels=channels, kernel_size=1)\n    \n    def forward(self, x):\n        # x shape is expected to be [B, C, T] from previous operations\n        \n        # First, check if we need to adapt the channel dimension\n        if x.size(1) != self.channels:\n            # Use the 1x1 convolution to adapt the channel dimension\n            x = self.input_proj(x)\n        \n        # Now reshape for LSTM\n        batch_size, channels, seq_len = x.size()\n        x = x.permute(0, 2, 1)  # [B, C, T] -> [B, T, C]\n        \n        # LSTM expects [B, T, C] with batch_first=True\n        x, _ = self.lstm(x)\n        \n        # Apply projection if needed\n        x = self.proj(x)\n        \n        # Return to original dimension ordering\n        x = x.permute(0, 2, 1)  # [B, T, C] -> [B, C, T]\n        \n        return x\n\nclass Dilated(Operation):\n    def __init__(self, channels, stride=1):\n        super(Dilated, self).__init__(channels, stride)\n        self.conv = nn.Conv1d(channels, channels, 3, stride=stride, padding=2, dilation=2)\n        self.bn = nn.BatchNorm1d(channels)\n        self.relu = nn.ReLU()\n    \n    def forward(self, x):\n        return self.relu(self.bn(self.conv(x)))\n\nclass SkipConnect(Operation):\n    def __init__(self, channels, stride=1):\n        super(SkipConnect, self).__init__(channels, stride)\n    \n    def forward(self, x):\n        return x\n\nclass Attention(Operation):\n    def __init__(self, channels, stride=1):\n        super(Attention, self).__init__(channels, stride)\n        self.query = nn.Conv1d(channels, channels, 1)\n        self.key = nn.Conv1d(channels, channels, 1)\n        self.value = nn.Conv1d(channels, channels, 1)\n        self.scale = torch.sqrt(torch.FloatTensor([channels])).to(device)\n    \n    def forward(self, x):\n        # x shape: [C, T, B]\n        q = self.query(x)\n        k = self.key(x)\n        v = self.value(x)\n        \n        # Self-attention\n        attention = torch.matmul(q.permute(0, 2, 1), k) / self.scale\n        attention = F.softmax(attention, dim=-1)\n        x = torch.matmul(attention, v.permute(0, 2, 1)).permute(0, 2, 1)\n        return x\n\n# Define the mixed operation (to be controlled by PPO)\nclass MixedOp(nn.Module):\n    def __init__(self, channels, stride=1):\n        super(MixedOp, self).__init__()\n        self.ops = nn.ModuleList([\n            ConvBlock(channels, 3, stride),\n            ConvBlock(channels, 5, stride),\n            LSTM(channels, stride),\n            Dilated(channels, stride),\n            SkipConnect(channels, stride),\n            Attention(channels, stride)\n        ])\n    \n    def forward(self, x, weights):\n        \"\"\"Forward pass with operation weights\"\"\"\n        return sum(w * op(x) for w, op in zip(weights, self.ops))","metadata":{"_uuid":"7f3edfdc-8a27-4c5d-8ad7-1a77fb834b22","_cell_guid":"c072f101-96dd-447f-92cd-6c6eaa7b97a5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-04-15T02:16:39.436126Z","iopub.execute_input":"2025-04-15T02:16:39.436355Z","iopub.status.idle":"2025-04-15T02:16:39.449399Z","shell.execute_reply.started":"2025-04-15T02:16:39.436338Z","shell.execute_reply":"2025-04-15T02:16:39.448676Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Cell structure\nclass Cell(nn.Module):\n    def __init__(self, channels, num_nodes=4):\n        super(Cell, self).__init__()\n        self.channels = channels\n        self.num_nodes = num_nodes\n        \n        # For each node, create edges from all previous nodes\n        self.edges = nn.ModuleList()\n        for i in range(num_nodes):\n            for j in range(i+1):  # connections from input and previous nodes\n                self.edges.append(MixedOp(channels))\n        \n        # Output projection - ensure consistent channel dimension\n        self.project = nn.Conv1d(channels * num_nodes, channels, 1)\n    \n    def forward(self, x, weights):\n        \"\"\"\n        Forward pass through the cell\n        Args:\n            x: Input tensor [B, C, T]\n            weights: List of weight tensors for each edge\n        \"\"\"\n        # Add debugging print to check dimensions\n        #print(f\"Cell input shape: {x.shape}\")\n        \n        states = [x]\n        offset = 0\n        \n        # Process each node\n        for i in range(self.num_nodes):\n            # Gather inputs from previous nodes\n            node_inputs = []\n            for j in range(i+1):\n                edge_output = self.edges[offset + j](states[j], weights[offset + j])\n                # Add dimension check\n                if edge_output.size(1) != self.channels:\n                    print(f\"Dimension mismatch at node {i}, edge {j}: expected {self.channels}, got {edge_output.size(1)}\")\n                    # Add adaptive padding or projection if needed\n                    edge_output = F.pad(edge_output, (0, 0, 0, self.channels - edge_output.size(1), 0, 0))\n                node_inputs.append(edge_output)\n            \n            node_input = sum(node_inputs)\n            offset += i+1\n            states.append(node_input)\n        \n        # Concatenate all intermediate nodes and check dimensions\n        cat_states = torch.cat(states[1:], dim=1)\n        #print(f\"Concatenated states shape before projection: {cat_states.shape}\")\n        \n        return self.project(cat_states)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.450126Z","iopub.execute_input":"2025-04-15T02:16:39.450379Z","iopub.status.idle":"2025-04-15T02:16:39.461872Z","shell.execute_reply.started":"2025-04-15T02:16:39.450363Z","shell.execute_reply":"2025-04-15T02:16:39.461334Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Complete model with cells\nclass DeepfakeDetectionModel(nn.Module):\n    def __init__(self, input_channels, num_cells=3, num_nodes=4, num_ops=6):\n        super(DeepfakeDetectionModel, self).__init__()\n        self.input_channels = input_channels\n        self.num_cells = num_cells\n        self.num_nodes = num_nodes\n        self.num_ops = num_ops\n        \n        # Initial projection\n        self.stem = nn.Sequential(\n            nn.Conv1d(input_channels, 64, 3, padding=1),\n            nn.BatchNorm1d(64),\n            nn.ReLU()\n        )\n        \n        # Cells\n        self.cells = nn.ModuleList()\n        for i in range(num_cells):\n            self.cells.append(Cell(64, num_nodes))\n        \n        # Classification head\n        self.pool = nn.AdaptiveAvgPool1d(1)\n        self.classifier = nn.Linear(64, 2)  # Binary classification\n        \n        # Calculate total number of weights needed\n        edges_per_cell = sum(range(1, num_nodes+1))\n        self.total_weights = num_cells * edges_per_cell * num_ops\n    \n    def forward(self, x, architecture_weights):\n        \"\"\"\n        Forward pass with specific architecture weights\n        Args:\n            x: Input features [B, C, T]\n            architecture_weights: Architecture weights tensor\n        \"\"\"\n        # Check input format and adjust if needed\n        if x.shape[1] == self.input_channels:\n            # Input is already [B, C, T]\n            pass\n        else:\n            # Input is [B, T, C], convert to [B, C, T]\n            x = x.permute(0, 2, 1)\n    \n        # Process input (no need for permute since we've handled it above)\n        x = self.stem(x)\n    \n        # Reshape weights for each edge\n        edge_weights = []\n        edges_per_cell = sum(range(1, self.num_nodes+1))\n        total_edges = self.num_cells * edges_per_cell\n        \n        # Split weights by cell and edge\n        for i in range(total_edges):\n            start_idx = i * self.num_ops\n            end_idx = start_idx + self.num_ops\n            # Apply softmax to get probability distribution over operations\n            edge_weights.append(F.softmax(architecture_weights[start_idx:end_idx], dim=0))\n        \n        \n        \n        # Process cells\n        offset = 0\n        for i, cell in enumerate(self.cells):\n            cell_weights = edge_weights[offset:offset + edges_per_cell]\n            offset += edges_per_cell\n            x = cell(x, cell_weights)\n        \n        # Classification\n        x = self.pool(x).squeeze(-1)\n        x = self.classifier(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.462423Z","iopub.execute_input":"2025-04-15T02:16:39.462601Z","iopub.status.idle":"2025-04-15T02:16:39.477991Z","shell.execute_reply.started":"2025-04-15T02:16:39.462587Z","shell.execute_reply":"2025-04-15T02:16:39.477420Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PPOController(nn.Module):\n    def __init__(self, state_dim, action_dim, hidden_dim=64):\n        super(PPOController, self).__init__()\n        \n        # Print dimensions for debugging\n        print(f\"Initializing PPO controller with state_dim={state_dim}, action_dim={action_dim}\")\n        \n        # Actor network (policy)\n        self.actor = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, action_dim)\n        )\n        \n        # Critic network (value function)\n        self.critic = nn.Sequential(\n            nn.Linear(state_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, 1)\n        )\n        \n    def forward(self, state):\n        # Print state shape for debugging\n        #if hasattr(state, 'shape'):\n            #print(f\"State shape in forward: {state.shape}\")\n        \n        # Returns action probabilities and estimated value\n        action_probs = F.softmax(self.actor(state), dim=-1)\n        value = self.critic(state)\n        return action_probs, value\n    \n    def act(self, state):\n        action_probs, _ = self.forward(state)\n        dist = Categorical(action_probs)\n        action = dist.sample()\n        log_prob = dist.log_prob(action)\n        return action.detach(), log_prob.detach()\n    \n    def evaluate(self, state, action):\n        action_probs, value = self.forward(state)\n        dist = Categorical(action_probs)\n        log_prob = dist.log_prob(action)\n        entropy = dist.entropy()\n        return log_prob, value, entropy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.479950Z","iopub.execute_input":"2025-04-15T02:16:39.480159Z","iopub.status.idle":"2025-04-15T02:16:39.493142Z","shell.execute_reply.started":"2025-04-15T02:16:39.480134Z","shell.execute_reply":"2025-04-15T02:16:39.492588Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Updated PPO Training function to properly handle the state dimension\ndef train_ppo(controller, optimizer, memories, clip_ratio=0.2, epochs=10, entropy_coef=0.01):\n    \"\"\"Train the PPO controller on collected experiences\"\"\"\n    # Unpack memories with proper reshaping\n    states = torch.cat([m['state'] for m in memories])\n    actions = torch.cat([m['action'] for m in memories])\n    old_log_probs = torch.cat([m['log_prob'] for m in memories])\n    rewards = torch.cat([m['reward'] for m in memories])\n    \n    # Check state dimensions\n    #print(f\"States shape in train_ppo: {states.shape}\")\n    \n    # Reshape states if needed - keeping only one element per state instead of flattening\n    if len(states.shape) == 1:  # If states got flattened to [N]\n        states = states.view(-1, 1)  # Reshape to [N, 1]\n        #print(f\"Reshaped states to: {states.shape}\")\n    \n    # Normalize rewards for stable training\n    rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n    \n    # Store metrics for logging\n    metrics = {\n        'actor_loss': 0,\n        'critic_loss': 0,\n        'entropy_loss': 0\n    }\n    \n    # Train for multiple epochs with progress bar\n    ppo_pbar = tqdm(range(epochs), desc=\"PPO Training\", leave=False)\n    \n    for _ in ppo_pbar:\n        try:\n            # Process states and actions in batches to evaluate\n            # Evaluate one item at a time to avoid shape issues\n            all_log_probs = []\n            all_values = []\n            all_entropy = []\n            \n            for i in range(len(states)):\n                state_i = states[i:i+1]  # Take one state at a time, keep as [1, dim]\n                action_i = actions[i:i+1]  # Take one action at a time\n                \n                # Evaluate through controller\n                action_probs, value = controller.forward(state_i)\n                dist = Categorical(action_probs)\n                log_prob = dist.log_prob(action_i.squeeze())\n                entropy = dist.entropy()\n                \n                all_log_probs.append(log_prob)\n                all_values.append(value.squeeze())\n                all_entropy.append(entropy)\n            \n            # Combine results\n            log_probs = torch.stack(all_log_probs)\n            values = torch.stack(all_values)\n            entropy = torch.stack(all_entropy)\n            \n            # Compute ratio and surrogate loss\n            ratio = torch.exp(log_probs - old_log_probs)\n            surr1 = ratio * rewards\n            surr2 = torch.clamp(ratio, 1 - clip_ratio, 1 + clip_ratio) * rewards\n            \n            # PPO loss\n            actor_loss = -torch.min(surr1, surr2).mean()\n            critic_loss = F.mse_loss(values, rewards)\n            entropy_loss = -entropy.mean()\n            \n            # Total loss\n            loss = actor_loss + 0.5 * critic_loss - entropy_coef * entropy_loss\n            \n            # Update\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            # Update metrics\n            metrics['actor_loss'] += actor_loss.item() / epochs\n            metrics['critic_loss'] += critic_loss.item() / epochs\n            metrics['entropy_loss'] += entropy_loss.item() / epochs\n            \n            # Update progress bar\n            ppo_pbar.set_postfix({\n                'actor_loss': f\"{actor_loss.item():.4f}\",\n                'critic_loss': f\"{critic_loss.item():.4f}\",\n                'entropy': f\"{entropy.mean().item():.4f}\"\n            })\n        except Exception as e:\n            print(f\"Error in PPO training: {e}\")\n            import traceback\n            traceback.print_exc()\n            # Return some values to avoid breaking the training loop\n            return 0.0, 0.0, 0.0\n    \n    return metrics['actor_loss'], metrics['critic_loss'], metrics['entropy_loss']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.493865Z","iopub.execute_input":"2025-04-15T02:16:39.494123Z","iopub.status.idle":"2025-04-15T02:16:39.508792Z","shell.execute_reply.started":"2025-04-15T02:16:39.494101Z","shell.execute_reply":"2025-04-15T02:16:39.508178Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Main NAS using PPO\ndef search_architecture(train_loader, val_loader, device, input_channels=60, num_cells=3, \n                        num_nodes=4, num_ops=6, epochs=50, ppo_updates=5, project_name=\"deepfake-nas-ppo\"):\n    \"\"\"Perform neural architecture search using PPO\"\"\"\n    # Initialize wandb\n    wandb.init(project=project_name, name=f\"NAS_cells{num_cells}_nodes{num_nodes}\")\n    \n    # Log hyperparameters\n    config = {\n        \"input_channels\": input_channels,\n        \"num_cells\": num_cells,\n        \"num_nodes\": num_nodes,\n        \"num_ops\": num_ops,\n        \"epochs\": epochs,\n        \"ppo_updates\": ppo_updates,\n        \"model_lr\": 0.001,\n        \"controller_lr\": 0.001,\n    }\n    wandb.config.update(config)\n    \n    # Calculate edges first\n    edges_per_cell = sum(range(1, num_nodes+1))\n    total_edges = num_cells * edges_per_cell\n    \n    # Initialize model and controller\n    model = DeepfakeDetectionModel(input_channels, num_cells, num_nodes, num_ops).to(device)\n    \n    # State dimension is the validation performance metric (just using EER as state)\n    state_dim = 1  # Single value for validation performance\n    \n    # Action dimension is the number of operations per edge\n    action_dim = num_ops  # Number of operations per edge\n    \n    # Initialize PPO controller\n    controller = PPOController(state_dim, action_dim).to(device)\n    controller_optimizer = optim.Adam(controller.parameters(), lr=config[\"controller_lr\"])\n    \n    # Model optimizer\n    model_optimizer = optim.Adam(model.parameters(), lr=config[\"model_lr\"])\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, 'min', patience=5)\n    \n    # Metrics tracking\n    best_val_eer = 1.0\n    best_architecture = None\n    \n    # Disable nested progress bars completely\n    tqdm.monitor_interval = 0\n    \n    # Use with statement for epoch progress bar\n    with tqdm(total=epochs, desc=\"Architecture Search Progress\", position=0, leave=True) as epoch_pbar:\n        for epoch in range(epochs):\n            # Train the model with current architecture\n            model.train()\n            train_loss = 0.0\n            correct = 0\n            total = 0\n            \n            # For PPO\n            memories = []\n            current_architecture = []\n            \n            # Sample architecture for this epoch\n            for i in range(total_edges):\n                # Use current validation EER as state (normalized between 0 and 1)\n                state = torch.FloatTensor([min(best_val_eer, 0.5) * 2]).to(device)  # Scale to [0, 1]\n                \n                # Sample architecture weights for this edge\n                for j in range(num_ops):\n                    action, log_prob = controller.act(state)\n                    current_architecture.append(action.item())\n                    \n                    # Store experience for PPO - ensure state is properly shaped\n                    memories.append({\n                        'state': state.clone(),  # Ensure this is a 1D tensor of shape [1]\n                        'action': action.unsqueeze(0),\n                        'log_prob': log_prob.unsqueeze(0),\n                        'reward': torch.zeros(1).to(device)  # Will be updated later\n                    })\n            \n            # Convert architecture to tensor\n            architecture_weights = torch.FloatTensor(current_architecture).to(device)\n            \n            # Train the model with current architecture - use a simple counter instead of tqdm\n            batch_count = 0\n            for inputs, targets in train_loader:\n                batch_count += 1\n                if batch_count % 10 == 0:  # Only print every 10 batches\n                    print(f\"\\rTraining batch {batch_count}/{len(train_loader)}\", end=\"\")\n                    \n                inputs, targets = inputs.to(device), targets.to(device)\n                # Check for NaN values in inputs\n                if torch.isnan(inputs).any():\n                    print(\"Warning: NaN values in inputs, replacing with zeros\")\n                    inputs = torch.nan_to_num(inputs, nan=0.0)\n            \n                model_optimizer.zero_grad()\n            \n                try:\n                    outputs = model(inputs, architecture_weights)\n                \n                    # Check for NaN values in outputs\n                    if torch.isnan(outputs).any():\n                        print(\"Warning: NaN values in model outputs, replacing with zeros\")\n                        outputs = torch.nan_to_num(outputs, nan=0.0)\n                \n                    loss = F.cross_entropy(outputs, targets)\n                    loss.backward()\n                    # Clip gradients to prevent explosion\n                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n                    model_optimizer.step()\n                \n                    train_loss += loss.item()\n                    _, predicted = outputs.max(1)\n                    total += targets.size(0)\n                    correct += predicted.eq(targets).sum().item()\n                \n                except Exception as e:\n                    print(f\"Error in training step: {e}\")\n                    continue\n            \n            print()  # Line break after training\n            \n            train_accuracy = 100 * correct / total if total > 0 else 0\n            avg_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n            \n            # Validate the model\n            model.eval()\n            val_loss = 0.0\n            all_targets = []\n            all_scores = []\n            \n            with torch.no_grad():\n                # Use a simple counter instead of tqdm\n                batch_count = 0\n                for inputs, targets in val_loader:\n                    batch_count += 1\n                    if batch_count % 10 == 0:  # Only print every 10 batches\n                        print(f\"\\rValidation batch {batch_count}/{len(val_loader)}\", end=\"\")\n                        \n                    try:\n                        inputs, targets = inputs.to(device), targets.to(device)\n                    \n                        # Check for NaN values in inputs\n                        if torch.isnan(inputs).any():\n                            print(\"Warning: NaN values in inputs, replacing with zeros\")\n                            inputs = torch.nan_to_num(inputs, nan=0.0)\n                    \n                        outputs = model(inputs, architecture_weights)\n                    \n                        # Check for NaN values in outputs\n                        if torch.isnan(outputs).any():\n                            print(\"Warning: NaN values in model outputs, replacing with zeros\")\n                            outputs = torch.nan_to_num(outputs, nan=0.0)\n                    \n                        loss = F.cross_entropy(outputs, targets)\n                        val_loss += loss.item()\n                    \n                        # Get scores for EER calculation\n                        scores = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Score for spoof class\n                    \n                        # Check for NaN values in scores\n                        if np.isnan(scores).any():\n                            print(\"Warning: NaN values in scores, replacing with zeros\")\n                            scores = np.nan_to_num(scores, nan=0.0)\n                    \n                        all_targets.extend(targets.cpu().numpy())\n                        all_scores.extend(scores)\n                    \n                    except Exception as e:\n                        print(f\"Error in validation step: {e}\")\n                        continue\n            \n            print()  # Line break after validation\n            \n            # Calculate EER with robust error handling\n            try:\n                # First check if we have enough data\n                if len(all_targets) == 0 or len(all_scores) == 0:\n                    print(\"Warning: No valid targets or scores for EER calculation\")\n                    eer = 0.5  # Default to random guess performance\n                    eer_threshold = 0.5\n                else:\n                    # Check if we have both classes in the targets\n                    unique_targets = np.unique(all_targets)\n                    if len(unique_targets) < 2:\n                        print(f\"Warning: Only found class {unique_targets[0]} in targets, need both classes for ROC curve\")\n                        eer = 0.5\n                        eer_threshold = 0.5\n                    else:\n                        fpr, tpr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n                        fnr = 1 - tpr\n                \n                        # Check if there are no valid values for EER calculation\n                        if len(thresholds) == 0 or np.all(np.isnan(fnr - fpr)):\n                            print(\"Warning: Cannot calculate EER - invalid ROC curve\")\n                            eer = 0.5  # Default to random guess performance\n                            eer_threshold = 0.5\n                        else:\n                            # Find the index where the difference is minimum\n                            idx = np.nanargmin(np.absolute(fnr - fpr))\n                            eer_threshold = thresholds[idx]\n                            eer = (fpr[idx] + fnr[idx]) / 2\n            \n            except Exception as e:\n                print(f\"Error calculating EER: {e}\")\n                print(f\"all_targets shape: {np.shape(all_targets)}, unique values: {np.unique(all_targets) if len(all_targets) > 0 else 'None'}\")\n                print(f\"all_scores shape: {np.shape(all_scores)}, range: [{np.min(all_scores) if len(all_scores) > 0 else 'N/A'}, {np.max(all_scores) if len(all_scores) > 0 else 'N/A'}]\")\n                # Provide fallback values\n                eer = 0.5\n                eer_threshold = 0.5\n            \n            avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n            \n            # Update epoch progress bar\n            epoch_pbar.update(1)\n            epoch_pbar.set_postfix({\n                \"Train Loss\": f\"{avg_train_loss:.4f}\",\n                \"Val EER\": f\"{eer:.4f}\",\n                \"Best EER\": f\"{best_val_eer:.4f}\"\n            })\n            \n            # Log metrics to wandb\n            wandb.log({\n                \"epoch\": epoch + 1,\n                \"train_loss\": avg_train_loss,\n                \"train_accuracy\": train_accuracy,\n                \"val_loss\": avg_val_loss,\n                \"val_eer\": eer,\n                \"best_val_eer\": best_val_eer,\n                \"learning_rate\": model_optimizer.param_groups[0]['lr']\n            })\n            \n            # Update PPO rewards based on EER improvement\n            reward = best_val_eer - eer if eer < best_val_eer else 0\n            for memory in memories:\n                memory['reward'] = torch.FloatTensor([reward]).to(device)\n            \n            # Update best architecture if improved\n            if eer < best_val_eer:\n                best_val_eer = eer\n                best_architecture = architecture_weights.clone()\n                \n                # Save best model\n                checkpoint_path = 'best_deepfake_detection_model.pth'\n                torch.save({\n                    'model_state_dict': model.state_dict(),\n                    'architecture': best_architecture,\n                    'eer': best_val_eer,\n                    'epoch': epoch + 1\n                }, checkpoint_path)\n                \n                # Log best model to wandb\n                wandb.save(checkpoint_path)\n                \n                # Log best architecture visualization\n                visualize_architecture(best_architecture, num_cells, num_nodes, num_ops, save_to_wandb=True)\n                \n                print(f\"\\nNew best architecture found! EER: {best_val_eer:.4f}\")\n            \n            # Update learning rate\n            scheduler.step(eer)\n            \n            # Update PPO controller if enough data\n            if epoch % ppo_updates == 0 and len(memories) > 0:\n                try:\n                    print(\"Updating PPO controller...\")\n                    actor_loss, critic_loss, entropy_loss = train_ppo(\n                        controller, controller_optimizer, memories)\n                    \n                    # Log PPO metrics\n                    wandb.log({\n                        \"actor_loss\": actor_loss,\n                        \"critic_loss\": critic_loss,\n                        \"entropy_loss\": entropy_loss\n                    })\n                except Exception as e:\n                    print(f\"Error in PPO update: {e}\")\n                    import traceback\n                    traceback.print_exc()\n    \n    # Finish wandb run\n    wandb.finish()\n    \n    return model, best_architecture, best_val_eer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.509574Z","iopub.execute_input":"2025-04-15T02:16:39.509812Z","iopub.status.idle":"2025-04-15T02:16:39.533308Z","shell.execute_reply.started":"2025-04-15T02:16:39.509791Z","shell.execute_reply":"2025-04-15T02:16:39.532638Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Utility functions for evaluation\ndef evaluate_model(model, architecture, test_loader, device, log_to_wandb=True):\n    \"\"\"Evaluate the model with the best architecture\"\"\"\n    model.eval()\n    all_targets = []\n    all_scores = []\n    test_loss = 0.0\n    correct = 0\n    total = 0\n    \n    # Create a progress bar for evaluation\n    eval_pbar = tqdm(test_loader, desc=\"Evaluating\")\n    \n    with torch.no_grad():\n        for inputs, targets in eval_pbar:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs, architecture)\n            \n            # Compute loss\n            loss = F.cross_entropy(outputs, targets)\n            test_loss += loss.item()\n            \n            # Compute accuracy\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            # Get scores for EER calculation\n            scores = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Score for spoof class\n            all_targets.extend(targets.cpu().numpy())\n            all_scores.extend(scores)\n            \n            # Update progress bar with current metrics\n            eval_pbar.set_postfix({\n                \"loss\": f\"{loss.item():.4f}\",\n                \"accuracy\": f\"{100.0 * correct / total:.2f}%\"\n            })\n    \n    # Calculate test accuracy\n    test_accuracy = 100.0 * correct / total\n    avg_test_loss = test_loss / len(test_loader)\n    # Calculate EER\n    try:\n        fpr, tpr, thresholds = roc_curve(all_targets, all_scores, pos_label=1)\n        fnr = 1 - tpr\n    \n        # Check if we have valid values before using nanargmin\n        if np.all(np.isnan(fnr - fpr)):\n            print(\"Warning: Cannot calculate EER - all differences are NaN\")\n            # Provide a fallback value if EER calculation fails\n            eer = 0.5  # Default to random guess performance\n            eer_threshold = 0.5\n        else:\n            # Find the index where the difference is minimum\n            idx = np.nanargmin(np.absolute(fnr - fpr))\n            eer_threshold = thresholds[idx]\n            eer = (fpr[idx] + fnr[idx]) / 2\n        \n    except Exception as e:\n        print(f\"Error calculating EER: {e}\")\n        print(f\"all_targets shape: {np.shape(all_targets)}, unique values: {np.unique(all_targets)}\")\n        print(f\"all_scores shape: {np.shape(all_scores)}, range: [{np.min(all_scores)}, {np.max(all_scores)}]\")\n        # Provide fallback values\n        eer = 0.5\n        eer_threshold = 0.5\n    \n    # Plot ROC curve\n    plt.figure(figsize=(10, 8))\n    plt.plot(fpr, tpr, label=f'ROC Curve (EER = {eer:.4f})')\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve for Deepfake Detection')\n    plt.legend(loc=\"lower right\")\n    \n    # Save ROC curve\n    roc_curve_path = 'roc_curve.png'\n    plt.savefig(roc_curve_path)\n    \n    # Print results\n    print(f\"\\nTest Results - Loss: {avg_test_loss:.4f}, Accuracy: {test_accuracy:.2f}%, EER: {eer:.4f}, EER Threshold: {eer_threshold:.4f}\")\n    \n    # Log to wandb if requested\n    if log_to_wandb:\n        # Initialize wandb if it's not already running\n        if wandb.run is None:\n            wandb.init(project=\"deepfake-nas-ppo\", name=\"final_evaluation\")\n        \n        # Log metrics\n        wandb.log({\n            \"test_loss\": avg_test_loss,\n            \"test_accuracy\": test_accuracy,\n            \"test_eer\": eer,\n            \"eer_threshold\": eer_threshold\n        })\n        \n        # Log ROC curve\n        wandb.log({\"roc_curve\": wandb.Image(roc_curve_path)})\n        \n        # Log confusion matrix\n        cm = np.zeros((2, 2))\n        for i in range(len(all_targets)):\n            pred_class = 1 if all_scores[i] > eer_threshold else 0\n            cm[all_targets[i]][pred_class] += 1\n        \n        # Normalize confusion matrix\n        cm_norm = cm / cm.sum(axis=1, keepdims=True)\n        \n        # Plot confusion matrix\n        plt.figure(figsize=(8, 6))\n        plt.imshow(cm_norm, cmap='Blues')\n        plt.colorbar()\n        plt.title('Normalized Confusion Matrix')\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.xticks([0, 1], ['Bonafide', 'Spoof'])\n        plt.yticks([0, 1], ['Bonafide', 'Spoof'])\n        \n        # Add text annotations\n        for i in range(2):\n            for j in range(2):\n                plt.text(j, i, f'{cm[i, j]:.0f}\\n({cm_norm[i, j]:.2f})', \n                         ha='center', va='center', \n                         color='white' if cm_norm[i, j] > 0.5 else 'black')\n        \n        cm_path = 'confusion_matrix.png'\n        plt.savefig(cm_path)\n        wandb.log({\"confusion_matrix\": wandb.Image(cm_path)})\n    \n    return eer, eer_threshold\n\ndef visualize_architecture(architecture, num_cells, num_nodes, num_ops, save_to_wandb=False):\n    \"\"\"Visualize the architecture weights\"\"\"\n    edges_per_cell = sum(range(1, num_nodes+1))\n    \n    plt.figure(figsize=(15, 10))\n    \n    # Operation names for better visualization\n    op_names = ['Conv3x3', 'Conv5x5', 'LSTM', 'Dilated', 'SkipConn', 'Attention']\n    \n    for cell in range(num_cells):\n        plt.subplot(num_cells, 1, cell+1)\n        \n        edge_idx = 0\n        weights_matrix = np.zeros((num_nodes+1, num_nodes))\n        \n        # Create a matrix to store the operation types\n        op_matrix = np.empty((num_nodes+1, num_nodes), dtype=object)\n        \n        for i in range(num_nodes):\n            for j in range(i+1):\n                start_idx = (cell * edges_per_cell + edge_idx) * num_ops\n                edge_weights = F.softmax(architecture[start_idx:start_idx+num_ops].cpu(), dim=0).numpy()\n                strongest_op = np.argmax(edge_weights)\n                weights_matrix[j, i] = strongest_op + 1  # +1 for better visualization\n                op_matrix[j, i] = op_names[strongest_op] if strongest_op < len(op_names) else f\"Op{strongest_op}\"\n                edge_idx += 1\n        \n        # Create heatmap with annotations\n        plt.imshow(weights_matrix, cmap='viridis')\n        plt.colorbar(ticks=range(1, num_ops+2))\n        \n        # Add text annotations for operation types\n        for i in range(num_nodes):\n            for j in range(i+1):\n                if op_matrix[j, i] is not None:\n                    plt.text(i, j, op_matrix[j, i], ha=\"center\", va=\"center\", \n                             color=\"white\" if weights_matrix[j, i] > num_ops/2 else \"black\",\n                             fontsize=8)\n        \n        plt.title(f'Cell {cell+1} Architecture')\n        plt.xlabel('Destination Node')\n        plt.ylabel('Source Node')\n    \n    plt.tight_layout()\n    \n    # Save figure\n    fig_path = 'architecture_visualization.png'\n    plt.savefig(fig_path)\n    \n    # Log to wandb if requested\n    if save_to_wandb:\n        wandb.log({\"architecture_visualization\": wandb.Image(fig_path)})\n    \n    return fig_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.534224Z","iopub.execute_input":"2025-04-15T02:16:39.534433Z","iopub.status.idle":"2025-04-15T02:16:39.554780Z","shell.execute_reply.started":"2025-04-15T02:16:39.534419Z","shell.execute_reply":"2025-04-15T02:16:39.554145Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Main function to run the entire pipeline\ndef main():\n    # Import time for experiment naming\n    import time\n    import os\n    \n    # Initialize wandb for the entire experiment\n    experiment_name = f\"ASVspoof2019_NAS_PPO_{int(time.time())}\"\n    \n    print(\"Starting Deepfake Audio Detection with NAS and PPO\")\n    print(\"=\" * 80)\n    \n    # Paths and parameters (based on the provided dataset structure)\n    base_dir = \"/kaggle/input/asvspoof-dataset-2019\"\n    data_dir_train = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_train\", \"flac\")\n    data_dir_dev = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_dev\", \"flac\")\n    data_dir_eval = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_eval\", \"flac\")\n    \n    train_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.train.trn.txt\")\n    dev_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.dev.trl.txt\")\n    eval_protocol = os.path.join(base_dir, \"LA\", \"ASVspoof2019_LA_cm_protocols\", \"ASVspoof2019.LA.cm.eval.trl.txt\")\n    \n    # Log dataset information\n    print(f\"Train data directory: {data_dir_train}\")\n    print(f\"Train protocol file: {train_protocol}\")\n    print(f\"Dev data directory: {data_dir_dev}\")\n    print(f\"Dev protocol file: {dev_protocol}\")\n    print(f\"Eval data directory: {data_dir_eval}\")\n    print(f\"Eval protocol file: {eval_protocol}\")\n    \n    # Experiment configuration\n    feature_type = 'mfcc'  # Options: 'mfcc', 'spec', 'cqt'\n    max_seq_len = 400\n    batch_size_train = 32\n    batch_size_eval = 64\n    num_workers = 4\n\n    wandb.login(key=\"373119fa114178ac5e09f36834a61c071debfbb8\")\n    # Initialize wandb\n    wandb.init(\n        project=\"ASVspoof2019-NAS-PPO\",\n        name=experiment_name,\n        config={\n            \"feature_type\": feature_type,\n            \"max_sequence_length\": max_seq_len,\n            \"batch_size_train\": batch_size_train,\n            \"batch_size_eval\": batch_size_eval,\n            \"num_workers\": num_workers,\n            \"dataset\": \"ASVspoof2019 LA\"\n        }\n    )\n    \n    # Create datasets with tqdm progress for loading\n    print(\"Creating datasets...\")\n    \n    print(\"Loading training dataset...\")\n    train_dataset = ASVSpoofDataset(\n        root_dir=data_dir_train,\n        protocol_file=train_protocol,\n        feature_type=feature_type,\n        max_len=max_seq_len,\n        is_train=True\n    )\n    \n    print(\"Loading validation dataset...\")\n    dev_dataset = ASVSpoofDataset(\n        root_dir=data_dir_dev,\n        protocol_file=dev_protocol,\n        feature_type=feature_type,\n        max_len=max_seq_len,\n        is_train=False\n    )\n    \n    print(\"Loading evaluation dataset...\")\n    eval_dataset = ASVSpoofDataset(\n        root_dir=data_dir_eval,\n        protocol_file=eval_protocol,\n        feature_type=feature_type,\n        max_len=max_seq_len,\n        is_train=False\n    )\n    \n    # Log dataset sizes\n    print(f\"Training dataset size: {len(train_dataset)} samples\")\n    print(f\"Validation dataset size: {len(dev_dataset)} samples\")\n    print(f\"Evaluation dataset size: {len(eval_dataset)} samples\")\n    wandb.log({\n        \"train_dataset_size\": len(train_dataset),\n        \"val_dataset_size\": len(dev_dataset),\n        \"eval_dataset_size\": len(eval_dataset)\n    })\n    \n    # Create data loaders\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size_train, \n        shuffle=True, \n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    dev_loader = DataLoader(\n        dev_dataset, \n        batch_size=batch_size_eval, \n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    eval_loader = DataLoader(\n        eval_dataset, \n        batch_size=batch_size_eval, \n        shuffle=False, \n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    # Architecture search parameters\n    nas_config = {\n        \"input_channels\": 60,  # 20 MFCCs x 3 (static, delta, delta-delta)\n        \"num_cells\": 3,\n        \"num_nodes\": 4,\n        \"num_ops\": 6,\n        \"epochs\": 30,\n        \"ppo_updates\": 5,\n        \"project_name\": \"ASVspoof2019-NAS-PPO\"\n    }\n    \n    # Log NAS configuration\n    print(\"\\nNeural Architecture Search Configuration:\")\n    for key, value in nas_config.items():\n        print(f\"  {key}: {value}\")\n    \n    # Create output directory for results\n    output_dir = f\"/kaggle/working/results_{experiment_name}\"\n    os.makedirs(output_dir, exist_ok=True)\n    print(f\"\\nResults will be saved to {output_dir}\")\n    \n    # Perform architecture search with wandb logging\n    print(\"\\nStarting Neural Architecture Search...\")\n    model, best_architecture, best_val_eer = search_architecture(\n        train_loader=train_loader,\n        val_loader=dev_loader,\n        device=device,\n        input_channels=nas_config[\"input_channels\"],\n        num_cells=nas_config[\"num_cells\"],\n        num_nodes=nas_config[\"num_nodes\"],\n        num_ops=nas_config[\"num_ops\"],\n        epochs=nas_config[\"epochs\"],\n        ppo_updates=nas_config[\"ppo_updates\"],\n        project_name=nas_config[\"project_name\"]\n    )\n    \n    # Save best architecture\n    torch.save(best_architecture, os.path.join(output_dir, \"best_architecture.pt\"))\n    \n    # Initialize a new wandb run for final evaluation\n    wandb.finish()  # Finish the NAS run\n    wandb.init(\n        project=\"ASVspoof2019-NAS-PPO\",\n        name=f\"{experiment_name}_final_evaluation\",\n        config={\n            \"feature_type\": feature_type,\n            \"best_val_eer\": best_val_eer\n        }\n    )\n    \n    # Evaluate on the evaluation set\n    print(\"\\nPerforming final evaluation on test set...\")\n    test_eer, eer_threshold = evaluate_model(model, best_architecture, eval_loader, device)\n    \n    # Log final metrics\n    wandb.log({\n        \"final_test_eer\": test_eer,\n        \"eer_threshold\": eer_threshold\n    })\n    \n    # Visualize the architecture with annotations\n    print(\"\\nVisualizing the best architecture...\")\n    fig_path = visualize_architecture(best_architecture, \n                                     num_cells=nas_config[\"num_cells\"], \n                                     num_nodes=nas_config[\"num_nodes\"], \n                                     num_ops=nas_config[\"num_ops\"],\n                                     save_to_wandb=True)\n    \n    # Save architecture visualization\n    import shutil\n    shutil.copy(fig_path, os.path.join(output_dir, \"architecture_visualization.png\"))\n    \n    # Create a summary report\n    summary = {\n        \"experiment_name\": experiment_name,\n        \"feature_type\": feature_type,\n        \"best_validation_eer\": best_val_eer,\n        \"test_eer\": test_eer,\n        \"eer_threshold\": eer_threshold,\n        \"model_architecture\": {\n            \"num_cells\": nas_config[\"num_cells\"],\n            \"num_nodes\": nas_config[\"num_nodes\"],\n            \"num_operations\": nas_config[\"num_ops\"]\n        }\n    }\n    \n    # Save summary as JSON\n    import json\n    with open(os.path.join(output_dir, \"summary.json\"), \"w\") as f:\n        json.dump(summary, f, indent=4)\n    \n    # Also save as text for easy reading\n    with open(os.path.join(output_dir, \"summary.txt\"), \"w\") as f:\n        f.write(\"ASVspoof 2019 Deepfake Detection Summary\\n\")\n        f.write(\"=\" * 50 + \"\\n\\n\")\n        f.write(f\"Experiment name: {experiment_name}\\n\")\n        f.write(f\"Feature type: {feature_type}\\n\\n\")\n        f.write(\"Performance metrics:\\n\")\n        f.write(f\"  Best validation EER: {best_val_eer:.4f}\\n\")\n        f.write(f\"  Test EER: {test_eer:.4f}\\n\")\n        f.write(f\"  EER threshold: {eer_threshold:.4f}\\n\\n\")\n        f.write(\"Model architecture:\\n\")\n        f.write(f\"  Number of cells: {nas_config['num_cells']}\\n\")\n        f.write(f\"  Number of nodes per cell: {nas_config['num_nodes']}\\n\")\n        f.write(f\"  Number of operations: {nas_config['num_ops']}\\n\")\n    \n    # Log summary to wandb\n    wandb.save(os.path.join(output_dir, \"summary.txt\"))\n    wandb.save(os.path.join(output_dir, \"summary.json\"))\n    \n    print(\"\\nExperiment completed!\")\n    print(f\"Final Test EER: {test_eer:.4f}, EER Threshold: {eer_threshold:.4f}\")\n    print(f\"All results saved to {output_dir}\")\n    print(\"=\" * 80)\n    \n    # Finish wandb\n    wandb.finish()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.555525Z","iopub.execute_input":"2025-04-15T02:16:39.555791Z","iopub.status.idle":"2025-04-15T02:16:39.573945Z","shell.execute_reply.started":"2025-04-15T02:16:39.555751Z","shell.execute_reply":"2025-04-15T02:16:39.573449Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T02:16:39.574724Z","iopub.execute_input":"2025-04-15T02:16:39.575136Z"}},"outputs":[{"name":"stdout","text":"Starting Deepfake Audio Detection with NAS and PPO\n================================================================================\nTrain data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_train/flac\nTrain protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\nDev data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_dev/flac\nDev protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\nEval data directory: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_eval/flac\nEval protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtangridhruv\u001b[0m (\u001b[33mtangridhruv-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250415_021645-otpakgwb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/tangridhruv-carnegie-mellon-university/ASVspoof2019-NAS-PPO/runs/otpakgwb' target=\"_blank\">ASVspoof2019_NAS_PPO_1744683399</a></strong> to <a href='https://wandb.ai/tangridhruv-carnegie-mellon-university/ASVspoof2019-NAS-PPO' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/tangridhruv-carnegie-mellon-university/ASVspoof2019-NAS-PPO' target=\"_blank\">https://wandb.ai/tangridhruv-carnegie-mellon-university/ASVspoof2019-NAS-PPO</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/tangridhruv-carnegie-mellon-university/ASVspoof2019-NAS-PPO/runs/otpakgwb' target=\"_blank\">https://wandb.ai/tangridhruv-carnegie-mellon-university/ASVspoof2019-NAS-PPO/runs/otpakgwb</a>"},"metadata":{}},{"name":"stdout","text":"Creating datasets...\nLoading training dataset...\nReading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt\n","output_type":"stream"},{"name":"stderr","text":"Loading training protocol: 100%|| 25380/25380 [00:00<00:00, 1243054.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dataset loaded: 25380 samples (22800 bonafide, 2580 spoof)\nSubsampling training data for faster NAS...\nSubsampled to 5000 samples\nLoading validation dataset...\nReading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt\n","output_type":"stream"},{"name":"stderr","text":"Loading evaluation protocol: 100%|| 24844/24844 [00:00<00:00, 1561893.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Dataset loaded: 24844 samples (22296 bonafide, 2548 spoof)\nLoading evaluation dataset...\nReading protocol file: /kaggle/input/asvspoof-dataset-2019/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt\n","output_type":"stream"},{"name":"stderr","text":"Loading evaluation protocol: 100%|| 71237/71237 [00:00<00:00, 1538566.60it/s]","output_type":"stream"},{"name":"stdout","text":"Dataset loaded: 71237 samples (63882 bonafide, 7355 spoof)\nTraining dataset size: 5000 samples\nValidation dataset size: 24844 samples\nEvaluation dataset size: 71237 samples\n\nNeural Architecture Search Configuration:\n  input_channels: 60\n  num_cells: 3\n  num_nodes: 4\n  num_ops: 6\n  epochs: 30\n  ppo_updates: 5\n  project_name: ASVspoof2019-NAS-PPO\n\nResults will be saved to /kaggle/working/results_ASVspoof2019_NAS_PPO_1744683399\n\nStarting Neural Architecture Search...\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"Initializing PPO controller with state_dim=1, action_dim=6\n","output_type":"stream"},{"name":"stderr","text":"Architecture Search Progress:   0%|          | 0/30 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Training batch 150/157\nValidation batch 120/389","output_type":"stream"}],"execution_count":null}]}